{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoPERIYvHfVK3erd6kJ7Ue",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/titusjscott/multi-layer-perceptron/blob/main/current_airline_delay_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ_zj5dpaekW",
        "outputId": "ec610f04-c412-4611-aa17-a797b00c97c3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.3.0-py3-none-any.whl (167 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (7.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.25.1)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (23.1.21)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.31.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.51.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (15.0.6.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.19.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (4.5.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.2)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (5.7.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2022.12.7)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0->keras-tuner) (0.38.4)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.16.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.2.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (6.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.2.2)\n",
            "Installing collected packages: kt-legacy, jedi, keras-tuner\n",
            "Successfully installed jedi-0.18.2 keras-tuner-1.3.0 kt-legacy-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UBSsx0lrwlrI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.metrics import Precision, Recall\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelBinarizer, MinMaxScaler, Normalizer, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils import class_weight\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from kerastuner.tuners import RandomSearch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/titusjscott/multi-layer-perceptron/main/airlines_delay.csv\")\n"
      ],
      "metadata": {
        "id": "bp7nO5QswoRD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KdgFlS5exEtW",
        "outputId": "5127bfed-a576-47b5-df6a-3748221fc295"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Flight    Time  Length Airline AirportFrom AirportTo  DayOfWeek  Class\n",
              "0  2313.0  1296.0   141.0      DL         ATL       HOU          1      0\n",
              "1  6948.0   360.0   146.0      OO         COS       ORD          4      0\n",
              "2  1247.0  1170.0   143.0      B6         BOS       CLT          3      0\n",
              "3    31.0  1410.0   344.0      US         OGG       PHX          6      0\n",
              "4   563.0   692.0    98.0      FL         BMI       ATL          4      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98ad340b-1ecf-42d2-9d92-8b254b0232fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Flight</th>\n",
              "      <th>Time</th>\n",
              "      <th>Length</th>\n",
              "      <th>Airline</th>\n",
              "      <th>AirportFrom</th>\n",
              "      <th>AirportTo</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2313.0</td>\n",
              "      <td>1296.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>DL</td>\n",
              "      <td>ATL</td>\n",
              "      <td>HOU</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6948.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>OO</td>\n",
              "      <td>COS</td>\n",
              "      <td>ORD</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1247.0</td>\n",
              "      <td>1170.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>B6</td>\n",
              "      <td>BOS</td>\n",
              "      <td>CLT</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31.0</td>\n",
              "      <td>1410.0</td>\n",
              "      <td>344.0</td>\n",
              "      <td>US</td>\n",
              "      <td>OGG</td>\n",
              "      <td>PHX</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>563.0</td>\n",
              "      <td>692.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>FL</td>\n",
              "      <td>BMI</td>\n",
              "      <td>ATL</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98ad340b-1ecf-42d2-9d92-8b254b0232fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-98ad340b-1ecf-42d2-9d92-8b254b0232fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-98ad340b-1ecf-42d2-9d92-8b254b0232fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "334dWecVxe3i",
        "outputId": "fc5eceb0-a061-44af-a0d5-019195c25b1b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Flight         0\n",
              "Time           0\n",
              "Length         0\n",
              "Airline        0\n",
              "AirportFrom    0\n",
              "AirportTo      0\n",
              "DayOfWeek      0\n",
              "Class          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc-jLlQckmFq",
        "outputId": "ce4803c1-db58-4faf-8866-f220a5aabcaf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 539382 entries, 0 to 539381\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count   Dtype  \n",
            "---  ------       --------------   -----  \n",
            " 0   Flight       539382 non-null  float64\n",
            " 1   Time         539382 non-null  float64\n",
            " 2   Length       539382 non-null  float64\n",
            " 3   Airline      539382 non-null  object \n",
            " 4   AirportFrom  539382 non-null  object \n",
            " 5   AirportTo    539382 non-null  object \n",
            " 6   DayOfWeek    539382 non-null  int64  \n",
            " 7   Class        539382 non-null  int64  \n",
            "dtypes: float64(3), int64(2), object(3)\n",
            "memory usage: 32.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "WIOH82vzkc8S",
        "outputId": "22adaf32-4b67-4546-c1a9-51859dce6ef5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Flight           Time         Length      DayOfWeek  \\\n",
              "count  539382.000000  539382.000000  539382.000000  539382.000000   \n",
              "mean     2427.927988     802.728161     132.202104       3.929666   \n",
              "std      2067.431700     278.045546      70.117045       1.914666   \n",
              "min         1.000000      10.000000       0.000000       1.000000   \n",
              "25%       712.000000     565.000000      81.000000       2.000000   \n",
              "50%      1809.000000     795.000000     115.000000       4.000000   \n",
              "75%      3745.000000    1035.000000     162.000000       5.000000   \n",
              "max      7814.000000    1439.000000     655.000000       7.000000   \n",
              "\n",
              "               Class  \n",
              "count  539382.000000  \n",
              "mean        0.445443  \n",
              "std         0.497015  \n",
              "min         0.000000  \n",
              "25%         0.000000  \n",
              "50%         0.000000  \n",
              "75%         1.000000  \n",
              "max         1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ebb688e-23aa-43e8-9e53-62bcf3e1dc05\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Flight</th>\n",
              "      <th>Time</th>\n",
              "      <th>Length</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>539382.000000</td>\n",
              "      <td>539382.000000</td>\n",
              "      <td>539382.000000</td>\n",
              "      <td>539382.000000</td>\n",
              "      <td>539382.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2427.927988</td>\n",
              "      <td>802.728161</td>\n",
              "      <td>132.202104</td>\n",
              "      <td>3.929666</td>\n",
              "      <td>0.445443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2067.431700</td>\n",
              "      <td>278.045546</td>\n",
              "      <td>70.117045</td>\n",
              "      <td>1.914666</td>\n",
              "      <td>0.497015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>712.000000</td>\n",
              "      <td>565.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1809.000000</td>\n",
              "      <td>795.000000</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3745.000000</td>\n",
              "      <td>1035.000000</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7814.000000</td>\n",
              "      <td>1439.000000</td>\n",
              "      <td>655.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ebb688e-23aa-43e8-9e53-62bcf3e1dc05')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ebb688e-23aa-43e8-9e53-62bcf3e1dc05 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ebb688e-23aa-43e8-9e53-62bcf3e1dc05');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df['Class'], label = \"Count\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "FDU4Tp2Sxlsv",
        "outputId": "4a9584f5-b568-4b6d-b669-c9625cef0d58"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='Class', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rhzQFNAjDVs",
        "outputId": "12b52f63-1be7-48af-8aac-244c82af5479"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    299118\n",
              "1    240264\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "thE7nZYAkomn",
        "outputId": "576a348e-1afe-4393-b157-4668c1fb95f6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Flight    Time  Length Airline AirportFrom AirportTo  DayOfWeek  Class\n",
              "0  2313.0  1296.0   141.0      DL         ATL       HOU          1      0\n",
              "1  6948.0   360.0   146.0      OO         COS       ORD          4      0\n",
              "2  1247.0  1170.0   143.0      B6         BOS       CLT          3      0\n",
              "3    31.0  1410.0   344.0      US         OGG       PHX          6      0\n",
              "4   563.0   692.0    98.0      FL         BMI       ATL          4      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-525f2eb0-19e1-4d88-8e67-717a2e8ea6a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Flight</th>\n",
              "      <th>Time</th>\n",
              "      <th>Length</th>\n",
              "      <th>Airline</th>\n",
              "      <th>AirportFrom</th>\n",
              "      <th>AirportTo</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2313.0</td>\n",
              "      <td>1296.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>DL</td>\n",
              "      <td>ATL</td>\n",
              "      <td>HOU</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6948.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>OO</td>\n",
              "      <td>COS</td>\n",
              "      <td>ORD</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1247.0</td>\n",
              "      <td>1170.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>B6</td>\n",
              "      <td>BOS</td>\n",
              "      <td>CLT</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31.0</td>\n",
              "      <td>1410.0</td>\n",
              "      <td>344.0</td>\n",
              "      <td>US</td>\n",
              "      <td>OGG</td>\n",
              "      <td>PHX</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>563.0</td>\n",
              "      <td>692.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>FL</td>\n",
              "      <td>BMI</td>\n",
              "      <td>ATL</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-525f2eb0-19e1-4d88-8e67-717a2e8ea6a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-525f2eb0-19e1-4d88-8e67-717a2e8ea6a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-525f2eb0-19e1-4d88-8e67-717a2e8ea6a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.iloc[:,1:]"
      ],
      "metadata": {
        "id": "QkQT7YnQm6Ap"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DkMYDVL3m-eL",
        "outputId": "ead84510-53bc-49eb-de38-d400ad89d23f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Time  Length Airline AirportFrom AirportTo  DayOfWeek  Class\n",
              "0  1296.0   141.0      DL         ATL       HOU          1      0\n",
              "1   360.0   146.0      OO         COS       ORD          4      0\n",
              "2  1170.0   143.0      B6         BOS       CLT          3      0\n",
              "3  1410.0   344.0      US         OGG       PHX          6      0\n",
              "4   692.0    98.0      FL         BMI       ATL          4      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ebf57a97-4061-4f0f-abe4-5413a94a0c9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>Length</th>\n",
              "      <th>Airline</th>\n",
              "      <th>AirportFrom</th>\n",
              "      <th>AirportTo</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1296.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>DL</td>\n",
              "      <td>ATL</td>\n",
              "      <td>HOU</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>360.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>OO</td>\n",
              "      <td>COS</td>\n",
              "      <td>ORD</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1170.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>B6</td>\n",
              "      <td>BOS</td>\n",
              "      <td>CLT</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1410.0</td>\n",
              "      <td>344.0</td>\n",
              "      <td>US</td>\n",
              "      <td>OGG</td>\n",
              "      <td>PHX</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>692.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>FL</td>\n",
              "      <td>BMI</td>\n",
              "      <td>ATL</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebf57a97-4061-4f0f-abe4-5413a94a0c9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ebf57a97-4061-4f0f-abe4-5413a94a0c9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ebf57a97-4061-4f0f-abe4-5413a94a0c9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Airline'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVaMRZeqMfcA",
        "outputId": "8c674699-3741-4a62-988d-dd30b51bf96b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DL' 'OO' 'B6' 'US' 'FL' 'WN' 'CO' 'AA' 'YV' 'EV' 'XE' '9E' 'OH' 'UA'\n",
            " 'MQ' 'AS' 'F9' 'HA']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Airline'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwuRFeuHPj0F",
        "outputId": "e9b94deb-500b-4ce3-e139-e42e92342325"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WN    94097\n",
              "DL    60940\n",
              "OO    50254\n",
              "AA    45656\n",
              "MQ    36604\n",
              "US    34500\n",
              "XE    31126\n",
              "EV    27983\n",
              "UA    27619\n",
              "CO    21118\n",
              "FL    20827\n",
              "9E    20686\n",
              "B6    18112\n",
              "YV    13725\n",
              "OH    12630\n",
              "AS    11471\n",
              "F9     6456\n",
              "HA     5578\n",
              "Name: Airline, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert the airline codes to numeric value\n",
        "le = LabelEncoder()\n",
        "df['Airline_ID'] = le.fit_transform(df['Airline'])\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(1, 18))\n",
        "df['Airline_ID'] = scaler.fit_transform(df[['Airline_ID']])"
      ],
      "metadata": {
        "id": "jcYEUtf4S5ic"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Airline_ID'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNuJ6zkXTszs",
        "outputId": "69939dfc-69a0-450d-e0b3-d2ee649c2aa3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 6. 13.  4. 15.  9. 16.  5.  2. 18.  7. 17.  1. 12. 14. 11.  3.  8. 10.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Airline_ID'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ImycSLMT_9_",
        "outputId": "916fd7e9-3589-4925-ed26-de80ec2be437"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16.0    94097\n",
              "6.0     60940\n",
              "13.0    50254\n",
              "2.0     45656\n",
              "11.0    36604\n",
              "15.0    34500\n",
              "17.0    31126\n",
              "7.0     27983\n",
              "14.0    27619\n",
              "5.0     21118\n",
              "9.0     20827\n",
              "1.0     20686\n",
              "4.0     18112\n",
              "18.0    13725\n",
              "12.0    12630\n",
              "3.0     11471\n",
              "8.0      6456\n",
              "10.0     5578\n",
              "Name: Airline_ID, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['AirportFrom'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz53iyCtPuZr",
        "outputId": "e2fb4376-6277-4716-824d-701483555203"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ATL    34449\n",
              "ORD    24822\n",
              "DFW    22153\n",
              "DEN    19843\n",
              "LAX    16657\n",
              "       ...  \n",
              "MMH       16\n",
              "SJT       15\n",
              "GUM       10\n",
              "ADK        9\n",
              "ABR        2\n",
              "Name: AirportFrom, Length: 293, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert the AirportFrom codes to numeric value\n",
        "le = LabelEncoder()\n",
        "df['AirportFrom_ID'] = le.fit_transform(df['AirportFrom'])\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(1, 293))\n",
        "df['AirportFrom_ID'] = scaler.fit_transform(df[['AirportFrom_ID']])"
      ],
      "metadata": {
        "id": "z2iEHgLcUm_Y"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['AirportFrom_ID'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ2vvBTfU5u5",
        "outputId": "5da4b655-9524-4a9d-9b54-62e910fb8cd2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17.0     34449\n",
              "209.0    24822\n",
              "81.0     22153\n",
              "80.0     19843\n",
              "155.0    16657\n",
              "         ...  \n",
              "190.0       16\n",
              "260.0       15\n",
              "126.0       10\n",
              "9.0          9\n",
              "4.0          2\n",
              "Name: AirportFrom_ID, Length: 293, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['AirportTo'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBYxKdKrP2CO",
        "outputId": "05bfad9e-38db-4cad-fefe-c708f5def722"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ATL    34440\n",
              "ORD    24871\n",
              "DFW    22153\n",
              "DEN    19848\n",
              "LAX    16656\n",
              "       ...  \n",
              "MMH       16\n",
              "SJT       15\n",
              "GUM       10\n",
              "ADK        9\n",
              "ABR        2\n",
              "Name: AirportTo, Length: 293, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert the AirportTo codes to numeric value\n",
        "le = LabelEncoder()\n",
        "df['AirportTo_ID'] = le.fit_transform(df['AirportTo'])\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(1, 293))\n",
        "df['AirportTo_ID'] = scaler.fit_transform(df[['AirportTo_ID']])"
      ],
      "metadata": {
        "id": "oSyr4RLAVCgD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['AirportTo_ID'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QfyCQYZVM5r",
        "outputId": "2a736ee1-37b5-4780-cdcc-c5e79e37f5d3"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17.0     34440\n",
              "209.0    24871\n",
              "81.0     22153\n",
              "80.0     19848\n",
              "155.0    16656\n",
              "         ...  \n",
              "190.0       16\n",
              "260.0       15\n",
              "126.0       10\n",
              "9.0          9\n",
              "4.0          2\n",
              "Name: AirportTo_ID, Length: 293, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = df[['Airline', 'AirportFrom', 'AirportTo']]\n",
        "df = df.drop(a, axis=1)\n"
      ],
      "metadata": {
        "id": "xt0FEIOP0YG7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "p2ZlLSjD2AeT",
        "outputId": "e152d41c-f80e-4af9-d663-c4e19cd8139a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Time  Length  DayOfWeek  Class  Airline_ID  AirportFrom_ID  AirportTo_ID\n",
              "0  1296.0   141.0          1      0         6.0            17.0         130.0\n",
              "1   360.0   146.0          4      0        13.0            66.0         209.0\n",
              "2  1170.0   143.0          3      0         4.0            36.0          61.0\n",
              "3  1410.0   344.0          6      0        15.0           204.0         218.0\n",
              "4   692.0    98.0          4      0         9.0            33.0          17.0\n",
              "5   580.0    60.0          4      0        16.0           199.0          28.0\n",
              "6   690.0   239.0          4      0         5.0            97.0          81.0\n",
              "7  1210.0    80.0          3      0         2.0            81.0         178.0\n",
              "8  1295.0   105.0          7      0         9.0            46.0         120.0\n",
              "9   530.0   108.0          3      0         9.0            17.0         214.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a91762a8-b548-4a78-8a5c-2943bb29c7c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>Length</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Class</th>\n",
              "      <th>Airline_ID</th>\n",
              "      <th>AirportFrom_ID</th>\n",
              "      <th>AirportTo_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1296.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>130.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>360.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>209.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1170.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>61.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1410.0</td>\n",
              "      <td>344.0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>218.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>692.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>580.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>199.0</td>\n",
              "      <td>28.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>690.0</td>\n",
              "      <td>239.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>81.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1210.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>178.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1295.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>120.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>530.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>214.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a91762a8-b548-4a78-8a5c-2943bb29c7c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a91762a8-b548-4a78-8a5c-2943bb29c7c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a91762a8-b548-4a78-8a5c-2943bb29c7c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols = list(df.columns)\n",
        "cols = [cols[3]] + cols[:3] + cols[4:]\n",
        "df = df[cols]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kXkt3aeC26n6",
        "outputId": "33e844f4-80ab-40dc-aa17-6a682f55c2db"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Class    Time  Length  DayOfWeek  Airline_ID  AirportFrom_ID  AirportTo_ID\n",
              "0      0  1296.0   141.0          1         6.0            17.0         130.0\n",
              "1      0   360.0   146.0          4        13.0            66.0         209.0\n",
              "2      0  1170.0   143.0          3         4.0            36.0          61.0\n",
              "3      0  1410.0   344.0          6        15.0           204.0         218.0\n",
              "4      0   692.0    98.0          4         9.0            33.0          17.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-134ba5b1-7cbd-4a6e-a832-1bfb2413a694\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>Time</th>\n",
              "      <th>Length</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Airline_ID</th>\n",
              "      <th>AirportFrom_ID</th>\n",
              "      <th>AirportTo_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1296.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>130.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>4</td>\n",
              "      <td>13.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>209.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1170.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>61.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1410.0</td>\n",
              "      <td>344.0</td>\n",
              "      <td>6</td>\n",
              "      <td>15.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>218.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>692.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>4</td>\n",
              "      <td>9.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-134ba5b1-7cbd-4a6e-a832-1bfb2413a694')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-134ba5b1-7cbd-4a6e-a832-1bfb2413a694 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-134ba5b1-7cbd-4a6e-a832-1bfb2413a694');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df, test_size=0.35, random_state = 40)\n",
        "print(\"Training Data :\", train.shape)\n",
        "print(\"Testing Data :\", test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoDEcX8EntyR",
        "outputId": "032ff7a4-7dd0-4bc4-d4a5-3707a7b8dc8a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data : (350598, 7)\n",
            "Testing Data : (188784, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JYFa0jHDoEYn",
        "outputId": "bec3f37d-48b3-465a-801c-6fee2ea09074"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Class    Time  Length  DayOfWeek  Airline_ID  AirportFrom_ID  \\\n",
              "263031      1  1063.0   118.0          7        14.0           154.0   \n",
              "97712       1  1330.0   292.0          7        15.0           155.0   \n",
              "536842      1   570.0   165.0          5        16.0            80.0   \n",
              "237511      0   650.0   620.0          1         6.0            17.0   \n",
              "261014      1   510.0   160.0          2        16.0            46.0   \n",
              "\n",
              "        AirportTo_ID  \n",
              "263031          80.0  \n",
              "97712          217.0  \n",
              "536842         203.0  \n",
              "237511         129.0  \n",
              "261014         105.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93a53a6f-daeb-4f7d-951b-ec600ab12a3d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>Time</th>\n",
              "      <th>Length</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Airline_ID</th>\n",
              "      <th>AirportFrom_ID</th>\n",
              "      <th>AirportTo_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>263031</th>\n",
              "      <td>1</td>\n",
              "      <td>1063.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>7</td>\n",
              "      <td>14.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>80.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97712</th>\n",
              "      <td>1</td>\n",
              "      <td>1330.0</td>\n",
              "      <td>292.0</td>\n",
              "      <td>7</td>\n",
              "      <td>15.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>217.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>536842</th>\n",
              "      <td>1</td>\n",
              "      <td>570.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>5</td>\n",
              "      <td>16.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>203.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237511</th>\n",
              "      <td>0</td>\n",
              "      <td>650.0</td>\n",
              "      <td>620.0</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>129.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261014</th>\n",
              "      <td>1</td>\n",
              "      <td>510.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>2</td>\n",
              "      <td>16.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>105.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93a53a6f-daeb-4f7d-951b-ec600ab12a3d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-93a53a6f-daeb-4f7d-951b-ec600ab12a3d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-93a53a6f-daeb-4f7d-951b-ec600ab12a3d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MOCwZRFdoI_p",
        "outputId": "d1fbf6fe-71f4-49f0-a2e2-8fc858b3af9f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Class    Time  Length  DayOfWeek  Airline_ID  AirportFrom_ID  \\\n",
              "309672      1  1152.0    77.0          1         7.0            17.0   \n",
              "386273      0  1180.0    79.0          7         6.0           178.0   \n",
              "350725      0   695.0    80.0          1         7.0           288.0   \n",
              "69486       0   925.0   110.0          3        11.0           286.0   \n",
              "417318      1   510.0    80.0          5        11.0            81.0   \n",
              "\n",
              "        AirportTo_ID  \n",
              "309672         116.0  \n",
              "386273         199.0  \n",
              "350725          17.0  \n",
              "69486          209.0  \n",
              "417318          42.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e0c9027b-a16c-488b-a288-92f84bbb4ea8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>Time</th>\n",
              "      <th>Length</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Airline_ID</th>\n",
              "      <th>AirportFrom_ID</th>\n",
              "      <th>AirportTo_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>309672</th>\n",
              "      <td>1</td>\n",
              "      <td>1152.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>116.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386273</th>\n",
              "      <td>0</td>\n",
              "      <td>1180.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>7</td>\n",
              "      <td>6.0</td>\n",
              "      <td>178.0</td>\n",
              "      <td>199.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350725</th>\n",
              "      <td>0</td>\n",
              "      <td>695.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69486</th>\n",
              "      <td>0</td>\n",
              "      <td>925.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>3</td>\n",
              "      <td>11.0</td>\n",
              "      <td>286.0</td>\n",
              "      <td>209.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417318</th>\n",
              "      <td>1</td>\n",
              "      <td>510.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>5</td>\n",
              "      <td>11.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>42.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e0c9027b-a16c-488b-a288-92f84bbb4ea8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e0c9027b-a16c-488b-a288-92f84bbb4ea8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e0c9027b-a16c-488b-a288-92f84bbb4ea8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_x = train.iloc[:,1:]\n",
        "train_df_x = MinMaxScaler().fit_transform(train_df_x)\n",
        "\n",
        "test_df_x = test.iloc[:,1:]\n",
        "test_df_x = MinMaxScaler().fit_transform(test_df_x)\n",
        "\n",
        "print(train_df_x.shape)\n",
        "print(test_df_x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa1JxXH33UwT",
        "outputId": "e0c4c92f-b825-4038-9e42-061bdfcd6de1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(350598, 6)\n",
            "(188784, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_y = train.iloc[:,:1]\n",
        "train_df_y = train_df_y.astype('float32')\n",
        "\n",
        "test_df_y = test.iloc[:,:1]\n",
        "test_df_y = test_df_y.astype('float32')\n",
        "\n",
        "print(train_df_y)\n",
        "print(test_df_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SD5wfzs3ixK",
        "outputId": "c24fdb01-43cd-4f81-df4b-99fc0a231de0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Class\n",
            "263031    1.0\n",
            "97712     1.0\n",
            "536842    1.0\n",
            "237511    0.0\n",
            "261014    1.0\n",
            "...       ...\n",
            "138911    1.0\n",
            "200211    1.0\n",
            "137031    0.0\n",
            "114369    0.0\n",
            "473253    1.0\n",
            "\n",
            "[350598 rows x 1 columns]\n",
            "        Class\n",
            "309672    1.0\n",
            "386273    0.0\n",
            "350725    0.0\n",
            "69486     0.0\n",
            "417318    1.0\n",
            "...       ...\n",
            "368001    1.0\n",
            "456113    0.0\n",
            "80011     0.0\n",
            "38202     1.0\n",
            "190758    0.0\n",
            "\n",
            "[188784 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model builder function\n",
        "class_weights = {\n",
        "    0: 1.0,\n",
        "    1: 1.15,\n",
        "}\n",
        "\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    \n",
        "    # Tune the number of neurons in the first hidden layer\n",
        "    hp_units = hp.Int('units', min_value=64, max_value=512, step=64)\n",
        "    \n",
        "    model.add(layers.Dense(units=hp_units, activation='relu', input_shape=(6,), bias_initializer='random_normal'))\n",
        "    \n",
        "    # Tune the learning rate for the optimizer\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "    \n",
        "    model.add(layers.Dense(units=10, activation='relu', bias_initializer='random_normal'))\n",
        "    model.add(layers.Dense(units=1, activation='sigmoid', bias_initializer='random_normal'))\n",
        "    \n",
        "    # Compile the model with binary cross-entropy loss and Adam optimizer, and add precision, recall, and F1 score to the metrics\n",
        "    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(hp_learning_rate), metrics=['accuracy', Precision(), Recall()])\n",
        "    \n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Initialize the random search tuner with the model builder function and the hyperparameter search space\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=3,\n",
        "    directory='tuner_results',\n",
        "    project_name='my_model')\n",
        "\n",
        "# Search for the best hyperparameters\n",
        "tuner.search(train_df_x, train_df_y, epochs=200, batch_size=750, class_weight=class_weights, validation_data=(test_df_x, test_df_y))\n",
        "\n",
        "# Print the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print('Number of units in the first hidden layer: {}'.format(best_hps.get('units')))\n",
        "print('Learning rate: {}'.format(best_hps.get('learning_rate')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaBgMNp_ZSn-",
        "outputId": "7ec70cda-2737-4f3b-f778-65fd912d60c3"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 33m 04s]\n",
            "val_accuracy: 0.644837478796641\n",
            "\n",
            "Best val_accuracy So Far: 0.644837478796641\n",
            "Total elapsed time: 02h 32m 57s\n",
            "Number of units in the first hidden layer: 448\n",
            "Learning rate: 0.0001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights = {\n",
        "    0: 1.0,\n",
        "    1: 1.1965,\n",
        "}\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(448, activation='relu', input_shape = (6,), bias_initializer = 'random_normal'),\n",
        "    tf.keras.layers.Dense(15, activation='relu', bias_initializer='random_normal'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid', bias_initializer='random_normal')\n",
        "])"
      ],
      "metadata": {
        "id": "eaIwPT5jo13g"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model with binary cross-entropy loss and Adam optimizer, and add precision, recall score to the metrics\n",
        "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', Precision(), Recall()])\n",
        "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.001), metrics=['accuracy', Precision(), Recall()])\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10)\n",
        "\n",
        "\n",
        "# train the model using the training set\n",
        "history = model.fit(train_df_x, train_df_y, epochs=500, batch_size=1000, class_weight=class_weights, validation_data=(test_df_x, test_df_y))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_df_x, test_df_y, verbose=0)\n",
        "\n",
        "# Print the results\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_accuracy)\n",
        "print('Test Precision:', test_precision)\n",
        "print('Test Recall:', test_recall)"
      ],
      "metadata": {
        "id": "lEwy6Rkb6Hhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c5d2160-dab1-4387-aff9-7ec5b18eda4b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "351/351 [==============================] - 4s 7ms/step - loss: 0.7344 - accuracy: 0.5748 - precision_5: 0.5202 - recall_5: 0.5843 - val_loss: 0.6683 - val_accuracy: 0.5829 - val_precision_5: 0.5281 - val_recall_5: 0.5966\n",
            "Epoch 2/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.7282 - accuracy: 0.5841 - precision_5: 0.5285 - recall_5: 0.6134 - val_loss: 0.6686 - val_accuracy: 0.5838 - val_precision_5: 0.5250 - val_recall_5: 0.6890\n",
            "Epoch 3/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.7245 - accuracy: 0.5930 - precision_5: 0.5386 - recall_5: 0.6019 - val_loss: 0.6684 - val_accuracy: 0.5897 - val_precision_5: 0.5306 - val_recall_5: 0.6851\n",
            "Epoch 4/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.7218 - accuracy: 0.5980 - precision_5: 0.5449 - recall_5: 0.5926 - val_loss: 0.6590 - val_accuracy: 0.6039 - val_precision_5: 0.5520 - val_recall_5: 0.5886\n",
            "Epoch 5/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.7196 - accuracy: 0.6006 - precision_5: 0.5485 - recall_5: 0.5844 - val_loss: 0.6641 - val_accuracy: 0.5912 - val_precision_5: 0.5319 - val_recall_5: 0.6861\n",
            "Epoch 6/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.7175 - accuracy: 0.6030 - precision_5: 0.5516 - recall_5: 0.5814 - val_loss: 0.6551 - val_accuracy: 0.6073 - val_precision_5: 0.5568 - val_recall_5: 0.5809\n",
            "Epoch 7/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.7151 - accuracy: 0.6048 - precision_5: 0.5536 - recall_5: 0.5825 - val_loss: 0.6538 - val_accuracy: 0.6091 - val_precision_5: 0.5602 - val_recall_5: 0.5694\n",
            "Epoch 8/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.7121 - accuracy: 0.6081 - precision_5: 0.5579 - recall_5: 0.5792 - val_loss: 0.6523 - val_accuracy: 0.6072 - val_precision_5: 0.5523 - val_recall_5: 0.6245\n",
            "Epoch 9/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.7085 - accuracy: 0.6114 - precision_5: 0.5619 - recall_5: 0.5797 - val_loss: 0.6482 - val_accuracy: 0.6128 - val_precision_5: 0.5597 - val_recall_5: 0.6126\n",
            "Epoch 10/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.7041 - accuracy: 0.6163 - precision_5: 0.5690 - recall_5: 0.5716 - val_loss: 0.6410 - val_accuracy: 0.6240 - val_precision_5: 0.5847 - val_recall_5: 0.5387\n",
            "Epoch 11/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.7006 - accuracy: 0.6211 - precision_5: 0.5762 - recall_5: 0.5651 - val_loss: 0.6404 - val_accuracy: 0.6245 - val_precision_5: 0.5796 - val_recall_5: 0.5715\n",
            "Epoch 12/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6976 - accuracy: 0.6238 - precision_5: 0.5804 - recall_5: 0.5609 - val_loss: 0.6393 - val_accuracy: 0.6245 - val_precision_5: 0.5789 - val_recall_5: 0.5764\n",
            "Epoch 13/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6959 - accuracy: 0.6262 - precision_5: 0.5845 - recall_5: 0.5563 - val_loss: 0.6362 - val_accuracy: 0.6303 - val_precision_5: 0.5914 - val_recall_5: 0.5502\n",
            "Epoch 14/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6950 - accuracy: 0.6277 - precision_5: 0.5881 - recall_5: 0.5481 - val_loss: 0.6354 - val_accuracy: 0.6310 - val_precision_5: 0.5913 - val_recall_5: 0.5558\n",
            "Epoch 15/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6943 - accuracy: 0.6297 - precision_5: 0.5914 - recall_5: 0.5455 - val_loss: 0.6315 - val_accuracy: 0.6412 - val_precision_5: 0.6407 - val_recall_5: 0.4427\n",
            "Epoch 16/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6939 - accuracy: 0.6304 - precision_5: 0.5936 - recall_5: 0.5401 - val_loss: 0.6378 - val_accuracy: 0.6296 - val_precision_5: 0.5850 - val_recall_5: 0.5796\n",
            "Epoch 17/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6937 - accuracy: 0.6323 - precision_5: 0.5963 - recall_5: 0.5402 - val_loss: 0.6384 - val_accuracy: 0.6272 - val_precision_5: 0.5817 - val_recall_5: 0.5809\n",
            "Epoch 18/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6929 - accuracy: 0.6330 - precision_5: 0.5973 - recall_5: 0.5401 - val_loss: 0.6350 - val_accuracy: 0.6377 - val_precision_5: 0.6110 - val_recall_5: 0.5142\n",
            "Epoch 19/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6925 - accuracy: 0.6342 - precision_5: 0.5998 - recall_5: 0.5374 - val_loss: 0.6317 - val_accuracy: 0.6404 - val_precision_5: 0.6155 - val_recall_5: 0.5136\n",
            "Epoch 20/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6920 - accuracy: 0.6352 - precision_5: 0.6012 - recall_5: 0.5373 - val_loss: 0.6308 - val_accuracy: 0.6413 - val_precision_5: 0.6314 - val_recall_5: 0.4677\n",
            "Epoch 21/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6919 - accuracy: 0.6344 - precision_5: 0.5999 - recall_5: 0.5384 - val_loss: 0.6318 - val_accuracy: 0.6401 - val_precision_5: 0.6122 - val_recall_5: 0.5239\n",
            "Epoch 22/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6917 - accuracy: 0.6351 - precision_5: 0.6004 - recall_5: 0.5408 - val_loss: 0.6308 - val_accuracy: 0.6417 - val_precision_5: 0.6237 - val_recall_5: 0.4933\n",
            "Epoch 23/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6910 - accuracy: 0.6370 - precision_5: 0.6034 - recall_5: 0.5396 - val_loss: 0.6365 - val_accuracy: 0.6350 - val_precision_5: 0.5920 - val_recall_5: 0.5808\n",
            "Epoch 24/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6908 - accuracy: 0.6368 - precision_5: 0.6024 - recall_5: 0.5433 - val_loss: 0.6329 - val_accuracy: 0.6370 - val_precision_5: 0.6011 - val_recall_5: 0.5504\n",
            "Epoch 25/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6908 - accuracy: 0.6362 - precision_5: 0.6013 - recall_5: 0.5442 - val_loss: 0.6306 - val_accuracy: 0.6421 - val_precision_5: 0.6393 - val_recall_5: 0.4511\n",
            "Epoch 26/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6906 - accuracy: 0.6369 - precision_5: 0.6026 - recall_5: 0.5431 - val_loss: 0.6394 - val_accuracy: 0.6267 - val_precision_5: 0.5723 - val_recall_5: 0.6411\n",
            "Epoch 27/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6900 - accuracy: 0.6373 - precision_5: 0.6028 - recall_5: 0.5447 - val_loss: 0.6370 - val_accuracy: 0.6310 - val_precision_5: 0.5817 - val_recall_5: 0.6112\n",
            "Epoch 28/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6900 - accuracy: 0.6372 - precision_5: 0.6020 - recall_5: 0.5476 - val_loss: 0.6311 - val_accuracy: 0.6431 - val_precision_5: 0.6166 - val_recall_5: 0.5260\n",
            "Epoch 29/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6895 - accuracy: 0.6376 - precision_5: 0.6029 - recall_5: 0.5462 - val_loss: 0.6326 - val_accuracy: 0.6381 - val_precision_5: 0.5980 - val_recall_5: 0.5726\n",
            "Epoch 30/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6897 - accuracy: 0.6378 - precision_5: 0.6029 - recall_5: 0.5474 - val_loss: 0.6297 - val_accuracy: 0.6427 - val_precision_5: 0.6253 - val_recall_5: 0.4937\n",
            "Epoch 31/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6894 - accuracy: 0.6388 - precision_5: 0.6042 - recall_5: 0.5486 - val_loss: 0.6339 - val_accuracy: 0.6363 - val_precision_5: 0.5918 - val_recall_5: 0.5912\n",
            "Epoch 32/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6898 - accuracy: 0.6375 - precision_5: 0.6013 - recall_5: 0.5527 - val_loss: 0.6276 - val_accuracy: 0.6470 - val_precision_5: 0.6487 - val_recall_5: 0.4527\n",
            "Epoch 33/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6889 - accuracy: 0.6385 - precision_5: 0.6036 - recall_5: 0.5485 - val_loss: 0.6320 - val_accuracy: 0.6395 - val_precision_5: 0.6031 - val_recall_5: 0.5580\n",
            "Epoch 34/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6888 - accuracy: 0.6395 - precision_5: 0.6045 - recall_5: 0.5515 - val_loss: 0.6305 - val_accuracy: 0.6418 - val_precision_5: 0.6087 - val_recall_5: 0.5485\n",
            "Epoch 35/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6887 - accuracy: 0.6394 - precision_5: 0.6045 - recall_5: 0.5511 - val_loss: 0.6284 - val_accuracy: 0.6456 - val_precision_5: 0.6259 - val_recall_5: 0.5084\n",
            "Epoch 36/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6883 - accuracy: 0.6391 - precision_5: 0.6037 - recall_5: 0.5525 - val_loss: 0.6283 - val_accuracy: 0.6463 - val_precision_5: 0.6336 - val_recall_5: 0.4886\n",
            "Epoch 37/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6884 - accuracy: 0.6390 - precision_5: 0.6038 - recall_5: 0.5517 - val_loss: 0.6302 - val_accuracy: 0.6426 - val_precision_5: 0.6087 - val_recall_5: 0.5537\n",
            "Epoch 38/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6886 - accuracy: 0.6387 - precision_5: 0.6036 - recall_5: 0.5501 - val_loss: 0.6320 - val_accuracy: 0.6405 - val_precision_5: 0.6031 - val_recall_5: 0.5641\n",
            "Epoch 39/500\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6884 - accuracy: 0.6389 - precision_5: 0.6032 - recall_5: 0.5534 - val_loss: 0.6346 - val_accuracy: 0.6350 - val_precision_5: 0.5873 - val_recall_5: 0.6077\n",
            "Epoch 40/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6879 - accuracy: 0.6402 - precision_5: 0.6052 - recall_5: 0.5528 - val_loss: 0.6297 - val_accuracy: 0.6423 - val_precision_5: 0.6090 - val_recall_5: 0.5506\n",
            "Epoch 41/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6879 - accuracy: 0.6400 - precision_5: 0.6051 - recall_5: 0.5517 - val_loss: 0.6324 - val_accuracy: 0.6389 - val_precision_5: 0.5961 - val_recall_5: 0.5871\n",
            "Epoch 42/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6878 - accuracy: 0.6398 - precision_5: 0.6043 - recall_5: 0.5545 - val_loss: 0.6276 - val_accuracy: 0.6465 - val_precision_5: 0.6331 - val_recall_5: 0.4911\n",
            "Epoch 43/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6878 - accuracy: 0.6401 - precision_5: 0.6049 - recall_5: 0.5539 - val_loss: 0.6301 - val_accuracy: 0.6425 - val_precision_5: 0.6049 - val_recall_5: 0.5695\n",
            "Epoch 44/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6877 - accuracy: 0.6400 - precision_5: 0.6043 - recall_5: 0.5560 - val_loss: 0.6271 - val_accuracy: 0.6474 - val_precision_5: 0.6464 - val_recall_5: 0.4603\n",
            "Epoch 45/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6876 - accuracy: 0.6403 - precision_5: 0.6047 - recall_5: 0.5555 - val_loss: 0.6343 - val_accuracy: 0.6354 - val_precision_5: 0.5877 - val_recall_5: 0.6080\n",
            "Epoch 46/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6875 - accuracy: 0.6406 - precision_5: 0.6050 - recall_5: 0.5565 - val_loss: 0.6273 - val_accuracy: 0.6459 - val_precision_5: 0.6317 - val_recall_5: 0.4915\n",
            "Epoch 47/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6875 - accuracy: 0.6407 - precision_5: 0.6054 - recall_5: 0.5553 - val_loss: 0.6306 - val_accuracy: 0.6426 - val_precision_5: 0.6083 - val_recall_5: 0.5551\n",
            "Epoch 48/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6872 - accuracy: 0.6412 - precision_5: 0.6061 - recall_5: 0.5557 - val_loss: 0.6342 - val_accuracy: 0.6379 - val_precision_5: 0.5922 - val_recall_5: 0.6005\n",
            "Epoch 49/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6874 - accuracy: 0.6409 - precision_5: 0.6053 - recall_5: 0.5571 - val_loss: 0.6341 - val_accuracy: 0.6382 - val_precision_5: 0.5949 - val_recall_5: 0.5888\n",
            "Epoch 50/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6870 - accuracy: 0.6414 - precision_5: 0.6065 - recall_5: 0.5549 - val_loss: 0.6303 - val_accuracy: 0.6416 - val_precision_5: 0.6075 - val_recall_5: 0.5523\n",
            "Epoch 51/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6870 - accuracy: 0.6414 - precision_5: 0.6061 - recall_5: 0.5569 - val_loss: 0.6350 - val_accuracy: 0.6354 - val_precision_5: 0.5870 - val_recall_5: 0.6122\n",
            "Epoch 52/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6870 - accuracy: 0.6405 - precision_5: 0.6050 - recall_5: 0.5555 - val_loss: 0.6299 - val_accuracy: 0.6413 - val_precision_5: 0.6038 - val_recall_5: 0.5667\n",
            "Epoch 53/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6868 - accuracy: 0.6417 - precision_5: 0.6065 - recall_5: 0.5573 - val_loss: 0.6321 - val_accuracy: 0.6382 - val_precision_5: 0.5924 - val_recall_5: 0.6018\n",
            "Epoch 54/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6867 - accuracy: 0.6416 - precision_5: 0.6060 - recall_5: 0.5583 - val_loss: 0.6271 - val_accuracy: 0.6468 - val_precision_5: 0.6258 - val_recall_5: 0.5154\n",
            "Epoch 55/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6867 - accuracy: 0.6412 - precision_5: 0.6054 - recall_5: 0.5581 - val_loss: 0.6285 - val_accuracy: 0.6434 - val_precision_5: 0.6146 - val_recall_5: 0.5348\n",
            "Epoch 56/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6866 - accuracy: 0.6415 - precision_5: 0.6061 - recall_5: 0.5573 - val_loss: 0.6316 - val_accuracy: 0.6414 - val_precision_5: 0.6057 - val_recall_5: 0.5584\n",
            "Epoch 57/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6863 - accuracy: 0.6423 - precision_5: 0.6073 - recall_5: 0.5575 - val_loss: 0.6297 - val_accuracy: 0.6440 - val_precision_5: 0.6134 - val_recall_5: 0.5431\n",
            "Epoch 58/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6868 - accuracy: 0.6411 - precision_5: 0.6049 - recall_5: 0.5600 - val_loss: 0.6303 - val_accuracy: 0.6426 - val_precision_5: 0.6057 - val_recall_5: 0.5663\n",
            "Epoch 59/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6862 - accuracy: 0.6421 - precision_5: 0.6067 - recall_5: 0.5588 - val_loss: 0.6294 - val_accuracy: 0.6436 - val_precision_5: 0.6081 - val_recall_5: 0.5626\n",
            "Epoch 60/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6864 - accuracy: 0.6411 - precision_5: 0.6052 - recall_5: 0.5588 - val_loss: 0.6373 - val_accuracy: 0.6288 - val_precision_5: 0.5745 - val_recall_5: 0.6428\n",
            "Epoch 61/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6864 - accuracy: 0.6422 - precision_5: 0.6063 - recall_5: 0.5612 - val_loss: 0.6314 - val_accuracy: 0.6420 - val_precision_5: 0.6040 - val_recall_5: 0.5704\n",
            "Epoch 62/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6861 - accuracy: 0.6419 - precision_5: 0.6061 - recall_5: 0.5600 - val_loss: 0.6343 - val_accuracy: 0.6362 - val_precision_5: 0.5881 - val_recall_5: 0.6124\n",
            "Epoch 63/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6860 - accuracy: 0.6423 - precision_5: 0.6066 - recall_5: 0.5604 - val_loss: 0.6299 - val_accuracy: 0.6423 - val_precision_5: 0.6046 - val_recall_5: 0.5692\n",
            "Epoch 64/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6860 - accuracy: 0.6423 - precision_5: 0.6070 - recall_5: 0.5591 - val_loss: 0.6330 - val_accuracy: 0.6396 - val_precision_5: 0.5948 - val_recall_5: 0.5986\n",
            "Epoch 65/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6859 - accuracy: 0.6422 - precision_5: 0.6064 - recall_5: 0.5608 - val_loss: 0.6281 - val_accuracy: 0.6449 - val_precision_5: 0.6207 - val_recall_5: 0.5215\n",
            "Epoch 66/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6859 - accuracy: 0.6420 - precision_5: 0.6062 - recall_5: 0.5601 - val_loss: 0.6302 - val_accuracy: 0.6430 - val_precision_5: 0.6068 - val_recall_5: 0.5639\n",
            "Epoch 67/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6860 - accuracy: 0.6417 - precision_5: 0.6057 - recall_5: 0.5608 - val_loss: 0.6315 - val_accuracy: 0.6416 - val_precision_5: 0.6005 - val_recall_5: 0.5837\n",
            "Epoch 68/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6858 - accuracy: 0.6421 - precision_5: 0.6059 - recall_5: 0.5621 - val_loss: 0.6265 - val_accuracy: 0.6463 - val_precision_5: 0.6317 - val_recall_5: 0.4938\n",
            "Epoch 69/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6857 - accuracy: 0.6427 - precision_5: 0.6072 - recall_5: 0.5604 - val_loss: 0.6330 - val_accuracy: 0.6404 - val_precision_5: 0.5983 - val_recall_5: 0.5865\n",
            "Epoch 70/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6858 - accuracy: 0.6418 - precision_5: 0.6061 - recall_5: 0.5595 - val_loss: 0.6308 - val_accuracy: 0.6399 - val_precision_5: 0.6000 - val_recall_5: 0.5754\n",
            "Epoch 71/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6855 - accuracy: 0.6425 - precision_5: 0.6067 - recall_5: 0.5614 - val_loss: 0.6316 - val_accuracy: 0.6383 - val_precision_5: 0.5958 - val_recall_5: 0.5846\n",
            "Epoch 72/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6855 - accuracy: 0.6431 - precision_5: 0.6079 - recall_5: 0.5602 - val_loss: 0.6253 - val_accuracy: 0.6488 - val_precision_5: 0.6503 - val_recall_5: 0.4575\n",
            "Epoch 73/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6853 - accuracy: 0.6433 - precision_5: 0.6084 - recall_5: 0.5590 - val_loss: 0.6309 - val_accuracy: 0.6411 - val_precision_5: 0.5970 - val_recall_5: 0.5978\n",
            "Epoch 74/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6853 - accuracy: 0.6432 - precision_5: 0.6074 - recall_5: 0.5623 - val_loss: 0.6265 - val_accuracy: 0.6473 - val_precision_5: 0.6262 - val_recall_5: 0.5166\n",
            "Epoch 75/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6850 - accuracy: 0.6434 - precision_5: 0.6081 - recall_5: 0.5611 - val_loss: 0.6281 - val_accuracy: 0.6448 - val_precision_5: 0.6210 - val_recall_5: 0.5199\n",
            "Epoch 76/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6855 - accuracy: 0.6424 - precision_5: 0.6068 - recall_5: 0.5604 - val_loss: 0.6305 - val_accuracy: 0.6417 - val_precision_5: 0.6015 - val_recall_5: 0.5796\n",
            "Epoch 77/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6854 - accuracy: 0.6434 - precision_5: 0.6078 - recall_5: 0.5622 - val_loss: 0.6315 - val_accuracy: 0.6393 - val_precision_5: 0.5952 - val_recall_5: 0.5947\n",
            "Epoch 78/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6852 - accuracy: 0.6431 - precision_5: 0.6076 - recall_5: 0.5611 - val_loss: 0.6290 - val_accuracy: 0.6424 - val_precision_5: 0.6061 - val_recall_5: 0.5635\n",
            "Epoch 79/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6851 - accuracy: 0.6434 - precision_5: 0.6079 - recall_5: 0.5619 - val_loss: 0.6283 - val_accuracy: 0.6440 - val_precision_5: 0.6135 - val_recall_5: 0.5426\n",
            "Epoch 80/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6849 - accuracy: 0.6439 - precision_5: 0.6086 - recall_5: 0.5617 - val_loss: 0.6263 - val_accuracy: 0.6478 - val_precision_5: 0.6288 - val_recall_5: 0.5107\n",
            "Epoch 81/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6851 - accuracy: 0.6439 - precision_5: 0.6090 - recall_5: 0.5603 - val_loss: 0.6311 - val_accuracy: 0.6406 - val_precision_5: 0.5964 - val_recall_5: 0.5976\n",
            "Epoch 82/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6853 - accuracy: 0.6425 - precision_5: 0.6067 - recall_5: 0.5612 - val_loss: 0.6269 - val_accuracy: 0.6469 - val_precision_5: 0.6232 - val_recall_5: 0.5240\n",
            "Epoch 83/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6846 - accuracy: 0.6439 - precision_5: 0.6087 - recall_5: 0.5614 - val_loss: 0.6289 - val_accuracy: 0.6431 - val_precision_5: 0.6076 - val_recall_5: 0.5613\n",
            "Epoch 84/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6847 - accuracy: 0.6439 - precision_5: 0.6087 - recall_5: 0.5619 - val_loss: 0.6298 - val_accuracy: 0.6403 - val_precision_5: 0.6004 - val_recall_5: 0.5755\n",
            "Epoch 85/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6849 - accuracy: 0.6434 - precision_5: 0.6080 - recall_5: 0.5615 - val_loss: 0.6318 - val_accuracy: 0.6407 - val_precision_5: 0.5986 - val_recall_5: 0.5872\n",
            "Epoch 86/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6846 - accuracy: 0.6442 - precision_5: 0.6090 - recall_5: 0.5624 - val_loss: 0.6269 - val_accuracy: 0.6463 - val_precision_5: 0.6193 - val_recall_5: 0.5348\n",
            "Epoch 87/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6847 - accuracy: 0.6433 - precision_5: 0.6076 - recall_5: 0.5621 - val_loss: 0.6354 - val_accuracy: 0.6331 - val_precision_5: 0.5804 - val_recall_5: 0.6365\n",
            "Epoch 88/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6848 - accuracy: 0.6437 - precision_5: 0.6079 - recall_5: 0.5635 - val_loss: 0.6260 - val_accuracy: 0.6483 - val_precision_5: 0.6376 - val_recall_5: 0.4874\n",
            "Epoch 89/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6847 - accuracy: 0.6438 - precision_5: 0.6083 - recall_5: 0.5627 - val_loss: 0.6266 - val_accuracy: 0.6468 - val_precision_5: 0.6221 - val_recall_5: 0.5275\n",
            "Epoch 90/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6846 - accuracy: 0.6446 - precision_5: 0.6093 - recall_5: 0.5632 - val_loss: 0.6288 - val_accuracy: 0.6428 - val_precision_5: 0.6024 - val_recall_5: 0.5826\n",
            "Epoch 91/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6846 - accuracy: 0.6443 - precision_5: 0.6087 - recall_5: 0.5639 - val_loss: 0.6276 - val_accuracy: 0.6459 - val_precision_5: 0.6172 - val_recall_5: 0.5399\n",
            "Epoch 92/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6844 - accuracy: 0.6438 - precision_5: 0.6077 - recall_5: 0.5652 - val_loss: 0.6260 - val_accuracy: 0.6468 - val_precision_5: 0.6232 - val_recall_5: 0.5238\n",
            "Epoch 93/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6845 - accuracy: 0.6438 - precision_5: 0.6081 - recall_5: 0.5633 - val_loss: 0.6248 - val_accuracy: 0.6485 - val_precision_5: 0.6365 - val_recall_5: 0.4920\n",
            "Epoch 94/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6848 - accuracy: 0.6436 - precision_5: 0.6083 - recall_5: 0.5614 - val_loss: 0.6318 - val_accuracy: 0.6395 - val_precision_5: 0.5933 - val_recall_5: 0.6063\n",
            "Epoch 95/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6840 - accuracy: 0.6452 - precision_5: 0.6103 - recall_5: 0.5629 - val_loss: 0.6317 - val_accuracy: 0.6390 - val_precision_5: 0.5932 - val_recall_5: 0.6037\n",
            "Epoch 96/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6845 - accuracy: 0.6440 - precision_5: 0.6082 - recall_5: 0.5642 - val_loss: 0.6260 - val_accuracy: 0.6476 - val_precision_5: 0.6287 - val_recall_5: 0.5105\n",
            "Epoch 97/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6843 - accuracy: 0.6439 - precision_5: 0.6082 - recall_5: 0.5633 - val_loss: 0.6268 - val_accuracy: 0.6468 - val_precision_5: 0.6206 - val_recall_5: 0.5333\n",
            "Epoch 98/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6845 - accuracy: 0.6438 - precision_5: 0.6083 - recall_5: 0.5627 - val_loss: 0.6257 - val_accuracy: 0.6479 - val_precision_5: 0.6312 - val_recall_5: 0.5044\n",
            "Epoch 99/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6840 - accuracy: 0.6445 - precision_5: 0.6090 - recall_5: 0.5643 - val_loss: 0.6326 - val_accuracy: 0.6377 - val_precision_5: 0.5890 - val_recall_5: 0.6176\n",
            "Epoch 100/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6840 - accuracy: 0.6442 - precision_5: 0.6087 - recall_5: 0.5636 - val_loss: 0.6277 - val_accuracy: 0.6449 - val_precision_5: 0.6123 - val_recall_5: 0.5532\n",
            "Epoch 101/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6841 - accuracy: 0.6442 - precision_5: 0.6081 - recall_5: 0.5659 - val_loss: 0.6275 - val_accuracy: 0.6459 - val_precision_5: 0.6176 - val_recall_5: 0.5386\n",
            "Epoch 102/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6843 - accuracy: 0.6441 - precision_5: 0.6088 - recall_5: 0.5624 - val_loss: 0.6352 - val_accuracy: 0.6363 - val_precision_5: 0.5883 - val_recall_5: 0.6115\n",
            "Epoch 103/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6839 - accuracy: 0.6449 - precision_5: 0.6094 - recall_5: 0.5648 - val_loss: 0.6289 - val_accuracy: 0.6436 - val_precision_5: 0.6053 - val_recall_5: 0.5747\n",
            "Epoch 104/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6840 - accuracy: 0.6445 - precision_5: 0.6086 - recall_5: 0.5657 - val_loss: 0.6262 - val_accuracy: 0.6462 - val_precision_5: 0.6252 - val_recall_5: 0.5137\n",
            "Epoch 105/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6837 - accuracy: 0.6447 - precision_5: 0.6095 - recall_5: 0.5634 - val_loss: 0.6335 - val_accuracy: 0.6376 - val_precision_5: 0.5890 - val_recall_5: 0.6171\n",
            "Epoch 106/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6838 - accuracy: 0.6446 - precision_5: 0.6089 - recall_5: 0.5650 - val_loss: 0.6265 - val_accuracy: 0.6454 - val_precision_5: 0.6150 - val_recall_5: 0.5455\n",
            "Epoch 107/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6840 - accuracy: 0.6444 - precision_5: 0.6083 - recall_5: 0.5664 - val_loss: 0.6300 - val_accuracy: 0.6421 - val_precision_5: 0.6030 - val_recall_5: 0.5749\n",
            "Epoch 108/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6839 - accuracy: 0.6445 - precision_5: 0.6089 - recall_5: 0.5644 - val_loss: 0.6259 - val_accuracy: 0.6470 - val_precision_5: 0.6268 - val_recall_5: 0.5132\n",
            "Epoch 109/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6839 - accuracy: 0.6445 - precision_5: 0.6092 - recall_5: 0.5629 - val_loss: 0.6260 - val_accuracy: 0.6468 - val_precision_5: 0.6208 - val_recall_5: 0.5320\n",
            "Epoch 110/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6838 - accuracy: 0.6444 - precision_5: 0.6086 - recall_5: 0.5649 - val_loss: 0.6324 - val_accuracy: 0.6368 - val_precision_5: 0.5888 - val_recall_5: 0.6122\n",
            "Epoch 111/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6841 - accuracy: 0.6442 - precision_5: 0.6086 - recall_5: 0.5643 - val_loss: 0.6304 - val_accuracy: 0.6409 - val_precision_5: 0.5958 - val_recall_5: 0.6031\n",
            "Epoch 112/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6837 - accuracy: 0.6447 - precision_5: 0.6092 - recall_5: 0.5644 - val_loss: 0.6265 - val_accuracy: 0.6474 - val_precision_5: 0.6240 - val_recall_5: 0.5241\n",
            "Epoch 113/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6838 - accuracy: 0.6442 - precision_5: 0.6081 - recall_5: 0.5664 - val_loss: 0.6271 - val_accuracy: 0.6476 - val_precision_5: 0.6198 - val_recall_5: 0.5405\n",
            "Epoch 114/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6834 - accuracy: 0.6452 - precision_5: 0.6099 - recall_5: 0.5646 - val_loss: 0.6275 - val_accuracy: 0.6440 - val_precision_5: 0.6091 - val_recall_5: 0.5609\n",
            "Epoch 115/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6833 - accuracy: 0.6458 - precision_5: 0.6103 - recall_5: 0.5663 - val_loss: 0.6286 - val_accuracy: 0.6431 - val_precision_5: 0.6043 - val_recall_5: 0.5762\n",
            "Epoch 116/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6837 - accuracy: 0.6452 - precision_5: 0.6097 - recall_5: 0.5651 - val_loss: 0.6274 - val_accuracy: 0.6444 - val_precision_5: 0.6087 - val_recall_5: 0.5645\n",
            "Epoch 117/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6833 - accuracy: 0.6444 - precision_5: 0.6083 - recall_5: 0.5667 - val_loss: 0.6255 - val_accuracy: 0.6479 - val_precision_5: 0.6293 - val_recall_5: 0.5100\n",
            "Epoch 118/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6835 - accuracy: 0.6446 - precision_5: 0.6091 - recall_5: 0.5640 - val_loss: 0.6259 - val_accuracy: 0.6476 - val_precision_5: 0.6216 - val_recall_5: 0.5338\n",
            "Epoch 119/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6833 - accuracy: 0.6449 - precision_5: 0.6092 - recall_5: 0.5660 - val_loss: 0.6328 - val_accuracy: 0.6396 - val_precision_5: 0.5920 - val_recall_5: 0.6147\n",
            "Epoch 120/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6833 - accuracy: 0.6452 - precision_5: 0.6098 - recall_5: 0.5650 - val_loss: 0.6328 - val_accuracy: 0.6366 - val_precision_5: 0.5857 - val_recall_5: 0.6296\n",
            "Epoch 121/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6833 - accuracy: 0.6447 - precision_5: 0.6085 - recall_5: 0.5674 - val_loss: 0.6262 - val_accuracy: 0.6467 - val_precision_5: 0.6225 - val_recall_5: 0.5261\n",
            "Epoch 122/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6834 - accuracy: 0.6445 - precision_5: 0.6089 - recall_5: 0.5647 - val_loss: 0.6295 - val_accuracy: 0.6428 - val_precision_5: 0.6027 - val_recall_5: 0.5811\n",
            "Epoch 123/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6832 - accuracy: 0.6445 - precision_5: 0.6085 - recall_5: 0.5661 - val_loss: 0.6266 - val_accuracy: 0.6470 - val_precision_5: 0.6156 - val_recall_5: 0.5530\n",
            "Epoch 124/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6832 - accuracy: 0.6455 - precision_5: 0.6102 - recall_5: 0.5656 - val_loss: 0.6273 - val_accuracy: 0.6455 - val_precision_5: 0.6157 - val_recall_5: 0.5433\n",
            "Epoch 125/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6835 - accuracy: 0.6452 - precision_5: 0.6099 - recall_5: 0.5646 - val_loss: 0.6307 - val_accuracy: 0.6399 - val_precision_5: 0.5939 - val_recall_5: 0.6063\n",
            "Epoch 126/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6830 - accuracy: 0.6453 - precision_5: 0.6096 - recall_5: 0.5666 - val_loss: 0.6293 - val_accuracy: 0.6415 - val_precision_5: 0.6023 - val_recall_5: 0.5747\n",
            "Epoch 127/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6833 - accuracy: 0.6454 - precision_5: 0.6095 - recall_5: 0.5674 - val_loss: 0.6262 - val_accuracy: 0.6464 - val_precision_5: 0.6230 - val_recall_5: 0.5225\n",
            "Epoch 128/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6831 - accuracy: 0.6447 - precision_5: 0.6089 - recall_5: 0.5655 - val_loss: 0.6304 - val_accuracy: 0.6413 - val_precision_5: 0.5962 - val_recall_5: 0.6037\n",
            "Epoch 129/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6834 - accuracy: 0.6449 - precision_5: 0.6087 - recall_5: 0.5679 - val_loss: 0.6319 - val_accuracy: 0.6364 - val_precision_5: 0.5887 - val_recall_5: 0.6102\n",
            "Epoch 130/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6833 - accuracy: 0.6448 - precision_5: 0.6088 - recall_5: 0.5667 - val_loss: 0.6263 - val_accuracy: 0.6471 - val_precision_5: 0.6302 - val_recall_5: 0.5026\n",
            "Epoch 131/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6829 - accuracy: 0.6453 - precision_5: 0.6096 - recall_5: 0.5665 - val_loss: 0.6265 - val_accuracy: 0.6466 - val_precision_5: 0.6257 - val_recall_5: 0.5145\n",
            "Epoch 132/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6832 - accuracy: 0.6452 - precision_5: 0.6100 - recall_5: 0.5644 - val_loss: 0.6349 - val_accuracy: 0.6334 - val_precision_5: 0.5786 - val_recall_5: 0.6510\n",
            "Epoch 133/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6828 - accuracy: 0.6459 - precision_5: 0.6098 - recall_5: 0.5690 - val_loss: 0.6251 - val_accuracy: 0.6482 - val_precision_5: 0.6483 - val_recall_5: 0.4594\n",
            "Epoch 134/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6829 - accuracy: 0.6462 - precision_5: 0.6109 - recall_5: 0.5669 - val_loss: 0.6285 - val_accuracy: 0.6428 - val_precision_5: 0.6044 - val_recall_5: 0.5736\n",
            "Epoch 135/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6827 - accuracy: 0.6465 - precision_5: 0.6114 - recall_5: 0.5661 - val_loss: 0.6305 - val_accuracy: 0.6393 - val_precision_5: 0.5930 - val_recall_5: 0.6062\n",
            "Epoch 136/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6831 - accuracy: 0.6453 - precision_5: 0.6095 - recall_5: 0.5668 - val_loss: 0.6270 - val_accuracy: 0.6459 - val_precision_5: 0.6143 - val_recall_5: 0.5515\n",
            "Epoch 137/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6830 - accuracy: 0.6455 - precision_5: 0.6097 - recall_5: 0.5677 - val_loss: 0.6272 - val_accuracy: 0.6458 - val_precision_5: 0.6120 - val_recall_5: 0.5598\n",
            "Epoch 138/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6829 - accuracy: 0.6455 - precision_5: 0.6098 - recall_5: 0.5669 - val_loss: 0.6281 - val_accuracy: 0.6439 - val_precision_5: 0.6035 - val_recall_5: 0.5845\n",
            "Epoch 139/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6829 - accuracy: 0.6446 - precision_5: 0.6087 - recall_5: 0.5664 - val_loss: 0.6255 - val_accuracy: 0.6486 - val_precision_5: 0.6299 - val_recall_5: 0.5121\n",
            "Epoch 140/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6827 - accuracy: 0.6455 - precision_5: 0.6102 - recall_5: 0.5654 - val_loss: 0.6304 - val_accuracy: 0.6417 - val_precision_5: 0.5973 - val_recall_5: 0.6006\n",
            "Epoch 141/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6825 - accuracy: 0.6459 - precision_5: 0.6099 - recall_5: 0.5685 - val_loss: 0.6283 - val_accuracy: 0.6440 - val_precision_5: 0.6047 - val_recall_5: 0.5795\n",
            "Epoch 142/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6827 - accuracy: 0.6462 - precision_5: 0.6106 - recall_5: 0.5679 - val_loss: 0.6288 - val_accuracy: 0.6426 - val_precision_5: 0.6002 - val_recall_5: 0.5920\n",
            "Epoch 143/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6828 - accuracy: 0.6454 - precision_5: 0.6097 - recall_5: 0.5668 - val_loss: 0.6320 - val_accuracy: 0.6376 - val_precision_5: 0.5881 - val_recall_5: 0.6228\n",
            "Epoch 144/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6826 - accuracy: 0.6460 - precision_5: 0.6101 - recall_5: 0.5688 - val_loss: 0.6244 - val_accuracy: 0.6492 - val_precision_5: 0.6382 - val_recall_5: 0.4907\n",
            "Epoch 145/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6827 - accuracy: 0.6461 - precision_5: 0.6103 - recall_5: 0.5689 - val_loss: 0.6302 - val_accuracy: 0.6406 - val_precision_5: 0.5958 - val_recall_5: 0.6007\n",
            "Epoch 146/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6828 - accuracy: 0.6453 - precision_5: 0.6098 - recall_5: 0.5659 - val_loss: 0.6322 - val_accuracy: 0.6387 - val_precision_5: 0.5885 - val_recall_5: 0.6284\n",
            "Epoch 147/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6824 - accuracy: 0.6462 - precision_5: 0.6107 - recall_5: 0.5672 - val_loss: 0.6261 - val_accuracy: 0.6472 - val_precision_5: 0.6201 - val_recall_5: 0.5366\n",
            "Epoch 148/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6827 - accuracy: 0.6453 - precision_5: 0.6093 - recall_5: 0.5675 - val_loss: 0.6259 - val_accuracy: 0.6477 - val_precision_5: 0.6237 - val_recall_5: 0.5268\n",
            "Epoch 149/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6822 - accuracy: 0.6464 - precision_5: 0.6115 - recall_5: 0.5658 - val_loss: 0.6301 - val_accuracy: 0.6419 - val_precision_5: 0.5977 - val_recall_5: 0.5998\n",
            "Epoch 150/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6825 - accuracy: 0.6457 - precision_5: 0.6098 - recall_5: 0.5681 - val_loss: 0.6250 - val_accuracy: 0.6489 - val_precision_5: 0.6369 - val_recall_5: 0.4925\n",
            "Epoch 151/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6826 - accuracy: 0.6458 - precision_5: 0.6099 - recall_5: 0.5681 - val_loss: 0.6264 - val_accuracy: 0.6457 - val_precision_5: 0.6134 - val_recall_5: 0.5534\n",
            "Epoch 152/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6822 - accuracy: 0.6461 - precision_5: 0.6105 - recall_5: 0.5677 - val_loss: 0.6257 - val_accuracy: 0.6475 - val_precision_5: 0.6217 - val_recall_5: 0.5331\n",
            "Epoch 153/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6823 - accuracy: 0.6465 - precision_5: 0.6109 - recall_5: 0.5687 - val_loss: 0.6297 - val_accuracy: 0.6431 - val_precision_5: 0.6029 - val_recall_5: 0.5825\n",
            "Epoch 154/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6823 - accuracy: 0.6459 - precision_5: 0.6103 - recall_5: 0.5677 - val_loss: 0.6344 - val_accuracy: 0.6372 - val_precision_5: 0.5859 - val_recall_5: 0.6330\n",
            "Epoch 155/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6825 - accuracy: 0.6460 - precision_5: 0.6101 - recall_5: 0.5687 - val_loss: 0.6274 - val_accuracy: 0.6436 - val_precision_5: 0.6062 - val_recall_5: 0.5706\n",
            "Epoch 156/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6821 - accuracy: 0.6472 - precision_5: 0.6118 - recall_5: 0.5690 - val_loss: 0.6266 - val_accuracy: 0.6470 - val_precision_5: 0.6174 - val_recall_5: 0.5455\n",
            "Epoch 157/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6825 - accuracy: 0.6457 - precision_5: 0.6099 - recall_5: 0.5679 - val_loss: 0.6256 - val_accuracy: 0.6485 - val_precision_5: 0.6250 - val_recall_5: 0.5273\n",
            "Epoch 158/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6821 - accuracy: 0.6457 - precision_5: 0.6102 - recall_5: 0.5667 - val_loss: 0.6268 - val_accuracy: 0.6467 - val_precision_5: 0.6172 - val_recall_5: 0.5446\n",
            "Epoch 159/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6821 - accuracy: 0.6457 - precision_5: 0.6098 - recall_5: 0.5681 - val_loss: 0.6282 - val_accuracy: 0.6440 - val_precision_5: 0.6062 - val_recall_5: 0.5727\n",
            "Epoch 160/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6818 - accuracy: 0.6464 - precision_5: 0.6108 - recall_5: 0.5684 - val_loss: 0.6320 - val_accuracy: 0.6393 - val_precision_5: 0.5912 - val_recall_5: 0.6163\n",
            "Epoch 161/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6820 - accuracy: 0.6475 - precision_5: 0.6122 - recall_5: 0.5693 - val_loss: 0.6308 - val_accuracy: 0.6404 - val_precision_5: 0.5932 - val_recall_5: 0.6135\n",
            "Epoch 162/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6820 - accuracy: 0.6467 - precision_5: 0.6108 - recall_5: 0.5704 - val_loss: 0.6265 - val_accuracy: 0.6466 - val_precision_5: 0.6162 - val_recall_5: 0.5483\n",
            "Epoch 163/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6822 - accuracy: 0.6461 - precision_5: 0.6100 - recall_5: 0.5700 - val_loss: 0.6261 - val_accuracy: 0.6478 - val_precision_5: 0.6279 - val_recall_5: 0.5140\n",
            "Epoch 164/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6819 - accuracy: 0.6464 - precision_5: 0.6107 - recall_5: 0.5687 - val_loss: 0.6257 - val_accuracy: 0.6467 - val_precision_5: 0.6164 - val_recall_5: 0.5476\n",
            "Epoch 165/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6821 - accuracy: 0.6461 - precision_5: 0.6106 - recall_5: 0.5673 - val_loss: 0.6285 - val_accuracy: 0.6437 - val_precision_5: 0.6022 - val_recall_5: 0.5895\n",
            "Epoch 166/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6820 - accuracy: 0.6467 - precision_5: 0.6110 - recall_5: 0.5692 - val_loss: 0.6256 - val_accuracy: 0.6482 - val_precision_5: 0.6212 - val_recall_5: 0.5388\n",
            "Epoch 167/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6819 - accuracy: 0.6467 - precision_5: 0.6109 - recall_5: 0.5695 - val_loss: 0.6258 - val_accuracy: 0.6474 - val_precision_5: 0.6165 - val_recall_5: 0.5513\n",
            "Epoch 168/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6817 - accuracy: 0.6462 - precision_5: 0.6108 - recall_5: 0.5673 - val_loss: 0.6287 - val_accuracy: 0.6435 - val_precision_5: 0.6059 - val_recall_5: 0.5713\n",
            "Epoch 169/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6816 - accuracy: 0.6474 - precision_5: 0.6119 - recall_5: 0.5701 - val_loss: 0.6275 - val_accuracy: 0.6460 - val_precision_5: 0.6155 - val_recall_5: 0.5468\n",
            "Epoch 170/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6818 - accuracy: 0.6471 - precision_5: 0.6116 - recall_5: 0.5690 - val_loss: 0.6268 - val_accuracy: 0.6460 - val_precision_5: 0.6153 - val_recall_5: 0.5477\n",
            "Epoch 171/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6819 - accuracy: 0.6463 - precision_5: 0.6106 - recall_5: 0.5681 - val_loss: 0.6291 - val_accuracy: 0.6420 - val_precision_5: 0.5972 - val_recall_5: 0.6036\n",
            "Epoch 172/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6818 - accuracy: 0.6467 - precision_5: 0.6112 - recall_5: 0.5688 - val_loss: 0.6303 - val_accuracy: 0.6399 - val_precision_5: 0.5926 - val_recall_5: 0.6131\n",
            "Epoch 173/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6818 - accuracy: 0.6470 - precision_5: 0.6111 - recall_5: 0.5705 - val_loss: 0.6273 - val_accuracy: 0.6447 - val_precision_5: 0.6060 - val_recall_5: 0.5789\n",
            "Epoch 174/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6816 - accuracy: 0.6469 - precision_5: 0.6109 - recall_5: 0.5711 - val_loss: 0.6324 - val_accuracy: 0.6382 - val_precision_5: 0.5870 - val_recall_5: 0.6336\n",
            "Epoch 175/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6815 - accuracy: 0.6472 - precision_5: 0.6115 - recall_5: 0.5705 - val_loss: 0.6272 - val_accuracy: 0.6456 - val_precision_5: 0.6091 - val_recall_5: 0.5706\n",
            "Epoch 176/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6819 - accuracy: 0.6463 - precision_5: 0.6104 - recall_5: 0.5692 - val_loss: 0.6291 - val_accuracy: 0.6435 - val_precision_5: 0.6005 - val_recall_5: 0.5962\n",
            "Epoch 177/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6815 - accuracy: 0.6468 - precision_5: 0.6108 - recall_5: 0.5704 - val_loss: 0.6286 - val_accuracy: 0.6447 - val_precision_5: 0.6059 - val_recall_5: 0.5789\n",
            "Epoch 178/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6816 - accuracy: 0.6471 - precision_5: 0.6111 - recall_5: 0.5709 - val_loss: 0.6270 - val_accuracy: 0.6465 - val_precision_5: 0.6128 - val_recall_5: 0.5606\n",
            "Epoch 179/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6814 - accuracy: 0.6472 - precision_5: 0.6114 - recall_5: 0.5707 - val_loss: 0.6265 - val_accuracy: 0.6456 - val_precision_5: 0.6114 - val_recall_5: 0.5613\n",
            "Epoch 180/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6815 - accuracy: 0.6469 - precision_5: 0.6115 - recall_5: 0.5684 - val_loss: 0.6272 - val_accuracy: 0.6461 - val_precision_5: 0.6137 - val_recall_5: 0.5542\n",
            "Epoch 181/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6816 - accuracy: 0.6468 - precision_5: 0.6114 - recall_5: 0.5686 - val_loss: 0.6259 - val_accuracy: 0.6472 - val_precision_5: 0.6200 - val_recall_5: 0.5376\n",
            "Epoch 182/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6814 - accuracy: 0.6471 - precision_5: 0.6113 - recall_5: 0.5702 - val_loss: 0.6251 - val_accuracy: 0.6485 - val_precision_5: 0.6313 - val_recall_5: 0.5073\n",
            "Epoch 183/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6814 - accuracy: 0.6474 - precision_5: 0.6124 - recall_5: 0.5681 - val_loss: 0.6309 - val_accuracy: 0.6405 - val_precision_5: 0.5947 - val_recall_5: 0.6059\n",
            "Epoch 184/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6815 - accuracy: 0.6472 - precision_5: 0.6114 - recall_5: 0.5705 - val_loss: 0.6316 - val_accuracy: 0.6393 - val_precision_5: 0.5907 - val_recall_5: 0.6199\n",
            "Epoch 185/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6813 - accuracy: 0.6472 - precision_5: 0.6115 - recall_5: 0.5707 - val_loss: 0.6250 - val_accuracy: 0.6483 - val_precision_5: 0.6272 - val_recall_5: 0.5190\n",
            "Epoch 186/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6815 - accuracy: 0.6469 - precision_5: 0.6110 - recall_5: 0.5705 - val_loss: 0.6261 - val_accuracy: 0.6478 - val_precision_5: 0.6178 - val_recall_5: 0.5488\n",
            "Epoch 187/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6813 - accuracy: 0.6473 - precision_5: 0.6119 - recall_5: 0.5693 - val_loss: 0.6318 - val_accuracy: 0.6394 - val_precision_5: 0.5907 - val_recall_5: 0.6205\n",
            "Epoch 188/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6812 - accuracy: 0.6473 - precision_5: 0.6114 - recall_5: 0.5714 - val_loss: 0.6253 - val_accuracy: 0.6475 - val_precision_5: 0.6192 - val_recall_5: 0.5423\n",
            "Epoch 189/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6811 - accuracy: 0.6473 - precision_5: 0.6118 - recall_5: 0.5699 - val_loss: 0.6264 - val_accuracy: 0.6465 - val_precision_5: 0.6181 - val_recall_5: 0.5402\n",
            "Epoch 190/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6811 - accuracy: 0.6472 - precision_5: 0.6115 - recall_5: 0.5704 - val_loss: 0.6278 - val_accuracy: 0.6457 - val_precision_5: 0.6074 - val_recall_5: 0.5786\n",
            "Epoch 191/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6813 - accuracy: 0.6473 - precision_5: 0.6113 - recall_5: 0.5715 - val_loss: 0.6273 - val_accuracy: 0.6454 - val_precision_5: 0.6078 - val_recall_5: 0.5751\n",
            "Epoch 192/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6812 - accuracy: 0.6467 - precision_5: 0.6108 - recall_5: 0.5702 - val_loss: 0.6304 - val_accuracy: 0.6403 - val_precision_5: 0.5947 - val_recall_5: 0.6044\n",
            "Epoch 193/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6813 - accuracy: 0.6468 - precision_5: 0.6110 - recall_5: 0.5698 - val_loss: 0.6282 - val_accuracy: 0.6433 - val_precision_5: 0.6015 - val_recall_5: 0.5907\n",
            "Epoch 194/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6810 - accuracy: 0.6475 - precision_5: 0.6117 - recall_5: 0.5716 - val_loss: 0.6275 - val_accuracy: 0.6454 - val_precision_5: 0.6093 - val_recall_5: 0.5684\n",
            "Epoch 195/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6810 - accuracy: 0.6475 - precision_5: 0.6118 - recall_5: 0.5707 - val_loss: 0.6283 - val_accuracy: 0.6446 - val_precision_5: 0.6085 - val_recall_5: 0.5668\n",
            "Epoch 196/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6813 - accuracy: 0.6470 - precision_5: 0.6112 - recall_5: 0.5702 - val_loss: 0.6251 - val_accuracy: 0.6476 - val_precision_5: 0.6217 - val_recall_5: 0.5337\n",
            "Epoch 197/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6809 - accuracy: 0.6474 - precision_5: 0.6117 - recall_5: 0.5706 - val_loss: 0.6282 - val_accuracy: 0.6438 - val_precision_5: 0.6036 - val_recall_5: 0.5834\n",
            "Epoch 198/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6811 - accuracy: 0.6477 - precision_5: 0.6118 - recall_5: 0.5720 - val_loss: 0.6253 - val_accuracy: 0.6480 - val_precision_5: 0.6216 - val_recall_5: 0.5359\n",
            "Epoch 199/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6811 - accuracy: 0.6469 - precision_5: 0.6109 - recall_5: 0.5708 - val_loss: 0.6242 - val_accuracy: 0.6494 - val_precision_5: 0.6369 - val_recall_5: 0.4954\n",
            "Epoch 200/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6812 - accuracy: 0.6472 - precision_5: 0.6113 - recall_5: 0.5709 - val_loss: 0.6263 - val_accuracy: 0.6466 - val_precision_5: 0.6127 - val_recall_5: 0.5620\n",
            "Epoch 201/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6811 - accuracy: 0.6475 - precision_5: 0.6113 - recall_5: 0.5727 - val_loss: 0.6281 - val_accuracy: 0.6450 - val_precision_5: 0.6067 - val_recall_5: 0.5775\n",
            "Epoch 202/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6810 - accuracy: 0.6474 - precision_5: 0.6117 - recall_5: 0.5709 - val_loss: 0.6313 - val_accuracy: 0.6406 - val_precision_5: 0.5922 - val_recall_5: 0.6205\n",
            "Epoch 203/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6806 - accuracy: 0.6482 - precision_5: 0.6125 - recall_5: 0.5719 - val_loss: 0.6268 - val_accuracy: 0.6457 - val_precision_5: 0.6084 - val_recall_5: 0.5739\n",
            "Epoch 204/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6811 - accuracy: 0.6468 - precision_5: 0.6102 - recall_5: 0.5736 - val_loss: 0.6262 - val_accuracy: 0.6472 - val_precision_5: 0.6184 - val_recall_5: 0.5431\n",
            "Epoch 205/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6808 - accuracy: 0.6473 - precision_5: 0.6115 - recall_5: 0.5710 - val_loss: 0.6289 - val_accuracy: 0.6437 - val_precision_5: 0.6018 - val_recall_5: 0.5918\n",
            "Epoch 206/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6806 - accuracy: 0.6484 - precision_5: 0.6128 - recall_5: 0.5721 - val_loss: 0.6324 - val_accuracy: 0.6386 - val_precision_5: 0.5879 - val_recall_5: 0.6314\n",
            "Epoch 207/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6808 - accuracy: 0.6478 - precision_5: 0.6123 - recall_5: 0.5709 - val_loss: 0.6244 - val_accuracy: 0.6498 - val_precision_5: 0.6297 - val_recall_5: 0.5194\n",
            "Epoch 208/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6809 - accuracy: 0.6475 - precision_5: 0.6117 - recall_5: 0.5712 - val_loss: 0.6296 - val_accuracy: 0.6406 - val_precision_5: 0.5938 - val_recall_5: 0.6113\n",
            "Epoch 209/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6809 - accuracy: 0.6480 - precision_5: 0.6121 - recall_5: 0.5730 - val_loss: 0.6242 - val_accuracy: 0.6502 - val_precision_5: 0.6343 - val_recall_5: 0.5068\n",
            "Epoch 210/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6808 - accuracy: 0.6481 - precision_5: 0.6127 - recall_5: 0.5707 - val_loss: 0.6258 - val_accuracy: 0.6478 - val_precision_5: 0.6213 - val_recall_5: 0.5358\n",
            "Epoch 211/500\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6808 - accuracy: 0.6481 - precision_5: 0.6123 - recall_5: 0.5724 - val_loss: 0.6253 - val_accuracy: 0.6479 - val_precision_5: 0.6170 - val_recall_5: 0.5530\n",
            "Epoch 212/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6806 - accuracy: 0.6481 - precision_5: 0.6127 - recall_5: 0.5707 - val_loss: 0.6266 - val_accuracy: 0.6467 - val_precision_5: 0.6139 - val_recall_5: 0.5574\n",
            "Epoch 213/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6806 - accuracy: 0.6476 - precision_5: 0.6117 - recall_5: 0.5718 - val_loss: 0.6282 - val_accuracy: 0.6438 - val_precision_5: 0.6033 - val_recall_5: 0.5848\n",
            "Epoch 214/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6805 - accuracy: 0.6484 - precision_5: 0.6128 - recall_5: 0.5722 - val_loss: 0.6276 - val_accuracy: 0.6442 - val_precision_5: 0.6033 - val_recall_5: 0.5878\n",
            "Epoch 215/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6806 - accuracy: 0.6478 - precision_5: 0.6118 - recall_5: 0.5723 - val_loss: 0.6251 - val_accuracy: 0.6490 - val_precision_5: 0.6274 - val_recall_5: 0.5222\n",
            "Epoch 216/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6804 - accuracy: 0.6485 - precision_5: 0.6132 - recall_5: 0.5711 - val_loss: 0.6292 - val_accuracy: 0.6426 - val_precision_5: 0.6000 - val_recall_5: 0.5935\n",
            "Epoch 217/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6806 - accuracy: 0.6480 - precision_5: 0.6121 - recall_5: 0.5729 - val_loss: 0.6256 - val_accuracy: 0.6471 - val_precision_5: 0.6227 - val_recall_5: 0.5274\n",
            "Epoch 218/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6805 - accuracy: 0.6483 - precision_5: 0.6129 - recall_5: 0.5710 - val_loss: 0.6267 - val_accuracy: 0.6450 - val_precision_5: 0.6119 - val_recall_5: 0.5554\n",
            "Epoch 219/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6808 - accuracy: 0.6474 - precision_5: 0.6115 - recall_5: 0.5713 - val_loss: 0.6310 - val_accuracy: 0.6393 - val_precision_5: 0.5900 - val_recall_5: 0.6234\n",
            "Epoch 220/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6805 - accuracy: 0.6485 - precision_5: 0.6130 - recall_5: 0.5718 - val_loss: 0.6285 - val_accuracy: 0.6422 - val_precision_5: 0.5992 - val_recall_5: 0.5941\n",
            "Epoch 221/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6805 - accuracy: 0.6472 - precision_5: 0.6110 - recall_5: 0.5725 - val_loss: 0.6269 - val_accuracy: 0.6463 - val_precision_5: 0.6178 - val_recall_5: 0.5397\n",
            "Epoch 222/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6804 - accuracy: 0.6481 - precision_5: 0.6124 - recall_5: 0.5723 - val_loss: 0.6250 - val_accuracy: 0.6493 - val_precision_5: 0.6229 - val_recall_5: 0.5388\n",
            "Epoch 223/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6806 - accuracy: 0.6479 - precision_5: 0.6118 - recall_5: 0.5734 - val_loss: 0.6255 - val_accuracy: 0.6485 - val_precision_5: 0.6276 - val_recall_5: 0.5183\n",
            "Epoch 224/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6804 - accuracy: 0.6481 - precision_5: 0.6125 - recall_5: 0.5717 - val_loss: 0.6279 - val_accuracy: 0.6449 - val_precision_5: 0.6084 - val_recall_5: 0.5692\n",
            "Epoch 225/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6805 - accuracy: 0.6480 - precision_5: 0.6120 - recall_5: 0.5734 - val_loss: 0.6269 - val_accuracy: 0.6473 - val_precision_5: 0.6147 - val_recall_5: 0.5582\n",
            "Epoch 226/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6803 - accuracy: 0.6481 - precision_5: 0.6125 - recall_5: 0.5718 - val_loss: 0.6298 - val_accuracy: 0.6431 - val_precision_5: 0.6005 - val_recall_5: 0.5938\n",
            "Epoch 227/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6805 - accuracy: 0.6477 - precision_5: 0.6117 - recall_5: 0.5722 - val_loss: 0.6265 - val_accuracy: 0.6479 - val_precision_5: 0.6165 - val_recall_5: 0.5549\n",
            "Epoch 228/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6802 - accuracy: 0.6484 - precision_5: 0.6123 - recall_5: 0.5742 - val_loss: 0.6243 - val_accuracy: 0.6495 - val_precision_5: 0.6308 - val_recall_5: 0.5141\n",
            "Epoch 229/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6804 - accuracy: 0.6484 - precision_5: 0.6128 - recall_5: 0.5722 - val_loss: 0.6257 - val_accuracy: 0.6465 - val_precision_5: 0.6147 - val_recall_5: 0.5533\n",
            "Epoch 230/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6801 - accuracy: 0.6489 - precision_5: 0.6132 - recall_5: 0.5736 - val_loss: 0.6314 - val_accuracy: 0.6391 - val_precision_5: 0.5907 - val_recall_5: 0.6180\n",
            "Epoch 231/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6804 - accuracy: 0.6481 - precision_5: 0.6124 - recall_5: 0.5722 - val_loss: 0.6254 - val_accuracy: 0.6479 - val_precision_5: 0.6205 - val_recall_5: 0.5394\n",
            "Epoch 232/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6804 - accuracy: 0.6486 - precision_5: 0.6129 - recall_5: 0.5729 - val_loss: 0.6259 - val_accuracy: 0.6470 - val_precision_5: 0.6157 - val_recall_5: 0.5524\n",
            "Epoch 233/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6803 - accuracy: 0.6485 - precision_5: 0.6126 - recall_5: 0.5738 - val_loss: 0.6299 - val_accuracy: 0.6422 - val_precision_5: 0.5965 - val_recall_5: 0.6085\n",
            "Epoch 234/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6803 - accuracy: 0.6484 - precision_5: 0.6123 - recall_5: 0.5740 - val_loss: 0.6246 - val_accuracy: 0.6492 - val_precision_5: 0.6254 - val_recall_5: 0.5297\n",
            "Epoch 235/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6803 - accuracy: 0.6483 - precision_5: 0.6123 - recall_5: 0.5735 - val_loss: 0.6264 - val_accuracy: 0.6468 - val_precision_5: 0.6141 - val_recall_5: 0.5574\n",
            "Epoch 236/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6804 - accuracy: 0.6479 - precision_5: 0.6121 - recall_5: 0.5722 - val_loss: 0.6263 - val_accuracy: 0.6461 - val_precision_5: 0.6173 - val_recall_5: 0.5406\n",
            "Epoch 237/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6802 - accuracy: 0.6481 - precision_5: 0.6122 - recall_5: 0.5732 - val_loss: 0.6266 - val_accuracy: 0.6448 - val_precision_5: 0.6073 - val_recall_5: 0.5735\n",
            "Epoch 238/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6799 - accuracy: 0.6487 - precision_5: 0.6130 - recall_5: 0.5735 - val_loss: 0.6306 - val_accuracy: 0.6411 - val_precision_5: 0.5938 - val_recall_5: 0.6149\n",
            "Epoch 239/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6801 - accuracy: 0.6485 - precision_5: 0.6128 - recall_5: 0.5731 - val_loss: 0.6266 - val_accuracy: 0.6463 - val_precision_5: 0.6129 - val_recall_5: 0.5588\n",
            "Epoch 240/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6801 - accuracy: 0.6490 - precision_5: 0.6129 - recall_5: 0.5757 - val_loss: 0.6250 - val_accuracy: 0.6491 - val_precision_5: 0.6251 - val_recall_5: 0.5303\n",
            "Epoch 241/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6800 - accuracy: 0.6484 - precision_5: 0.6129 - recall_5: 0.5717 - val_loss: 0.6332 - val_accuracy: 0.6395 - val_precision_5: 0.5908 - val_recall_5: 0.6207\n",
            "Epoch 242/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6801 - accuracy: 0.6483 - precision_5: 0.6126 - recall_5: 0.5725 - val_loss: 0.6303 - val_accuracy: 0.6415 - val_precision_5: 0.5955 - val_recall_5: 0.6090\n",
            "Epoch 243/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6800 - accuracy: 0.6486 - precision_5: 0.6129 - recall_5: 0.5731 - val_loss: 0.6311 - val_accuracy: 0.6404 - val_precision_5: 0.5910 - val_recall_5: 0.6256\n",
            "Epoch 244/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6801 - accuracy: 0.6485 - precision_5: 0.6124 - recall_5: 0.5747 - val_loss: 0.6277 - val_accuracy: 0.6454 - val_precision_5: 0.6090 - val_recall_5: 0.5702\n",
            "Epoch 245/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6802 - accuracy: 0.6483 - precision_5: 0.6123 - recall_5: 0.5738 - val_loss: 0.6285 - val_accuracy: 0.6429 - val_precision_5: 0.6013 - val_recall_5: 0.5890\n",
            "Epoch 246/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6799 - accuracy: 0.6486 - precision_5: 0.6129 - recall_5: 0.5732 - val_loss: 0.6259 - val_accuracy: 0.6473 - val_precision_5: 0.6162 - val_recall_5: 0.5526\n",
            "Epoch 247/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6800 - accuracy: 0.6487 - precision_5: 0.6129 - recall_5: 0.5733 - val_loss: 0.6285 - val_accuracy: 0.6438 - val_precision_5: 0.6031 - val_recall_5: 0.5862\n",
            "Epoch 248/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6798 - accuracy: 0.6490 - precision_5: 0.6132 - recall_5: 0.5741 - val_loss: 0.6306 - val_accuracy: 0.6408 - val_precision_5: 0.5948 - val_recall_5: 0.6075\n",
            "Epoch 249/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6800 - accuracy: 0.6486 - precision_5: 0.6127 - recall_5: 0.5740 - val_loss: 0.6292 - val_accuracy: 0.6431 - val_precision_5: 0.5983 - val_recall_5: 0.6053\n",
            "Epoch 250/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6800 - accuracy: 0.6484 - precision_5: 0.6125 - recall_5: 0.5738 - val_loss: 0.6256 - val_accuracy: 0.6472 - val_precision_5: 0.6161 - val_recall_5: 0.5518\n",
            "Epoch 251/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6801 - accuracy: 0.6485 - precision_5: 0.6129 - recall_5: 0.5727 - val_loss: 0.6298 - val_accuracy: 0.6424 - val_precision_5: 0.5968 - val_recall_5: 0.6075\n",
            "Epoch 252/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6800 - accuracy: 0.6488 - precision_5: 0.6132 - recall_5: 0.5730 - val_loss: 0.6294 - val_accuracy: 0.6429 - val_precision_5: 0.5986 - val_recall_5: 0.6020\n",
            "Epoch 253/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6796 - accuracy: 0.6491 - precision_5: 0.6134 - recall_5: 0.5742 - val_loss: 0.6307 - val_accuracy: 0.6405 - val_precision_5: 0.5922 - val_recall_5: 0.6198\n",
            "Epoch 254/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6799 - accuracy: 0.6489 - precision_5: 0.6134 - recall_5: 0.5731 - val_loss: 0.6266 - val_accuracy: 0.6455 - val_precision_5: 0.6123 - val_recall_5: 0.5568\n",
            "Epoch 255/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6795 - accuracy: 0.6491 - precision_5: 0.6135 - recall_5: 0.5733 - val_loss: 0.6269 - val_accuracy: 0.6470 - val_precision_5: 0.6114 - val_recall_5: 0.5694\n",
            "Epoch 256/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6796 - accuracy: 0.6487 - precision_5: 0.6131 - recall_5: 0.5726 - val_loss: 0.6296 - val_accuracy: 0.6425 - val_precision_5: 0.5990 - val_recall_5: 0.5973\n",
            "Epoch 257/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6798 - accuracy: 0.6484 - precision_5: 0.6120 - recall_5: 0.5758 - val_loss: 0.6277 - val_accuracy: 0.6455 - val_precision_5: 0.6090 - val_recall_5: 0.5704\n",
            "Epoch 258/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6798 - accuracy: 0.6488 - precision_5: 0.6126 - recall_5: 0.5756 - val_loss: 0.6257 - val_accuracy: 0.6480 - val_precision_5: 0.6186 - val_recall_5: 0.5469\n",
            "Epoch 259/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6797 - accuracy: 0.6495 - precision_5: 0.6138 - recall_5: 0.5748 - val_loss: 0.6305 - val_accuracy: 0.6412 - val_precision_5: 0.5946 - val_recall_5: 0.6117\n",
            "Epoch 260/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6796 - accuracy: 0.6488 - precision_5: 0.6130 - recall_5: 0.5740 - val_loss: 0.6315 - val_accuracy: 0.6392 - val_precision_5: 0.5893 - val_recall_5: 0.6274\n",
            "Epoch 261/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6795 - accuracy: 0.6498 - precision_5: 0.6147 - recall_5: 0.5728 - val_loss: 0.6274 - val_accuracy: 0.6453 - val_precision_5: 0.6055 - val_recall_5: 0.5848\n",
            "Epoch 262/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6797 - accuracy: 0.6490 - precision_5: 0.6132 - recall_5: 0.5739 - val_loss: 0.6254 - val_accuracy: 0.6476 - val_precision_5: 0.6199 - val_recall_5: 0.5401\n",
            "Epoch 263/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6799 - accuracy: 0.6483 - precision_5: 0.6117 - recall_5: 0.5763 - val_loss: 0.6248 - val_accuracy: 0.6494 - val_precision_5: 0.6286 - val_recall_5: 0.5204\n",
            "Epoch 264/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6798 - accuracy: 0.6492 - precision_5: 0.6137 - recall_5: 0.5736 - val_loss: 0.6246 - val_accuracy: 0.6486 - val_precision_5: 0.6288 - val_recall_5: 0.5156\n",
            "Epoch 265/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6796 - accuracy: 0.6492 - precision_5: 0.6137 - recall_5: 0.5735 - val_loss: 0.6254 - val_accuracy: 0.6473 - val_precision_5: 0.6178 - val_recall_5: 0.5461\n",
            "Epoch 266/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6794 - accuracy: 0.6487 - precision_5: 0.6133 - recall_5: 0.5725 - val_loss: 0.6269 - val_accuracy: 0.6457 - val_precision_5: 0.6086 - val_recall_5: 0.5737\n",
            "Epoch 267/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6797 - accuracy: 0.6488 - precision_5: 0.6130 - recall_5: 0.5741 - val_loss: 0.6299 - val_accuracy: 0.6421 - val_precision_5: 0.5965 - val_recall_5: 0.6071\n",
            "Epoch 268/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6797 - accuracy: 0.6489 - precision_5: 0.6131 - recall_5: 0.5743 - val_loss: 0.6242 - val_accuracy: 0.6504 - val_precision_5: 0.6340 - val_recall_5: 0.5088\n",
            "Epoch 269/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6795 - accuracy: 0.6494 - precision_5: 0.6139 - recall_5: 0.5738 - val_loss: 0.6294 - val_accuracy: 0.6416 - val_precision_5: 0.5956 - val_recall_5: 0.6091\n",
            "Epoch 270/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6800 - accuracy: 0.6482 - precision_5: 0.6123 - recall_5: 0.5732 - val_loss: 0.6259 - val_accuracy: 0.6483 - val_precision_5: 0.6247 - val_recall_5: 0.5273\n",
            "Epoch 271/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6793 - accuracy: 0.6497 - precision_5: 0.6141 - recall_5: 0.5747 - val_loss: 0.6270 - val_accuracy: 0.6473 - val_precision_5: 0.6138 - val_recall_5: 0.5616\n",
            "Epoch 272/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6794 - accuracy: 0.6490 - precision_5: 0.6133 - recall_5: 0.5736 - val_loss: 0.6269 - val_accuracy: 0.6454 - val_precision_5: 0.6112 - val_recall_5: 0.5604\n",
            "Epoch 273/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6795 - accuracy: 0.6490 - precision_5: 0.6132 - recall_5: 0.5740 - val_loss: 0.6352 - val_accuracy: 0.6348 - val_precision_5: 0.5801 - val_recall_5: 0.6520\n",
            "Epoch 274/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6796 - accuracy: 0.6491 - precision_5: 0.6132 - recall_5: 0.5748 - val_loss: 0.6270 - val_accuracy: 0.6461 - val_precision_5: 0.6119 - val_recall_5: 0.5621\n",
            "Epoch 275/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6795 - accuracy: 0.6490 - precision_5: 0.6130 - recall_5: 0.5751 - val_loss: 0.6256 - val_accuracy: 0.6482 - val_precision_5: 0.6208 - val_recall_5: 0.5401\n",
            "Epoch 276/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6797 - accuracy: 0.6490 - precision_5: 0.6134 - recall_5: 0.5734 - val_loss: 0.6258 - val_accuracy: 0.6473 - val_precision_5: 0.6144 - val_recall_5: 0.5590\n",
            "Epoch 277/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6793 - accuracy: 0.6495 - precision_5: 0.6137 - recall_5: 0.5748 - val_loss: 0.6295 - val_accuracy: 0.6427 - val_precision_5: 0.6008 - val_recall_5: 0.5897\n",
            "Epoch 278/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6796 - accuracy: 0.6492 - precision_5: 0.6133 - recall_5: 0.5747 - val_loss: 0.6252 - val_accuracy: 0.6485 - val_precision_5: 0.6210 - val_recall_5: 0.5415\n",
            "Epoch 279/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6794 - accuracy: 0.6492 - precision_5: 0.6135 - recall_5: 0.5738 - val_loss: 0.6280 - val_accuracy: 0.6448 - val_precision_5: 0.6036 - val_recall_5: 0.5905\n",
            "Epoch 280/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6794 - accuracy: 0.6496 - precision_5: 0.6138 - recall_5: 0.5750 - val_loss: 0.6256 - val_accuracy: 0.6486 - val_precision_5: 0.6173 - val_recall_5: 0.5560\n",
            "Epoch 281/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6794 - accuracy: 0.6497 - precision_5: 0.6142 - recall_5: 0.5739 - val_loss: 0.6270 - val_accuracy: 0.6462 - val_precision_5: 0.6090 - val_recall_5: 0.5747\n",
            "Epoch 282/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6794 - accuracy: 0.6490 - precision_5: 0.6133 - recall_5: 0.5738 - val_loss: 0.6252 - val_accuracy: 0.6482 - val_precision_5: 0.6248 - val_recall_5: 0.5261\n",
            "Epoch 283/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6793 - accuracy: 0.6499 - precision_5: 0.6141 - recall_5: 0.5760 - val_loss: 0.6258 - val_accuracy: 0.6472 - val_precision_5: 0.6159 - val_recall_5: 0.5526\n",
            "Epoch 284/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6793 - accuracy: 0.6489 - precision_5: 0.6126 - recall_5: 0.5761 - val_loss: 0.6247 - val_accuracy: 0.6494 - val_precision_5: 0.6331 - val_recall_5: 0.5067\n",
            "Epoch 285/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6792 - accuracy: 0.6497 - precision_5: 0.6141 - recall_5: 0.5749 - val_loss: 0.6311 - val_accuracy: 0.6412 - val_precision_5: 0.5962 - val_recall_5: 0.6027\n",
            "Epoch 286/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6794 - accuracy: 0.6490 - precision_5: 0.6133 - recall_5: 0.5737 - val_loss: 0.6285 - val_accuracy: 0.6445 - val_precision_5: 0.6051 - val_recall_5: 0.5811\n",
            "Epoch 287/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6793 - accuracy: 0.6497 - precision_5: 0.6140 - recall_5: 0.5748 - val_loss: 0.6264 - val_accuracy: 0.6467 - val_precision_5: 0.6102 - val_recall_5: 0.5727\n",
            "Epoch 288/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6792 - accuracy: 0.6495 - precision_5: 0.6139 - recall_5: 0.5744 - val_loss: 0.6252 - val_accuracy: 0.6479 - val_precision_5: 0.6239 - val_recall_5: 0.5275\n",
            "Epoch 289/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6794 - accuracy: 0.6500 - precision_5: 0.6147 - recall_5: 0.5744 - val_loss: 0.6297 - val_accuracy: 0.6409 - val_precision_5: 0.5944 - val_recall_5: 0.6103\n",
            "Epoch 290/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6792 - accuracy: 0.6485 - precision_5: 0.6123 - recall_5: 0.5749 - val_loss: 0.6292 - val_accuracy: 0.6422 - val_precision_5: 0.5979 - val_recall_5: 0.6005\n",
            "Epoch 291/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6794 - accuracy: 0.6491 - precision_5: 0.6131 - recall_5: 0.5754 - val_loss: 0.6304 - val_accuracy: 0.6402 - val_precision_5: 0.5927 - val_recall_5: 0.6143\n",
            "Epoch 292/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6793 - accuracy: 0.6489 - precision_5: 0.6131 - recall_5: 0.5741 - val_loss: 0.6290 - val_accuracy: 0.6421 - val_precision_5: 0.6003 - val_recall_5: 0.5882\n",
            "Epoch 293/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6792 - accuracy: 0.6495 - precision_5: 0.6135 - recall_5: 0.5761 - val_loss: 0.6287 - val_accuracy: 0.6441 - val_precision_5: 0.6061 - val_recall_5: 0.5741\n",
            "Epoch 294/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6789 - accuracy: 0.6502 - precision_5: 0.6147 - recall_5: 0.5751 - val_loss: 0.6261 - val_accuracy: 0.6479 - val_precision_5: 0.6121 - val_recall_5: 0.5722\n",
            "Epoch 295/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6792 - accuracy: 0.6493 - precision_5: 0.6134 - recall_5: 0.5753 - val_loss: 0.6252 - val_accuracy: 0.6480 - val_precision_5: 0.6231 - val_recall_5: 0.5306\n",
            "Epoch 296/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6792 - accuracy: 0.6493 - precision_5: 0.6132 - recall_5: 0.5757 - val_loss: 0.6280 - val_accuracy: 0.6434 - val_precision_5: 0.6020 - val_recall_5: 0.5886\n",
            "Epoch 297/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6792 - accuracy: 0.6488 - precision_5: 0.6128 - recall_5: 0.5750 - val_loss: 0.6280 - val_accuracy: 0.6431 - val_precision_5: 0.6027 - val_recall_5: 0.5832\n",
            "Epoch 298/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6791 - accuracy: 0.6494 - precision_5: 0.6138 - recall_5: 0.5745 - val_loss: 0.6270 - val_accuracy: 0.6456 - val_precision_5: 0.6094 - val_recall_5: 0.5695\n",
            "Epoch 299/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6792 - accuracy: 0.6496 - precision_5: 0.6137 - recall_5: 0.5755 - val_loss: 0.6272 - val_accuracy: 0.6441 - val_precision_5: 0.6037 - val_recall_5: 0.5854\n",
            "Epoch 300/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6789 - accuracy: 0.6498 - precision_5: 0.6136 - recall_5: 0.5774 - val_loss: 0.6251 - val_accuracy: 0.6491 - val_precision_5: 0.6246 - val_recall_5: 0.5324\n",
            "Epoch 301/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6788 - accuracy: 0.6497 - precision_5: 0.6141 - recall_5: 0.5751 - val_loss: 0.6276 - val_accuracy: 0.6456 - val_precision_5: 0.6078 - val_recall_5: 0.5764\n",
            "Epoch 302/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6793 - accuracy: 0.6482 - precision_5: 0.6119 - recall_5: 0.5751 - val_loss: 0.6245 - val_accuracy: 0.6497 - val_precision_5: 0.6231 - val_recall_5: 0.5405\n",
            "Epoch 303/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6788 - accuracy: 0.6495 - precision_5: 0.6134 - recall_5: 0.5768 - val_loss: 0.6253 - val_accuracy: 0.6479 - val_precision_5: 0.6180 - val_recall_5: 0.5491\n",
            "Epoch 304/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6789 - accuracy: 0.6499 - precision_5: 0.6141 - recall_5: 0.5761 - val_loss: 0.6254 - val_accuracy: 0.6484 - val_precision_5: 0.6251 - val_recall_5: 0.5263\n",
            "Epoch 305/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6792 - accuracy: 0.6495 - precision_5: 0.6137 - recall_5: 0.5753 - val_loss: 0.6260 - val_accuracy: 0.6472 - val_precision_5: 0.6164 - val_recall_5: 0.5508\n",
            "Epoch 306/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6791 - accuracy: 0.6489 - precision_5: 0.6129 - recall_5: 0.5746 - val_loss: 0.6273 - val_accuracy: 0.6455 - val_precision_5: 0.6077 - val_recall_5: 0.5763\n",
            "Epoch 307/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6789 - accuracy: 0.6500 - precision_5: 0.6140 - recall_5: 0.5771 - val_loss: 0.6279 - val_accuracy: 0.6437 - val_precision_5: 0.6011 - val_recall_5: 0.5950\n",
            "Epoch 308/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6789 - accuracy: 0.6499 - precision_5: 0.6141 - recall_5: 0.5759 - val_loss: 0.6264 - val_accuracy: 0.6471 - val_precision_5: 0.6158 - val_recall_5: 0.5527\n",
            "Epoch 309/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6790 - accuracy: 0.6489 - precision_5: 0.6127 - recall_5: 0.5755 - val_loss: 0.6313 - val_accuracy: 0.6393 - val_precision_5: 0.5906 - val_recall_5: 0.6199\n",
            "Epoch 310/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6790 - accuracy: 0.6498 - precision_5: 0.6143 - recall_5: 0.5746 - val_loss: 0.6272 - val_accuracy: 0.6449 - val_precision_5: 0.6069 - val_recall_5: 0.5759\n",
            "Epoch 311/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6789 - accuracy: 0.6496 - precision_5: 0.6136 - recall_5: 0.5765 - val_loss: 0.6284 - val_accuracy: 0.6439 - val_precision_5: 0.6027 - val_recall_5: 0.5889\n",
            "Epoch 312/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6787 - accuracy: 0.6504 - precision_5: 0.6149 - recall_5: 0.5758 - val_loss: 0.6302 - val_accuracy: 0.6406 - val_precision_5: 0.5930 - val_recall_5: 0.6155\n",
            "Epoch 313/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6789 - accuracy: 0.6502 - precision_5: 0.6148 - recall_5: 0.5751 - val_loss: 0.6306 - val_accuracy: 0.6409 - val_precision_5: 0.5927 - val_recall_5: 0.6196\n",
            "Epoch 314/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6788 - accuracy: 0.6497 - precision_5: 0.6134 - recall_5: 0.5777 - val_loss: 0.6263 - val_accuracy: 0.6469 - val_precision_5: 0.6142 - val_recall_5: 0.5576\n",
            "Epoch 315/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6786 - accuracy: 0.6501 - precision_5: 0.6141 - recall_5: 0.5773 - val_loss: 0.6258 - val_accuracy: 0.6469 - val_precision_5: 0.6138 - val_recall_5: 0.5593\n",
            "Epoch 316/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6788 - accuracy: 0.6502 - precision_5: 0.6143 - recall_5: 0.5773 - val_loss: 0.6262 - val_accuracy: 0.6469 - val_precision_5: 0.6121 - val_recall_5: 0.5659\n",
            "Epoch 317/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6787 - accuracy: 0.6497 - precision_5: 0.6141 - recall_5: 0.5749 - val_loss: 0.6272 - val_accuracy: 0.6447 - val_precision_5: 0.6058 - val_recall_5: 0.5795\n",
            "Epoch 318/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6788 - accuracy: 0.6495 - precision_5: 0.6132 - recall_5: 0.5768 - val_loss: 0.6270 - val_accuracy: 0.6459 - val_precision_5: 0.6115 - val_recall_5: 0.5623\n",
            "Epoch 319/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6788 - accuracy: 0.6499 - precision_5: 0.6139 - recall_5: 0.5765 - val_loss: 0.6294 - val_accuracy: 0.6438 - val_precision_5: 0.6022 - val_recall_5: 0.5905\n",
            "Epoch 320/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6788 - accuracy: 0.6495 - precision_5: 0.6135 - recall_5: 0.5757 - val_loss: 0.6265 - val_accuracy: 0.6452 - val_precision_5: 0.6057 - val_recall_5: 0.5832\n",
            "Epoch 321/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6789 - accuracy: 0.6503 - precision_5: 0.6143 - recall_5: 0.5774 - val_loss: 0.6270 - val_accuracy: 0.6452 - val_precision_5: 0.6053 - val_recall_5: 0.5852\n",
            "Epoch 322/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6787 - accuracy: 0.6501 - precision_5: 0.6139 - recall_5: 0.5778 - val_loss: 0.6254 - val_accuracy: 0.6479 - val_precision_5: 0.6224 - val_recall_5: 0.5329\n",
            "Epoch 323/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6786 - accuracy: 0.6502 - precision_5: 0.6146 - recall_5: 0.5758 - val_loss: 0.6250 - val_accuracy: 0.6472 - val_precision_5: 0.6195 - val_recall_5: 0.5390\n",
            "Epoch 324/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6785 - accuracy: 0.6505 - precision_5: 0.6148 - recall_5: 0.5766 - val_loss: 0.6277 - val_accuracy: 0.6449 - val_precision_5: 0.6057 - val_recall_5: 0.5810\n",
            "Epoch 325/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6787 - accuracy: 0.6503 - precision_5: 0.6145 - recall_5: 0.5765 - val_loss: 0.6286 - val_accuracy: 0.6435 - val_precision_5: 0.6018 - val_recall_5: 0.5903\n",
            "Epoch 326/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6785 - accuracy: 0.6502 - precision_5: 0.6139 - recall_5: 0.5785 - val_loss: 0.6234 - val_accuracy: 0.6507 - val_precision_5: 0.6521 - val_recall_5: 0.4625\n",
            "Epoch 327/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6789 - accuracy: 0.6495 - precision_5: 0.6133 - recall_5: 0.5769 - val_loss: 0.6243 - val_accuracy: 0.6497 - val_precision_5: 0.6260 - val_recall_5: 0.5304\n",
            "Epoch 328/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6786 - accuracy: 0.6501 - precision_5: 0.6149 - recall_5: 0.5741 - val_loss: 0.6265 - val_accuracy: 0.6462 - val_precision_5: 0.6119 - val_recall_5: 0.5627\n",
            "Epoch 329/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6786 - accuracy: 0.6492 - precision_5: 0.6127 - recall_5: 0.5774 - val_loss: 0.6259 - val_accuracy: 0.6472 - val_precision_5: 0.6150 - val_recall_5: 0.5559\n",
            "Epoch 330/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6785 - accuracy: 0.6506 - precision_5: 0.6148 - recall_5: 0.5773 - val_loss: 0.6317 - val_accuracy: 0.6415 - val_precision_5: 0.5972 - val_recall_5: 0.6000\n",
            "Epoch 331/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6787 - accuracy: 0.6497 - precision_5: 0.6135 - recall_5: 0.5771 - val_loss: 0.6249 - val_accuracy: 0.6492 - val_precision_5: 0.6271 - val_recall_5: 0.5239\n",
            "Epoch 332/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6786 - accuracy: 0.6502 - precision_5: 0.6146 - recall_5: 0.5759 - val_loss: 0.6295 - val_accuracy: 0.6420 - val_precision_5: 0.5958 - val_recall_5: 0.6101\n",
            "Epoch 333/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6786 - accuracy: 0.6503 - precision_5: 0.6142 - recall_5: 0.5778 - val_loss: 0.6289 - val_accuracy: 0.6428 - val_precision_5: 0.6022 - val_recall_5: 0.5840\n",
            "Epoch 334/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6785 - accuracy: 0.6504 - precision_5: 0.6148 - recall_5: 0.5759 - val_loss: 0.6248 - val_accuracy: 0.6487 - val_precision_5: 0.6249 - val_recall_5: 0.5288\n",
            "Epoch 335/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6785 - accuracy: 0.6498 - precision_5: 0.6135 - recall_5: 0.5780 - val_loss: 0.6243 - val_accuracy: 0.6488 - val_precision_5: 0.6277 - val_recall_5: 0.5201\n",
            "Epoch 336/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6786 - accuracy: 0.6495 - precision_5: 0.6140 - recall_5: 0.5739 - val_loss: 0.6283 - val_accuracy: 0.6439 - val_precision_5: 0.6009 - val_recall_5: 0.5977\n",
            "Epoch 337/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6785 - accuracy: 0.6504 - precision_5: 0.6144 - recall_5: 0.5774 - val_loss: 0.6323 - val_accuracy: 0.6371 - val_precision_5: 0.5846 - val_recall_5: 0.6408\n",
            "Epoch 338/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6783 - accuracy: 0.6509 - precision_5: 0.6150 - recall_5: 0.5782 - val_loss: 0.6259 - val_accuracy: 0.6474 - val_precision_5: 0.6150 - val_recall_5: 0.5574\n",
            "Epoch 339/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6785 - accuracy: 0.6499 - precision_5: 0.6137 - recall_5: 0.5775 - val_loss: 0.6266 - val_accuracy: 0.6474 - val_precision_5: 0.6146 - val_recall_5: 0.5589\n",
            "Epoch 340/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6783 - accuracy: 0.6503 - precision_5: 0.6146 - recall_5: 0.5767 - val_loss: 0.6263 - val_accuracy: 0.6477 - val_precision_5: 0.6123 - val_recall_5: 0.5699\n",
            "Epoch 341/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6783 - accuracy: 0.6506 - precision_5: 0.6143 - recall_5: 0.5794 - val_loss: 0.6235 - val_accuracy: 0.6514 - val_precision_5: 0.6426 - val_recall_5: 0.4901\n",
            "Epoch 342/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6786 - accuracy: 0.6500 - precision_5: 0.6140 - recall_5: 0.5768 - val_loss: 0.6266 - val_accuracy: 0.6477 - val_precision_5: 0.6176 - val_recall_5: 0.5488\n",
            "Epoch 343/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6784 - accuracy: 0.6503 - precision_5: 0.6146 - recall_5: 0.5763 - val_loss: 0.6275 - val_accuracy: 0.6454 - val_precision_5: 0.6098 - val_recall_5: 0.5665\n",
            "Epoch 344/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6786 - accuracy: 0.6498 - precision_5: 0.6139 - recall_5: 0.5762 - val_loss: 0.6249 - val_accuracy: 0.6492 - val_precision_5: 0.6214 - val_recall_5: 0.5437\n",
            "Epoch 345/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6783 - accuracy: 0.6502 - precision_5: 0.6143 - recall_5: 0.5768 - val_loss: 0.6280 - val_accuracy: 0.6459 - val_precision_5: 0.6082 - val_recall_5: 0.5764\n",
            "Epoch 346/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6783 - accuracy: 0.6500 - precision_5: 0.6138 - recall_5: 0.5775 - val_loss: 0.6260 - val_accuracy: 0.6472 - val_precision_5: 0.6148 - val_recall_5: 0.5573\n",
            "Epoch 347/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6784 - accuracy: 0.6497 - precision_5: 0.6139 - recall_5: 0.5759 - val_loss: 0.6235 - val_accuracy: 0.6503 - val_precision_5: 0.6400 - val_recall_5: 0.4913\n",
            "Epoch 348/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6783 - accuracy: 0.6504 - precision_5: 0.6144 - recall_5: 0.5777 - val_loss: 0.6263 - val_accuracy: 0.6467 - val_precision_5: 0.6179 - val_recall_5: 0.5418\n",
            "Epoch 349/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6785 - accuracy: 0.6500 - precision_5: 0.6140 - recall_5: 0.5772 - val_loss: 0.6240 - val_accuracy: 0.6498 - val_precision_5: 0.6335 - val_recall_5: 0.5075\n",
            "Epoch 350/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6784 - accuracy: 0.6498 - precision_5: 0.6138 - recall_5: 0.5763 - val_loss: 0.6270 - val_accuracy: 0.6463 - val_precision_5: 0.6091 - val_recall_5: 0.5751\n",
            "Epoch 351/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6784 - accuracy: 0.6498 - precision_5: 0.6136 - recall_5: 0.5776 - val_loss: 0.6242 - val_accuracy: 0.6498 - val_precision_5: 0.6292 - val_recall_5: 0.5210\n",
            "Epoch 352/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6783 - accuracy: 0.6499 - precision_5: 0.6139 - recall_5: 0.5767 - val_loss: 0.6244 - val_accuracy: 0.6490 - val_precision_5: 0.6300 - val_recall_5: 0.5140\n",
            "Epoch 353/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6784 - accuracy: 0.6504 - precision_5: 0.6148 - recall_5: 0.5758 - val_loss: 0.6273 - val_accuracy: 0.6455 - val_precision_5: 0.6058 - val_recall_5: 0.5842\n",
            "Epoch 354/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6784 - accuracy: 0.6506 - precision_5: 0.6147 - recall_5: 0.5780 - val_loss: 0.6268 - val_accuracy: 0.6460 - val_precision_5: 0.6113 - val_recall_5: 0.5637\n",
            "Epoch 355/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6781 - accuracy: 0.6501 - precision_5: 0.6141 - recall_5: 0.5774 - val_loss: 0.6319 - val_accuracy: 0.6376 - val_precision_5: 0.5869 - val_recall_5: 0.6298\n",
            "Epoch 356/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6781 - accuracy: 0.6508 - precision_5: 0.6150 - recall_5: 0.5776 - val_loss: 0.6274 - val_accuracy: 0.6440 - val_precision_5: 0.6043 - val_recall_5: 0.5816\n",
            "Epoch 357/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6780 - accuracy: 0.6506 - precision_5: 0.6147 - recall_5: 0.5776 - val_loss: 0.6308 - val_accuracy: 0.6392 - val_precision_5: 0.5902 - val_recall_5: 0.6221\n",
            "Epoch 358/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6783 - accuracy: 0.6496 - precision_5: 0.6132 - recall_5: 0.5778 - val_loss: 0.6293 - val_accuracy: 0.6420 - val_precision_5: 0.5968 - val_recall_5: 0.6053\n",
            "Epoch 359/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6781 - accuracy: 0.6511 - precision_5: 0.6153 - recall_5: 0.5785 - val_loss: 0.6238 - val_accuracy: 0.6501 - val_precision_5: 0.6439 - val_recall_5: 0.4800\n",
            "Epoch 360/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6784 - accuracy: 0.6502 - precision_5: 0.6142 - recall_5: 0.5775 - val_loss: 0.6266 - val_accuracy: 0.6464 - val_precision_5: 0.6121 - val_recall_5: 0.5634\n",
            "Epoch 361/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6782 - accuracy: 0.6501 - precision_5: 0.6138 - recall_5: 0.5784 - val_loss: 0.6277 - val_accuracy: 0.6448 - val_precision_5: 0.6074 - val_recall_5: 0.5728\n",
            "Epoch 362/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6783 - accuracy: 0.6502 - precision_5: 0.6143 - recall_5: 0.5768 - val_loss: 0.6243 - val_accuracy: 0.6503 - val_precision_5: 0.6253 - val_recall_5: 0.5362\n",
            "Epoch 363/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6784 - accuracy: 0.6502 - precision_5: 0.6140 - recall_5: 0.5782 - val_loss: 0.6288 - val_accuracy: 0.6441 - val_precision_5: 0.6004 - val_recall_5: 0.6012\n",
            "Epoch 364/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6783 - accuracy: 0.6506 - precision_5: 0.6146 - recall_5: 0.5780 - val_loss: 0.6272 - val_accuracy: 0.6455 - val_precision_5: 0.6096 - val_recall_5: 0.5675\n",
            "Epoch 365/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6783 - accuracy: 0.6506 - precision_5: 0.6149 - recall_5: 0.5771 - val_loss: 0.6283 - val_accuracy: 0.6439 - val_precision_5: 0.6010 - val_recall_5: 0.5966\n",
            "Epoch 366/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6783 - accuracy: 0.6507 - precision_5: 0.6150 - recall_5: 0.5772 - val_loss: 0.6272 - val_accuracy: 0.6446 - val_precision_5: 0.6061 - val_recall_5: 0.5778\n",
            "Epoch 367/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6782 - accuracy: 0.6505 - precision_5: 0.6145 - recall_5: 0.5776 - val_loss: 0.6258 - val_accuracy: 0.6468 - val_precision_5: 0.6158 - val_recall_5: 0.5509\n",
            "Epoch 368/500\n",
            "351/351 [==============================] - 2s 6ms/step - loss: 0.6785 - accuracy: 0.6498 - precision_5: 0.6136 - recall_5: 0.5775 - val_loss: 0.6347 - val_accuracy: 0.6346 - val_precision_5: 0.5799 - val_recall_5: 0.6522\n",
            "Epoch 369/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6780 - accuracy: 0.6507 - precision_5: 0.6146 - recall_5: 0.5791 - val_loss: 0.6254 - val_accuracy: 0.6481 - val_precision_5: 0.6200 - val_recall_5: 0.5425\n",
            "Epoch 370/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6781 - accuracy: 0.6509 - precision_5: 0.6150 - recall_5: 0.5781 - val_loss: 0.6261 - val_accuracy: 0.6462 - val_precision_5: 0.6123 - val_recall_5: 0.5609\n",
            "Epoch 371/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6781 - accuracy: 0.6509 - precision_5: 0.6150 - recall_5: 0.5783 - val_loss: 0.6264 - val_accuracy: 0.6470 - val_precision_5: 0.6153 - val_recall_5: 0.5541\n",
            "Epoch 372/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6781 - accuracy: 0.6507 - precision_5: 0.6148 - recall_5: 0.5780 - val_loss: 0.6265 - val_accuracy: 0.6476 - val_precision_5: 0.6158 - val_recall_5: 0.5555\n",
            "Epoch 373/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6779 - accuracy: 0.6509 - precision_5: 0.6150 - recall_5: 0.5788 - val_loss: 0.6290 - val_accuracy: 0.6423 - val_precision_5: 0.5953 - val_recall_5: 0.6155\n",
            "Epoch 374/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6778 - accuracy: 0.6503 - precision_5: 0.6143 - recall_5: 0.5777 - val_loss: 0.6258 - val_accuracy: 0.6466 - val_precision_5: 0.6112 - val_recall_5: 0.5676\n",
            "Epoch 375/500\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6781 - accuracy: 0.6498 - precision_5: 0.6134 - recall_5: 0.5783 - val_loss: 0.6255 - val_accuracy: 0.6468 - val_precision_5: 0.6176 - val_recall_5: 0.5439\n",
            "Epoch 376/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6782 - accuracy: 0.6505 - precision_5: 0.6142 - recall_5: 0.5791 - val_loss: 0.6280 - val_accuracy: 0.6437 - val_precision_5: 0.6035 - val_recall_5: 0.5832\n",
            "Epoch 377/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6779 - accuracy: 0.6510 - precision_5: 0.6150 - recall_5: 0.5789 - val_loss: 0.6284 - val_accuracy: 0.6439 - val_precision_5: 0.6012 - val_recall_5: 0.5958\n",
            "Epoch 378/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6782 - accuracy: 0.6506 - precision_5: 0.6145 - recall_5: 0.5782 - val_loss: 0.6262 - val_accuracy: 0.6466 - val_precision_5: 0.6101 - val_recall_5: 0.5726\n",
            "Epoch 379/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6779 - accuracy: 0.6507 - precision_5: 0.6147 - recall_5: 0.5784 - val_loss: 0.6300 - val_accuracy: 0.6414 - val_precision_5: 0.5950 - val_recall_5: 0.6109\n",
            "Epoch 380/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6777 - accuracy: 0.6516 - precision_5: 0.6158 - recall_5: 0.5793 - val_loss: 0.6276 - val_accuracy: 0.6439 - val_precision_5: 0.6031 - val_recall_5: 0.5871\n",
            "Epoch 381/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6778 - accuracy: 0.6503 - precision_5: 0.6140 - recall_5: 0.5785 - val_loss: 0.6270 - val_accuracy: 0.6456 - val_precision_5: 0.6074 - val_recall_5: 0.5781\n",
            "Epoch 382/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6783 - accuracy: 0.6499 - precision_5: 0.6136 - recall_5: 0.5776 - val_loss: 0.6288 - val_accuracy: 0.6433 - val_precision_5: 0.6014 - val_recall_5: 0.5909\n",
            "Epoch 383/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6779 - accuracy: 0.6510 - precision_5: 0.6149 - recall_5: 0.5793 - val_loss: 0.6306 - val_accuracy: 0.6403 - val_precision_5: 0.5926 - val_recall_5: 0.6160\n",
            "Epoch 384/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6782 - accuracy: 0.6504 - precision_5: 0.6140 - recall_5: 0.5791 - val_loss: 0.6272 - val_accuracy: 0.6451 - val_precision_5: 0.6064 - val_recall_5: 0.5790\n",
            "Epoch 385/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6780 - accuracy: 0.6502 - precision_5: 0.6142 - recall_5: 0.5774 - val_loss: 0.6284 - val_accuracy: 0.6437 - val_precision_5: 0.5997 - val_recall_5: 0.6021\n",
            "Epoch 386/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6779 - accuracy: 0.6508 - precision_5: 0.6145 - recall_5: 0.5798 - val_loss: 0.6256 - val_accuracy: 0.6485 - val_precision_5: 0.6176 - val_recall_5: 0.5537\n",
            "Epoch 387/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6777 - accuracy: 0.6508 - precision_5: 0.6147 - recall_5: 0.5788 - val_loss: 0.6280 - val_accuracy: 0.6441 - val_precision_5: 0.6028 - val_recall_5: 0.5893\n",
            "Epoch 388/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6781 - accuracy: 0.6502 - precision_5: 0.6139 - recall_5: 0.5782 - val_loss: 0.6256 - val_accuracy: 0.6476 - val_precision_5: 0.6187 - val_recall_5: 0.5443\n",
            "Epoch 389/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6778 - accuracy: 0.6510 - precision_5: 0.6150 - recall_5: 0.5790 - val_loss: 0.6288 - val_accuracy: 0.6431 - val_precision_5: 0.6003 - val_recall_5: 0.5949\n",
            "Epoch 390/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6778 - accuracy: 0.6504 - precision_5: 0.6141 - recall_5: 0.5788 - val_loss: 0.6274 - val_accuracy: 0.6447 - val_precision_5: 0.6065 - val_recall_5: 0.5762\n",
            "Epoch 391/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6777 - accuracy: 0.6509 - precision_5: 0.6148 - recall_5: 0.5787 - val_loss: 0.6283 - val_accuracy: 0.6435 - val_precision_5: 0.6029 - val_recall_5: 0.5848\n",
            "Epoch 392/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6778 - accuracy: 0.6498 - precision_5: 0.6132 - recall_5: 0.5789 - val_loss: 0.6257 - val_accuracy: 0.6469 - val_precision_5: 0.6131 - val_recall_5: 0.5620\n",
            "Epoch 393/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6777 - accuracy: 0.6512 - precision_5: 0.6151 - recall_5: 0.5798 - val_loss: 0.6279 - val_accuracy: 0.6450 - val_precision_5: 0.6051 - val_recall_5: 0.5849\n",
            "Epoch 394/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6777 - accuracy: 0.6506 - precision_5: 0.6146 - recall_5: 0.5784 - val_loss: 0.6277 - val_accuracy: 0.6450 - val_precision_5: 0.6052 - val_recall_5: 0.5843\n",
            "Epoch 395/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6778 - accuracy: 0.6506 - precision_5: 0.6141 - recall_5: 0.5804 - val_loss: 0.6252 - val_accuracy: 0.6479 - val_precision_5: 0.6186 - val_recall_5: 0.5469\n",
            "Epoch 396/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6781 - accuracy: 0.6508 - precision_5: 0.6150 - recall_5: 0.5780 - val_loss: 0.6246 - val_accuracy: 0.6491 - val_precision_5: 0.6255 - val_recall_5: 0.5289\n",
            "Epoch 397/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6779 - accuracy: 0.6508 - precision_5: 0.6147 - recall_5: 0.5788 - val_loss: 0.6289 - val_accuracy: 0.6432 - val_precision_5: 0.6006 - val_recall_5: 0.5943\n",
            "Epoch 398/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6777 - accuracy: 0.6515 - precision_5: 0.6157 - recall_5: 0.5793 - val_loss: 0.6288 - val_accuracy: 0.6447 - val_precision_5: 0.6053 - val_recall_5: 0.5818\n",
            "Epoch 399/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6776 - accuracy: 0.6515 - precision_5: 0.6157 - recall_5: 0.5791 - val_loss: 0.6243 - val_accuracy: 0.6504 - val_precision_5: 0.6305 - val_recall_5: 0.5200\n",
            "Epoch 400/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6779 - accuracy: 0.6511 - precision_5: 0.6152 - recall_5: 0.5785 - val_loss: 0.6268 - val_accuracy: 0.6463 - val_precision_5: 0.6116 - val_recall_5: 0.5642\n",
            "Epoch 401/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6776 - accuracy: 0.6512 - precision_5: 0.6150 - recall_5: 0.5800 - val_loss: 0.6262 - val_accuracy: 0.6476 - val_precision_5: 0.6174 - val_recall_5: 0.5492\n",
            "Epoch 402/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6775 - accuracy: 0.6514 - precision_5: 0.6155 - recall_5: 0.5793 - val_loss: 0.6290 - val_accuracy: 0.6428 - val_precision_5: 0.6002 - val_recall_5: 0.5939\n",
            "Epoch 403/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6782 - accuracy: 0.6505 - precision_5: 0.6141 - recall_5: 0.5793 - val_loss: 0.6269 - val_accuracy: 0.6447 - val_precision_5: 0.6085 - val_recall_5: 0.5678\n",
            "Epoch 404/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6775 - accuracy: 0.6513 - precision_5: 0.6155 - recall_5: 0.5783 - val_loss: 0.6272 - val_accuracy: 0.6447 - val_precision_5: 0.6032 - val_recall_5: 0.5911\n",
            "Epoch 405/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6774 - accuracy: 0.6510 - precision_5: 0.6150 - recall_5: 0.5788 - val_loss: 0.6259 - val_accuracy: 0.6474 - val_precision_5: 0.6168 - val_recall_5: 0.5507\n",
            "Epoch 406/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6778 - accuracy: 0.6505 - precision_5: 0.6138 - recall_5: 0.5804 - val_loss: 0.6284 - val_accuracy: 0.6452 - val_precision_5: 0.6045 - val_recall_5: 0.5883\n",
            "Epoch 407/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6775 - accuracy: 0.6513 - precision_5: 0.6154 - recall_5: 0.5793 - val_loss: 0.6295 - val_accuracy: 0.6420 - val_precision_5: 0.5947 - val_recall_5: 0.6164\n",
            "Epoch 408/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6776 - accuracy: 0.6516 - precision_5: 0.6155 - recall_5: 0.5804 - val_loss: 0.6280 - val_accuracy: 0.6457 - val_precision_5: 0.6078 - val_recall_5: 0.5765\n",
            "Epoch 409/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6777 - accuracy: 0.6510 - precision_5: 0.6149 - recall_5: 0.5796 - val_loss: 0.6249 - val_accuracy: 0.6483 - val_precision_5: 0.6208 - val_recall_5: 0.5404\n",
            "Epoch 410/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6777 - accuracy: 0.6507 - precision_5: 0.6143 - recall_5: 0.5798 - val_loss: 0.6280 - val_accuracy: 0.6449 - val_precision_5: 0.6075 - val_recall_5: 0.5731\n",
            "Epoch 411/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6776 - accuracy: 0.6509 - precision_5: 0.6148 - recall_5: 0.5793 - val_loss: 0.6280 - val_accuracy: 0.6428 - val_precision_5: 0.6020 - val_recall_5: 0.5845\n",
            "Epoch 412/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6776 - accuracy: 0.6511 - precision_5: 0.6150 - recall_5: 0.5794 - val_loss: 0.6248 - val_accuracy: 0.6487 - val_precision_5: 0.6270 - val_recall_5: 0.5217\n",
            "Epoch 413/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6774 - accuracy: 0.6516 - precision_5: 0.6154 - recall_5: 0.5811 - val_loss: 0.6258 - val_accuracy: 0.6470 - val_precision_5: 0.6191 - val_recall_5: 0.5398\n",
            "Epoch 414/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6775 - accuracy: 0.6515 - precision_5: 0.6157 - recall_5: 0.5789 - val_loss: 0.6274 - val_accuracy: 0.6456 - val_precision_5: 0.6058 - val_recall_5: 0.5851\n",
            "Epoch 415/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6774 - accuracy: 0.6517 - precision_5: 0.6156 - recall_5: 0.5809 - val_loss: 0.6271 - val_accuracy: 0.6463 - val_precision_5: 0.6092 - val_recall_5: 0.5744\n",
            "Epoch 416/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6773 - accuracy: 0.6519 - precision_5: 0.6158 - recall_5: 0.5810 - val_loss: 0.6264 - val_accuracy: 0.6464 - val_precision_5: 0.6133 - val_recall_5: 0.5581\n",
            "Epoch 417/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6775 - accuracy: 0.6511 - precision_5: 0.6154 - recall_5: 0.5780 - val_loss: 0.6260 - val_accuracy: 0.6484 - val_precision_5: 0.6158 - val_recall_5: 0.5600\n",
            "Epoch 418/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6776 - accuracy: 0.6511 - precision_5: 0.6148 - recall_5: 0.5801 - val_loss: 0.6273 - val_accuracy: 0.6466 - val_precision_5: 0.6106 - val_recall_5: 0.5701\n",
            "Epoch 419/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6775 - accuracy: 0.6517 - precision_5: 0.6156 - recall_5: 0.5810 - val_loss: 0.6260 - val_accuracy: 0.6481 - val_precision_5: 0.6196 - val_recall_5: 0.5438\n",
            "Epoch 420/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6773 - accuracy: 0.6508 - precision_5: 0.6145 - recall_5: 0.5799 - val_loss: 0.6330 - val_accuracy: 0.6377 - val_precision_5: 0.5873 - val_recall_5: 0.6279\n",
            "Epoch 421/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6774 - accuracy: 0.6514 - precision_5: 0.6157 - recall_5: 0.5788 - val_loss: 0.6314 - val_accuracy: 0.6397 - val_precision_5: 0.5901 - val_recall_5: 0.6257\n",
            "Epoch 422/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6772 - accuracy: 0.6510 - precision_5: 0.6147 - recall_5: 0.5802 - val_loss: 0.6289 - val_accuracy: 0.6425 - val_precision_5: 0.5961 - val_recall_5: 0.6123\n",
            "Epoch 423/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6774 - accuracy: 0.6509 - precision_5: 0.6148 - recall_5: 0.5792 - val_loss: 0.6288 - val_accuracy: 0.6430 - val_precision_5: 0.5986 - val_recall_5: 0.6027\n",
            "Epoch 424/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6776 - accuracy: 0.6507 - precision_5: 0.6138 - recall_5: 0.5816 - val_loss: 0.6252 - val_accuracy: 0.6483 - val_precision_5: 0.6197 - val_recall_5: 0.5449\n",
            "Epoch 425/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6773 - accuracy: 0.6510 - precision_5: 0.6152 - recall_5: 0.5784 - val_loss: 0.6281 - val_accuracy: 0.6458 - val_precision_5: 0.6071 - val_recall_5: 0.5807\n",
            "Epoch 426/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6775 - accuracy: 0.6511 - precision_5: 0.6152 - recall_5: 0.5786 - val_loss: 0.6304 - val_accuracy: 0.6421 - val_precision_5: 0.5964 - val_recall_5: 0.6082\n",
            "Epoch 427/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6776 - accuracy: 0.6508 - precision_5: 0.6146 - recall_5: 0.5793 - val_loss: 0.6268 - val_accuracy: 0.6460 - val_precision_5: 0.6091 - val_recall_5: 0.5727\n",
            "Epoch 428/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6773 - accuracy: 0.6515 - precision_5: 0.6154 - recall_5: 0.5800 - val_loss: 0.6250 - val_accuracy: 0.6491 - val_precision_5: 0.6226 - val_recall_5: 0.5389\n",
            "Epoch 429/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6774 - accuracy: 0.6516 - precision_5: 0.6154 - recall_5: 0.5806 - val_loss: 0.6269 - val_accuracy: 0.6460 - val_precision_5: 0.6101 - val_recall_5: 0.5692\n",
            "Epoch 430/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6774 - accuracy: 0.6513 - precision_5: 0.6151 - recall_5: 0.5804 - val_loss: 0.6260 - val_accuracy: 0.6466 - val_precision_5: 0.6127 - val_recall_5: 0.5616\n",
            "Epoch 431/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6774 - accuracy: 0.6507 - precision_5: 0.6144 - recall_5: 0.5792 - val_loss: 0.6258 - val_accuracy: 0.6480 - val_precision_5: 0.6150 - val_recall_5: 0.5609\n",
            "Epoch 432/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6770 - accuracy: 0.6518 - precision_5: 0.6158 - recall_5: 0.5802 - val_loss: 0.6258 - val_accuracy: 0.6470 - val_precision_5: 0.6179 - val_recall_5: 0.5437\n",
            "Epoch 433/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6772 - accuracy: 0.6513 - precision_5: 0.6151 - recall_5: 0.5804 - val_loss: 0.6261 - val_accuracy: 0.6465 - val_precision_5: 0.6123 - val_recall_5: 0.5628\n",
            "Epoch 434/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6774 - accuracy: 0.6511 - precision_5: 0.6150 - recall_5: 0.5797 - val_loss: 0.6271 - val_accuracy: 0.6475 - val_precision_5: 0.6124 - val_recall_5: 0.5684\n",
            "Epoch 435/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6775 - accuracy: 0.6512 - precision_5: 0.6153 - recall_5: 0.5790 - val_loss: 0.6261 - val_accuracy: 0.6479 - val_precision_5: 0.6205 - val_recall_5: 0.5396\n",
            "Epoch 436/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6775 - accuracy: 0.6517 - precision_5: 0.6156 - recall_5: 0.5804 - val_loss: 0.6234 - val_accuracy: 0.6503 - val_precision_5: 0.6381 - val_recall_5: 0.4968\n",
            "Epoch 437/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6772 - accuracy: 0.6514 - precision_5: 0.6152 - recall_5: 0.5804 - val_loss: 0.6268 - val_accuracy: 0.6449 - val_precision_5: 0.6120 - val_recall_5: 0.5542\n",
            "Epoch 438/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6772 - accuracy: 0.6509 - precision_5: 0.6147 - recall_5: 0.5794 - val_loss: 0.6277 - val_accuracy: 0.6431 - val_precision_5: 0.6010 - val_recall_5: 0.5915\n",
            "Epoch 439/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6771 - accuracy: 0.6516 - precision_5: 0.6156 - recall_5: 0.5801 - val_loss: 0.6284 - val_accuracy: 0.6427 - val_precision_5: 0.5984 - val_recall_5: 0.6019\n",
            "Epoch 440/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6773 - accuracy: 0.6513 - precision_5: 0.6151 - recall_5: 0.5803 - val_loss: 0.6276 - val_accuracy: 0.6448 - val_precision_5: 0.6020 - val_recall_5: 0.5980\n",
            "Epoch 441/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6773 - accuracy: 0.6509 - precision_5: 0.6142 - recall_5: 0.5815 - val_loss: 0.6269 - val_accuracy: 0.6464 - val_precision_5: 0.6157 - val_recall_5: 0.5489\n",
            "Epoch 442/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6774 - accuracy: 0.6510 - precision_5: 0.6149 - recall_5: 0.5791 - val_loss: 0.6256 - val_accuracy: 0.6478 - val_precision_5: 0.6174 - val_recall_5: 0.5505\n",
            "Epoch 443/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6773 - accuracy: 0.6512 - precision_5: 0.6151 - recall_5: 0.5795 - val_loss: 0.6251 - val_accuracy: 0.6488 - val_precision_5: 0.6182 - val_recall_5: 0.5529\n",
            "Epoch 444/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6771 - accuracy: 0.6519 - precision_5: 0.6160 - recall_5: 0.5804 - val_loss: 0.6260 - val_accuracy: 0.6470 - val_precision_5: 0.6158 - val_recall_5: 0.5518\n",
            "Epoch 445/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6772 - accuracy: 0.6515 - precision_5: 0.6156 - recall_5: 0.5797 - val_loss: 0.6287 - val_accuracy: 0.6429 - val_precision_5: 0.6002 - val_recall_5: 0.5937\n",
            "Epoch 446/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6773 - accuracy: 0.6510 - precision_5: 0.6150 - recall_5: 0.5793 - val_loss: 0.6252 - val_accuracy: 0.6484 - val_precision_5: 0.6193 - val_recall_5: 0.5468\n",
            "Epoch 447/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6770 - accuracy: 0.6519 - precision_5: 0.6161 - recall_5: 0.5798 - val_loss: 0.6255 - val_accuracy: 0.6493 - val_precision_5: 0.6168 - val_recall_5: 0.5618\n",
            "Epoch 448/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6770 - accuracy: 0.6517 - precision_5: 0.6156 - recall_5: 0.5809 - val_loss: 0.6273 - val_accuracy: 0.6448 - val_precision_5: 0.6072 - val_recall_5: 0.5738\n",
            "Epoch 449/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6771 - accuracy: 0.6514 - precision_5: 0.6152 - recall_5: 0.5803 - val_loss: 0.6260 - val_accuracy: 0.6476 - val_precision_5: 0.6184 - val_recall_5: 0.5454\n",
            "Epoch 450/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6773 - accuracy: 0.6517 - precision_5: 0.6157 - recall_5: 0.5804 - val_loss: 0.6250 - val_accuracy: 0.6481 - val_precision_5: 0.6171 - val_recall_5: 0.5534\n",
            "Epoch 451/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6770 - accuracy: 0.6518 - precision_5: 0.6154 - recall_5: 0.5822 - val_loss: 0.6246 - val_accuracy: 0.6498 - val_precision_5: 0.6282 - val_recall_5: 0.5236\n",
            "Epoch 452/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6773 - accuracy: 0.6512 - precision_5: 0.6152 - recall_5: 0.5794 - val_loss: 0.6314 - val_accuracy: 0.6404 - val_precision_5: 0.5921 - val_recall_5: 0.6193\n",
            "Epoch 453/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6771 - accuracy: 0.6514 - precision_5: 0.6152 - recall_5: 0.5808 - val_loss: 0.6244 - val_accuracy: 0.6495 - val_precision_5: 0.6257 - val_recall_5: 0.5305\n",
            "Epoch 454/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6770 - accuracy: 0.6519 - precision_5: 0.6160 - recall_5: 0.5804 - val_loss: 0.6286 - val_accuracy: 0.6435 - val_precision_5: 0.6014 - val_recall_5: 0.5918\n",
            "Epoch 455/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6770 - accuracy: 0.6522 - precision_5: 0.6165 - recall_5: 0.5801 - val_loss: 0.6315 - val_accuracy: 0.6395 - val_precision_5: 0.5903 - val_recall_5: 0.6232\n",
            "Epoch 456/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6771 - accuracy: 0.6510 - precision_5: 0.6146 - recall_5: 0.5807 - val_loss: 0.6265 - val_accuracy: 0.6460 - val_precision_5: 0.6132 - val_recall_5: 0.5560\n",
            "Epoch 457/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6769 - accuracy: 0.6522 - precision_5: 0.6162 - recall_5: 0.5810 - val_loss: 0.6249 - val_accuracy: 0.6487 - val_precision_5: 0.6235 - val_recall_5: 0.5337\n",
            "Epoch 458/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6772 - accuracy: 0.6513 - precision_5: 0.6154 - recall_5: 0.5789 - val_loss: 0.6290 - val_accuracy: 0.6438 - val_precision_5: 0.6011 - val_recall_5: 0.5961\n",
            "Epoch 459/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6769 - accuracy: 0.6517 - precision_5: 0.6151 - recall_5: 0.5828 - val_loss: 0.6259 - val_accuracy: 0.6491 - val_precision_5: 0.6281 - val_recall_5: 0.5204\n",
            "Epoch 460/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6772 - accuracy: 0.6511 - precision_5: 0.6150 - recall_5: 0.5796 - val_loss: 0.6265 - val_accuracy: 0.6470 - val_precision_5: 0.6211 - val_recall_5: 0.5324\n",
            "Epoch 461/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6770 - accuracy: 0.6513 - precision_5: 0.6153 - recall_5: 0.5797 - val_loss: 0.6242 - val_accuracy: 0.6501 - val_precision_5: 0.6334 - val_recall_5: 0.5095\n",
            "Epoch 462/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6769 - accuracy: 0.6514 - precision_5: 0.6156 - recall_5: 0.5790 - val_loss: 0.6296 - val_accuracy: 0.6413 - val_precision_5: 0.5944 - val_recall_5: 0.6129\n",
            "Epoch 463/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6771 - accuracy: 0.6512 - precision_5: 0.6150 - recall_5: 0.5806 - val_loss: 0.6274 - val_accuracy: 0.6457 - val_precision_5: 0.6079 - val_recall_5: 0.5765\n",
            "Epoch 464/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6770 - accuracy: 0.6515 - precision_5: 0.6154 - recall_5: 0.5802 - val_loss: 0.6379 - val_accuracy: 0.6299 - val_precision_5: 0.5711 - val_recall_5: 0.6794\n",
            "Epoch 465/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6768 - accuracy: 0.6524 - precision_5: 0.6165 - recall_5: 0.5811 - val_loss: 0.6282 - val_accuracy: 0.6448 - val_precision_5: 0.6032 - val_recall_5: 0.5920\n",
            "Epoch 466/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6769 - accuracy: 0.6519 - precision_5: 0.6155 - recall_5: 0.5819 - val_loss: 0.6255 - val_accuracy: 0.6491 - val_precision_5: 0.6219 - val_recall_5: 0.5413\n",
            "Epoch 467/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6769 - accuracy: 0.6517 - precision_5: 0.6156 - recall_5: 0.5806 - val_loss: 0.6259 - val_accuracy: 0.6482 - val_precision_5: 0.6178 - val_recall_5: 0.5512\n",
            "Epoch 468/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6768 - accuracy: 0.6517 - precision_5: 0.6156 - recall_5: 0.5810 - val_loss: 0.6241 - val_accuracy: 0.6492 - val_precision_5: 0.6243 - val_recall_5: 0.5336\n",
            "Epoch 469/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6770 - accuracy: 0.6513 - precision_5: 0.6153 - recall_5: 0.5795 - val_loss: 0.6284 - val_accuracy: 0.6443 - val_precision_5: 0.6032 - val_recall_5: 0.5888\n",
            "Epoch 470/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6769 - accuracy: 0.6517 - precision_5: 0.6155 - recall_5: 0.5813 - val_loss: 0.6293 - val_accuracy: 0.6439 - val_precision_5: 0.6021 - val_recall_5: 0.5914\n",
            "Epoch 471/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6770 - accuracy: 0.6516 - precision_5: 0.6154 - recall_5: 0.5809 - val_loss: 0.6281 - val_accuracy: 0.6448 - val_precision_5: 0.6045 - val_recall_5: 0.5861\n",
            "Epoch 472/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6770 - accuracy: 0.6520 - precision_5: 0.6160 - recall_5: 0.5807 - val_loss: 0.6274 - val_accuracy: 0.6464 - val_precision_5: 0.6097 - val_recall_5: 0.5732\n",
            "Epoch 473/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6770 - accuracy: 0.6517 - precision_5: 0.6155 - recall_5: 0.5811 - val_loss: 0.6242 - val_accuracy: 0.6494 - val_precision_5: 0.6260 - val_recall_5: 0.5288\n",
            "Epoch 474/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6767 - accuracy: 0.6520 - precision_5: 0.6161 - recall_5: 0.5806 - val_loss: 0.6255 - val_accuracy: 0.6487 - val_precision_5: 0.6188 - val_recall_5: 0.5502\n",
            "Epoch 475/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6768 - accuracy: 0.6520 - precision_5: 0.6158 - recall_5: 0.5815 - val_loss: 0.6240 - val_accuracy: 0.6500 - val_precision_5: 0.6372 - val_recall_5: 0.4978\n",
            "Epoch 476/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6769 - accuracy: 0.6518 - precision_5: 0.6157 - recall_5: 0.5807 - val_loss: 0.6298 - val_accuracy: 0.6427 - val_precision_5: 0.5981 - val_recall_5: 0.6034\n",
            "Epoch 477/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6769 - accuracy: 0.6525 - precision_5: 0.6168 - recall_5: 0.5804 - val_loss: 0.6319 - val_accuracy: 0.6401 - val_precision_5: 0.5909 - val_recall_5: 0.6242\n",
            "Epoch 478/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6768 - accuracy: 0.6519 - precision_5: 0.6156 - recall_5: 0.5816 - val_loss: 0.6295 - val_accuracy: 0.6418 - val_precision_5: 0.5968 - val_recall_5: 0.6034\n",
            "Epoch 479/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6770 - accuracy: 0.6515 - precision_5: 0.6155 - recall_5: 0.5803 - val_loss: 0.6235 - val_accuracy: 0.6514 - val_precision_5: 0.6361 - val_recall_5: 0.5080\n",
            "Epoch 480/500\n",
            "351/351 [==============================] - 3s 10ms/step - loss: 0.6769 - accuracy: 0.6516 - precision_5: 0.6152 - recall_5: 0.5815 - val_loss: 0.6271 - val_accuracy: 0.6451 - val_precision_5: 0.6047 - val_recall_5: 0.5873\n",
            "Epoch 481/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6767 - accuracy: 0.6519 - precision_5: 0.6156 - recall_5: 0.5818 - val_loss: 0.6258 - val_accuracy: 0.6490 - val_precision_5: 0.6228 - val_recall_5: 0.5373\n",
            "Epoch 482/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6767 - accuracy: 0.6513 - precision_5: 0.6151 - recall_5: 0.5804 - val_loss: 0.6259 - val_accuracy: 0.6465 - val_precision_5: 0.6118 - val_recall_5: 0.5650\n",
            "Epoch 483/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6769 - accuracy: 0.6515 - precision_5: 0.6152 - recall_5: 0.5811 - val_loss: 0.6297 - val_accuracy: 0.6419 - val_precision_5: 0.5943 - val_recall_5: 0.6181\n",
            "Epoch 484/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6769 - accuracy: 0.6513 - precision_5: 0.6152 - recall_5: 0.5798 - val_loss: 0.6258 - val_accuracy: 0.6476 - val_precision_5: 0.6134 - val_recall_5: 0.5653\n",
            "Epoch 485/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6768 - accuracy: 0.6516 - precision_5: 0.6153 - recall_5: 0.5813 - val_loss: 0.6271 - val_accuracy: 0.6467 - val_precision_5: 0.6128 - val_recall_5: 0.5622\n",
            "Epoch 486/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6766 - accuracy: 0.6519 - precision_5: 0.6162 - recall_5: 0.5797 - val_loss: 0.6340 - val_accuracy: 0.6357 - val_precision_5: 0.5819 - val_recall_5: 0.6468\n",
            "Epoch 487/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6769 - accuracy: 0.6518 - precision_5: 0.6151 - recall_5: 0.5830 - val_loss: 0.6267 - val_accuracy: 0.6484 - val_precision_5: 0.6276 - val_recall_5: 0.5180\n",
            "Epoch 488/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6769 - accuracy: 0.6521 - precision_5: 0.6164 - recall_5: 0.5797 - val_loss: 0.6239 - val_accuracy: 0.6496 - val_precision_5: 0.6321 - val_recall_5: 0.5108\n",
            "Epoch 489/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6767 - accuracy: 0.6516 - precision_5: 0.6150 - recall_5: 0.5821 - val_loss: 0.6291 - val_accuracy: 0.6443 - val_precision_5: 0.6039 - val_recall_5: 0.5856\n",
            "Epoch 490/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6766 - accuracy: 0.6522 - precision_5: 0.6161 - recall_5: 0.5817 - val_loss: 0.6254 - val_accuracy: 0.6468 - val_precision_5: 0.6140 - val_recall_5: 0.5575\n",
            "Epoch 491/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6768 - accuracy: 0.6520 - precision_5: 0.6156 - recall_5: 0.5822 - val_loss: 0.6281 - val_accuracy: 0.6450 - val_precision_5: 0.6080 - val_recall_5: 0.5716\n",
            "Epoch 492/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6767 - accuracy: 0.6521 - precision_5: 0.6161 - recall_5: 0.5810 - val_loss: 0.6272 - val_accuracy: 0.6456 - val_precision_5: 0.6075 - val_recall_5: 0.5776\n",
            "Epoch 493/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6767 - accuracy: 0.6516 - precision_5: 0.6155 - recall_5: 0.5804 - val_loss: 0.6264 - val_accuracy: 0.6468 - val_precision_5: 0.6080 - val_recall_5: 0.5832\n",
            "Epoch 494/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6765 - accuracy: 0.6522 - precision_5: 0.6160 - recall_5: 0.5821 - val_loss: 0.6269 - val_accuracy: 0.6456 - val_precision_5: 0.6080 - val_recall_5: 0.5756\n",
            "Epoch 495/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6770 - accuracy: 0.6513 - precision_5: 0.6149 - recall_5: 0.5811 - val_loss: 0.6283 - val_accuracy: 0.6448 - val_precision_5: 0.6036 - val_recall_5: 0.5906\n",
            "Epoch 496/500\n",
            "351/351 [==============================] - 3s 7ms/step - loss: 0.6766 - accuracy: 0.6522 - precision_5: 0.6160 - recall_5: 0.5822 - val_loss: 0.6272 - val_accuracy: 0.6456 - val_precision_5: 0.6064 - val_recall_5: 0.5824\n",
            "Epoch 497/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6766 - accuracy: 0.6517 - precision_5: 0.6156 - recall_5: 0.5810 - val_loss: 0.6264 - val_accuracy: 0.6472 - val_precision_5: 0.6132 - val_recall_5: 0.5632\n",
            "Epoch 498/500\n",
            "351/351 [==============================] - 3s 9ms/step - loss: 0.6766 - accuracy: 0.6521 - precision_5: 0.6161 - recall_5: 0.5810 - val_loss: 0.6267 - val_accuracy: 0.6461 - val_precision_5: 0.6078 - val_recall_5: 0.5795\n",
            "Epoch 499/500\n",
            "351/351 [==============================] - 2s 7ms/step - loss: 0.6767 - accuracy: 0.6518 - precision_5: 0.6155 - recall_5: 0.5819 - val_loss: 0.6285 - val_accuracy: 0.6438 - val_precision_5: 0.6008 - val_recall_5: 0.5975\n",
            "Epoch 500/500\n",
            "351/351 [==============================] - 3s 8ms/step - loss: 0.6768 - accuracy: 0.6518 - precision_5: 0.6159 - recall_5: 0.5801 - val_loss: 0.6276 - val_accuracy: 0.6445 - val_precision_5: 0.6017 - val_recall_5: 0.5972\n",
            "Test Loss: 0.6276174783706665\n",
            "Test Accuracy: 0.6445143818855286\n",
            "Test Precision: 0.6017492413520813\n",
            "Test Recall: 0.597241222858429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predict classes for the test set\n",
        "y_pred_prob = model.predict(test_df_x)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# generate confusion matrix\n",
        "cm = confusion_matrix(test_df_y, y_pred, labels=[0,1])\n",
        "\n",
        "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=['On Time', 'Delayed'], yticklabels=['On Time', 'Delayed'])\n",
        "\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "\n",
        "# print confusion matrix\n",
        "print('Confusion Matrix: ')\n",
        "print(cm)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PWsK5QOaNAjv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "7ad174d2-8eee-4c66-c25b-593ecbb5f4b6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5900/5900 [==============================] - 7s 1ms/step\n",
            "Confusion Matrix: \n",
            "[[71449 33240]\n",
            " [33870 50225]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}