{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHnpIrYEOaLT7ceM8/CDR0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/titusjscott/multi-layer-perceptron/blob/main/airline_delay_MLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ_zj5dpaekW",
        "outputId": "333ad405-ca98-46e7-c885-da3ad36ce39c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.8/dist-packages (1.3.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (1.0.4)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (7.9.0)\n",
            "Requirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.25.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (23.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.19.6)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (15.0.6.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.22.4)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (4.5.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (23.1.21)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.51.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.30.0)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.18.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (5.7.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0->keras-tuner) (0.38.4)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.16.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (6.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.14.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "UBSsx0lrwlrI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.metrics import Precision, Recall\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelBinarizer, MinMaxScaler, Normalizer, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.metrics import Precision, Recall\n",
        "from kerastuner.tuners import RandomSearch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/titusjscott/multi-layer-perceptron/main/airlines_delay.csv\")\n"
      ],
      "metadata": {
        "id": "bp7nO5QswoRD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "KdgFlS5exEtW",
        "outputId": "23d0db41-092c-49a1-fbf6-a1869448bf3e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Flight    Time  Length Airline AirportFrom AirportTo  DayOfWeek  Class\n",
              "0  2313.0  1296.0   141.0      DL         ATL       HOU          1      0\n",
              "1  6948.0   360.0   146.0      OO         COS       ORD          4      0\n",
              "2  1247.0  1170.0   143.0      B6         BOS       CLT          3      0\n",
              "3    31.0  1410.0   344.0      US         OGG       PHX          6      0\n",
              "4   563.0   692.0    98.0      FL         BMI       ATL          4      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8a36254-5aa6-44bf-bca3-f19b8c264058\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Flight</th>\n",
              "      <th>Time</th>\n",
              "      <th>Length</th>\n",
              "      <th>Airline</th>\n",
              "      <th>AirportFrom</th>\n",
              "      <th>AirportTo</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2313.0</td>\n",
              "      <td>1296.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>DL</td>\n",
              "      <td>ATL</td>\n",
              "      <td>HOU</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6948.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>OO</td>\n",
              "      <td>COS</td>\n",
              "      <td>ORD</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1247.0</td>\n",
              "      <td>1170.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>B6</td>\n",
              "      <td>BOS</td>\n",
              "      <td>CLT</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31.0</td>\n",
              "      <td>1410.0</td>\n",
              "      <td>344.0</td>\n",
              "      <td>US</td>\n",
              "      <td>OGG</td>\n",
              "      <td>PHX</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>563.0</td>\n",
              "      <td>692.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>FL</td>\n",
              "      <td>BMI</td>\n",
              "      <td>ATL</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8a36254-5aa6-44bf-bca3-f19b8c264058')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a8a36254-5aa6-44bf-bca3-f19b8c264058 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a8a36254-5aa6-44bf-bca3-f19b8c264058');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "334dWecVxe3i",
        "outputId": "844eb8ff-a5b2-4eab-e9dd-c7b3798c04db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Flight         0\n",
              "Time           0\n",
              "Length         0\n",
              "Airline        0\n",
              "AirportFrom    0\n",
              "AirportTo      0\n",
              "DayOfWeek      0\n",
              "Class          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc-jLlQckmFq",
        "outputId": "dec3140d-d825-4560-8b2d-93e5db2c2ab2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 539382 entries, 0 to 539381\n",
            "Data columns (total 8 columns):\n",
            " #   Column       Non-Null Count   Dtype  \n",
            "---  ------       --------------   -----  \n",
            " 0   Flight       539382 non-null  float64\n",
            " 1   Time         539382 non-null  float64\n",
            " 2   Length       539382 non-null  float64\n",
            " 3   Airline      539382 non-null  object \n",
            " 4   AirportFrom  539382 non-null  object \n",
            " 5   AirportTo    539382 non-null  object \n",
            " 6   DayOfWeek    539382 non-null  int64  \n",
            " 7   Class        539382 non-null  int64  \n",
            "dtypes: float64(3), int64(2), object(3)\n",
            "memory usage: 32.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "WIOH82vzkc8S",
        "outputId": "b8ba6d82-9efc-4432-8187-8855a97d08d5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Flight           Time         Length      DayOfWeek  \\\n",
              "count  539382.000000  539382.000000  539382.000000  539382.000000   \n",
              "mean     2427.927988     802.728161     132.202104       3.929666   \n",
              "std      2067.431700     278.045546      70.117045       1.914666   \n",
              "min         1.000000      10.000000       0.000000       1.000000   \n",
              "25%       712.000000     565.000000      81.000000       2.000000   \n",
              "50%      1809.000000     795.000000     115.000000       4.000000   \n",
              "75%      3745.000000    1035.000000     162.000000       5.000000   \n",
              "max      7814.000000    1439.000000     655.000000       7.000000   \n",
              "\n",
              "               Class  \n",
              "count  539382.000000  \n",
              "mean        0.445443  \n",
              "std         0.497015  \n",
              "min         0.000000  \n",
              "25%         0.000000  \n",
              "50%         0.000000  \n",
              "75%         1.000000  \n",
              "max         1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b084a9a6-ca8a-4adc-9f5e-5072ba7d5170\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Flight</th>\n",
              "      <th>Time</th>\n",
              "      <th>Length</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>539382.000000</td>\n",
              "      <td>539382.000000</td>\n",
              "      <td>539382.000000</td>\n",
              "      <td>539382.000000</td>\n",
              "      <td>539382.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2427.927988</td>\n",
              "      <td>802.728161</td>\n",
              "      <td>132.202104</td>\n",
              "      <td>3.929666</td>\n",
              "      <td>0.445443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2067.431700</td>\n",
              "      <td>278.045546</td>\n",
              "      <td>70.117045</td>\n",
              "      <td>1.914666</td>\n",
              "      <td>0.497015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>712.000000</td>\n",
              "      <td>565.000000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1809.000000</td>\n",
              "      <td>795.000000</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3745.000000</td>\n",
              "      <td>1035.000000</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>7814.000000</td>\n",
              "      <td>1439.000000</td>\n",
              "      <td>655.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b084a9a6-ca8a-4adc-9f5e-5072ba7d5170')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b084a9a6-ca8a-4adc-9f5e-5072ba7d5170 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b084a9a6-ca8a-4adc-9f5e-5072ba7d5170');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df['Class'], label = \"Count\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "FDU4Tp2Sxlsv",
        "outputId": "554f0765-5015-4d6a-f008-ca6a9d778f08"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='Class', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rhzQFNAjDVs",
        "outputId": "bad9ef2e-da4b-479a-a473-9500ba1e8901"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    299118\n",
              "1    240264\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "thE7nZYAkomn",
        "outputId": "ff42b6fa-ecc0-47ed-dae8-5eba77e1ccee"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Flight    Time  Length Airline AirportFrom AirportTo  DayOfWeek  Class\n",
              "0  2313.0  1296.0   141.0      DL         ATL       HOU          1      0\n",
              "1  6948.0   360.0   146.0      OO         COS       ORD          4      0\n",
              "2  1247.0  1170.0   143.0      B6         BOS       CLT          3      0\n",
              "3    31.0  1410.0   344.0      US         OGG       PHX          6      0\n",
              "4   563.0   692.0    98.0      FL         BMI       ATL          4      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ed53fdec-b55d-4bdf-9338-402ca4797ef6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Flight</th>\n",
              "      <th>Time</th>\n",
              "      <th>Length</th>\n",
              "      <th>Airline</th>\n",
              "      <th>AirportFrom</th>\n",
              "      <th>AirportTo</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2313.0</td>\n",
              "      <td>1296.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>DL</td>\n",
              "      <td>ATL</td>\n",
              "      <td>HOU</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6948.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>OO</td>\n",
              "      <td>COS</td>\n",
              "      <td>ORD</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1247.0</td>\n",
              "      <td>1170.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>B6</td>\n",
              "      <td>BOS</td>\n",
              "      <td>CLT</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31.0</td>\n",
              "      <td>1410.0</td>\n",
              "      <td>344.0</td>\n",
              "      <td>US</td>\n",
              "      <td>OGG</td>\n",
              "      <td>PHX</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>563.0</td>\n",
              "      <td>692.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>FL</td>\n",
              "      <td>BMI</td>\n",
              "      <td>ATL</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ed53fdec-b55d-4bdf-9338-402ca4797ef6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ed53fdec-b55d-4bdf-9338-402ca4797ef6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ed53fdec-b55d-4bdf-9338-402ca4797ef6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.iloc[:,1:]"
      ],
      "metadata": {
        "id": "QkQT7YnQm6Ap"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DkMYDVL3m-eL",
        "outputId": "4633b201-8818-43bb-c147-1094dc06a515"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Time  Length Airline AirportFrom AirportTo  DayOfWeek  Class\n",
              "0  1296.0   141.0      DL         ATL       HOU          1      0\n",
              "1   360.0   146.0      OO         COS       ORD          4      0\n",
              "2  1170.0   143.0      B6         BOS       CLT          3      0\n",
              "3  1410.0   344.0      US         OGG       PHX          6      0\n",
              "4   692.0    98.0      FL         BMI       ATL          4      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-05055db2-5502-46bc-a752-fb669e116f0d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>Length</th>\n",
              "      <th>Airline</th>\n",
              "      <th>AirportFrom</th>\n",
              "      <th>AirportTo</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1296.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>DL</td>\n",
              "      <td>ATL</td>\n",
              "      <td>HOU</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>360.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>OO</td>\n",
              "      <td>COS</td>\n",
              "      <td>ORD</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1170.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>B6</td>\n",
              "      <td>BOS</td>\n",
              "      <td>CLT</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1410.0</td>\n",
              "      <td>344.0</td>\n",
              "      <td>US</td>\n",
              "      <td>OGG</td>\n",
              "      <td>PHX</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>692.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>FL</td>\n",
              "      <td>BMI</td>\n",
              "      <td>ATL</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05055db2-5502-46bc-a752-fb669e116f0d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-05055db2-5502-46bc-a752-fb669e116f0d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-05055db2-5502-46bc-a752-fb669e116f0d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Airline'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVaMRZeqMfcA",
        "outputId": "806b2e33-2bec-4fab-9198-cd845ff818d5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DL' 'OO' 'B6' 'US' 'FL' 'WN' 'CO' 'AA' 'YV' 'EV' 'XE' '9E' 'OH' 'UA'\n",
            " 'MQ' 'AS' 'F9' 'HA']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Airline'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwuRFeuHPj0F",
        "outputId": "1e2f1d5d-d2e0-44d7-de2e-236651f90fbe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WN    94097\n",
              "DL    60940\n",
              "OO    50254\n",
              "AA    45656\n",
              "MQ    36604\n",
              "US    34500\n",
              "XE    31126\n",
              "EV    27983\n",
              "UA    27619\n",
              "CO    21118\n",
              "FL    20827\n",
              "9E    20686\n",
              "B6    18112\n",
              "YV    13725\n",
              "OH    12630\n",
              "AS    11471\n",
              "F9     6456\n",
              "HA     5578\n",
              "Name: Airline, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert the airline codes to numeric value\n",
        "le = LabelEncoder()\n",
        "df['Airline_ID'] = le.fit_transform(df['Airline'])\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(1, 18))\n",
        "df['Airline_ID'] = scaler.fit_transform(df[['Airline_ID']])"
      ],
      "metadata": {
        "id": "jcYEUtf4S5ic"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Airline_ID'].unique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNuJ6zkXTszs",
        "outputId": "c1a1bedf-1866-4dec-eddc-55a230554ca7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 6. 13.  4. 15.  9. 16.  5.  2. 18.  7. 17.  1. 12. 14. 11.  3.  8. 10.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Airline_ID'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ImycSLMT_9_",
        "outputId": "68cb5151-4923-4c64-b853-0b5b5192753e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16.0    94097\n",
              "6.0     60940\n",
              "13.0    50254\n",
              "2.0     45656\n",
              "11.0    36604\n",
              "15.0    34500\n",
              "17.0    31126\n",
              "7.0     27983\n",
              "14.0    27619\n",
              "5.0     21118\n",
              "9.0     20827\n",
              "1.0     20686\n",
              "4.0     18112\n",
              "18.0    13725\n",
              "12.0    12630\n",
              "3.0     11471\n",
              "8.0      6456\n",
              "10.0     5578\n",
              "Name: Airline_ID, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['AirportFrom'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mz53iyCtPuZr",
        "outputId": "4ef704ba-01bf-4f38-8359-88efc79e3c7f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ATL    34449\n",
              "ORD    24822\n",
              "DFW    22153\n",
              "DEN    19843\n",
              "LAX    16657\n",
              "       ...  \n",
              "MMH       16\n",
              "SJT       15\n",
              "GUM       10\n",
              "ADK        9\n",
              "ABR        2\n",
              "Name: AirportFrom, Length: 293, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert the AirportFrom codes to numeric value\n",
        "le = LabelEncoder()\n",
        "df['AirportFrom_ID'] = le.fit_transform(df['AirportFrom'])\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(1, 293))\n",
        "df['AirportFrom_ID'] = scaler.fit_transform(df[['AirportFrom_ID']])"
      ],
      "metadata": {
        "id": "z2iEHgLcUm_Y"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['AirportFrom_ID'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQ2vvBTfU5u5",
        "outputId": "133c8ac5-ccf9-4e04-f0be-83e0cd0cc1d0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17.0     34449\n",
              "209.0    24822\n",
              "81.0     22153\n",
              "80.0     19843\n",
              "155.0    16657\n",
              "         ...  \n",
              "190.0       16\n",
              "260.0       15\n",
              "126.0       10\n",
              "9.0          9\n",
              "4.0          2\n",
              "Name: AirportFrom_ID, Length: 293, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['AirportTo'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBYxKdKrP2CO",
        "outputId": "5e3d84c8-c603-46d0-dead-6f95f8e28783"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ATL    34440\n",
              "ORD    24871\n",
              "DFW    22153\n",
              "DEN    19848\n",
              "LAX    16656\n",
              "       ...  \n",
              "MMH       16\n",
              "SJT       15\n",
              "GUM       10\n",
              "ADK        9\n",
              "ABR        2\n",
              "Name: AirportTo, Length: 293, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert the AirportTo codes to numeric value\n",
        "le = LabelEncoder()\n",
        "df['AirportTo_ID'] = le.fit_transform(df['AirportTo'])\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(1, 293))\n",
        "df['AirportTo_ID'] = scaler.fit_transform(df[['AirportTo_ID']])"
      ],
      "metadata": {
        "id": "oSyr4RLAVCgD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['AirportTo_ID'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QfyCQYZVM5r",
        "outputId": "b678d9ad-a221-4954-f499-008ba36cc675"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17.0     34440\n",
              "209.0    24871\n",
              "81.0     22153\n",
              "80.0     19848\n",
              "155.0    16656\n",
              "         ...  \n",
              "190.0       16\n",
              "260.0       15\n",
              "126.0       10\n",
              "9.0          9\n",
              "4.0          2\n",
              "Name: AirportTo_ID, Length: 293, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = df[['Airline', 'AirportFrom', 'AirportTo']]\n",
        "df = df.drop(a, axis=1)\n"
      ],
      "metadata": {
        "id": "xt0FEIOP0YG7"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "p2ZlLSjD2AeT",
        "outputId": "e5a43d0d-cc6a-48b2-8131-362a211d999e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Time  Length  DayOfWeek  Class  Airline_ID  AirportFrom_ID  AirportTo_ID\n",
              "0  1296.0   141.0          1      0         6.0            17.0         130.0\n",
              "1   360.0   146.0          4      0        13.0            66.0         209.0\n",
              "2  1170.0   143.0          3      0         4.0            36.0          61.0\n",
              "3  1410.0   344.0          6      0        15.0           204.0         218.0\n",
              "4   692.0    98.0          4      0         9.0            33.0          17.0\n",
              "5   580.0    60.0          4      0        16.0           199.0          28.0\n",
              "6   690.0   239.0          4      0         5.0            97.0          81.0\n",
              "7  1210.0    80.0          3      0         2.0            81.0         178.0\n",
              "8  1295.0   105.0          7      0         9.0            46.0         120.0\n",
              "9   530.0   108.0          3      0         9.0            17.0         214.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ff3e1bf-120b-4427-9f0a-2cbe45fab728\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>Length</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Class</th>\n",
              "      <th>Airline_ID</th>\n",
              "      <th>AirportFrom_ID</th>\n",
              "      <th>AirportTo_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1296.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>130.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>360.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>209.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1170.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>61.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1410.0</td>\n",
              "      <td>344.0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>218.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>692.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>580.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>199.0</td>\n",
              "      <td>28.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>690.0</td>\n",
              "      <td>239.0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>81.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1210.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>178.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1295.0</td>\n",
              "      <td>105.0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>120.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>530.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>214.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ff3e1bf-120b-4427-9f0a-2cbe45fab728')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4ff3e1bf-120b-4427-9f0a-2cbe45fab728 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4ff3e1bf-120b-4427-9f0a-2cbe45fab728');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols = list(df.columns)\n",
        "cols = [cols[3]] + cols[:3] + cols[4:]\n",
        "df = df[cols]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kXkt3aeC26n6",
        "outputId": "e1b707f8-5719-43dd-f2c1-4e6d56cc5828"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Class    Time  Length  DayOfWeek  Airline_ID  AirportFrom_ID  AirportTo_ID\n",
              "0      0  1296.0   141.0          1         6.0            17.0         130.0\n",
              "1      0   360.0   146.0          4        13.0            66.0         209.0\n",
              "2      0  1170.0   143.0          3         4.0            36.0          61.0\n",
              "3      0  1410.0   344.0          6        15.0           204.0         218.0\n",
              "4      0   692.0    98.0          4         9.0            33.0          17.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c34f79ce-e5ca-43ed-991d-bca4f358b828\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>Time</th>\n",
              "      <th>Length</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Airline_ID</th>\n",
              "      <th>AirportFrom_ID</th>\n",
              "      <th>AirportTo_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1296.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>130.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>146.0</td>\n",
              "      <td>4</td>\n",
              "      <td>13.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>209.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1170.0</td>\n",
              "      <td>143.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>61.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1410.0</td>\n",
              "      <td>344.0</td>\n",
              "      <td>6</td>\n",
              "      <td>15.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>218.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>692.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>4</td>\n",
              "      <td>9.0</td>\n",
              "      <td>33.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c34f79ce-e5ca-43ed-991d-bca4f358b828')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c34f79ce-e5ca-43ed-991d-bca4f358b828 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c34f79ce-e5ca-43ed-991d-bca4f358b828');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df, test_size=0.35, random_state = 40)\n",
        "print(\"Training Data :\", train.shape)\n",
        "print(\"Testing Data :\", test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoDEcX8EntyR",
        "outputId": "6aaf2424-648c-40ec-d090-597428e56b58"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data : (350598, 7)\n",
            "Testing Data : (188784, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "JYFa0jHDoEYn",
        "outputId": "11fdcd8b-1787-4a3a-c2c5-5a1b9141bd08"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Class    Time  Length  DayOfWeek  Airline_ID  AirportFrom_ID  \\\n",
              "263031      1  1063.0   118.0          7        14.0           154.0   \n",
              "97712       1  1330.0   292.0          7        15.0           155.0   \n",
              "536842      1   570.0   165.0          5        16.0            80.0   \n",
              "237511      0   650.0   620.0          1         6.0            17.0   \n",
              "261014      1   510.0   160.0          2        16.0            46.0   \n",
              "\n",
              "        AirportTo_ID  \n",
              "263031          80.0  \n",
              "97712          217.0  \n",
              "536842         203.0  \n",
              "237511         129.0  \n",
              "261014         105.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4d7eaa91-a72c-4691-8edf-2cf9bf9a2f39\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>Time</th>\n",
              "      <th>Length</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Airline_ID</th>\n",
              "      <th>AirportFrom_ID</th>\n",
              "      <th>AirportTo_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>263031</th>\n",
              "      <td>1</td>\n",
              "      <td>1063.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>7</td>\n",
              "      <td>14.0</td>\n",
              "      <td>154.0</td>\n",
              "      <td>80.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97712</th>\n",
              "      <td>1</td>\n",
              "      <td>1330.0</td>\n",
              "      <td>292.0</td>\n",
              "      <td>7</td>\n",
              "      <td>15.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>217.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>536842</th>\n",
              "      <td>1</td>\n",
              "      <td>570.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>5</td>\n",
              "      <td>16.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>203.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237511</th>\n",
              "      <td>0</td>\n",
              "      <td>650.0</td>\n",
              "      <td>620.0</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>129.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261014</th>\n",
              "      <td>1</td>\n",
              "      <td>510.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>2</td>\n",
              "      <td>16.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>105.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4d7eaa91-a72c-4691-8edf-2cf9bf9a2f39')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4d7eaa91-a72c-4691-8edf-2cf9bf9a2f39 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4d7eaa91-a72c-4691-8edf-2cf9bf9a2f39');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MOCwZRFdoI_p",
        "outputId": "c9fe0e56-0a5e-4e9f-ea56-32dc8bdc668d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Class    Time  Length  DayOfWeek  Airline_ID  AirportFrom_ID  \\\n",
              "309672      1  1152.0    77.0          1         7.0            17.0   \n",
              "386273      0  1180.0    79.0          7         6.0           178.0   \n",
              "350725      0   695.0    80.0          1         7.0           288.0   \n",
              "69486       0   925.0   110.0          3        11.0           286.0   \n",
              "417318      1   510.0    80.0          5        11.0            81.0   \n",
              "\n",
              "        AirportTo_ID  \n",
              "309672         116.0  \n",
              "386273         199.0  \n",
              "350725          17.0  \n",
              "69486          209.0  \n",
              "417318          42.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-817f375d-345c-4aad-9b88-907396491211\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>Time</th>\n",
              "      <th>Length</th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Airline_ID</th>\n",
              "      <th>AirportFrom_ID</th>\n",
              "      <th>AirportTo_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>309672</th>\n",
              "      <td>1</td>\n",
              "      <td>1152.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>116.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386273</th>\n",
              "      <td>0</td>\n",
              "      <td>1180.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>7</td>\n",
              "      <td>6.0</td>\n",
              "      <td>178.0</td>\n",
              "      <td>199.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350725</th>\n",
              "      <td>0</td>\n",
              "      <td>695.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69486</th>\n",
              "      <td>0</td>\n",
              "      <td>925.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>3</td>\n",
              "      <td>11.0</td>\n",
              "      <td>286.0</td>\n",
              "      <td>209.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417318</th>\n",
              "      <td>1</td>\n",
              "      <td>510.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>5</td>\n",
              "      <td>11.0</td>\n",
              "      <td>81.0</td>\n",
              "      <td>42.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-817f375d-345c-4aad-9b88-907396491211')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-817f375d-345c-4aad-9b88-907396491211 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-817f375d-345c-4aad-9b88-907396491211');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_x = train.iloc[:,1:]\n",
        "train_df_x = MinMaxScaler().fit_transform(train_df_x)\n",
        "\n",
        "test_df_x = test.iloc[:,1:]\n",
        "test_df_x = MinMaxScaler().fit_transform(test_df_x)\n",
        "\n",
        "print(train_df_x.shape)\n",
        "print(test_df_x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa1JxXH33UwT",
        "outputId": "10d931ef-ca8b-4577-8c34-1b600481415b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(350598, 6)\n",
            "(188784, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_y = train.iloc[:,:1]\n",
        "train_df_y = train_df_y.astype('float32')\n",
        "\n",
        "test_df_y = test.iloc[:,:1]\n",
        "test_df_y = test_df_y.astype('float32')\n",
        "\n",
        "print(train_df_y)\n",
        "print(test_df_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SD5wfzs3ixK",
        "outputId": "f06fe669-801e-4c99-f66e-3b4fe602ed67"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Class\n",
            "263031    1.0\n",
            "97712     1.0\n",
            "536842    1.0\n",
            "237511    0.0\n",
            "261014    1.0\n",
            "...       ...\n",
            "138911    1.0\n",
            "200211    1.0\n",
            "137031    0.0\n",
            "114369    0.0\n",
            "473253    1.0\n",
            "\n",
            "[350598 rows x 1 columns]\n",
            "        Class\n",
            "309672    1.0\n",
            "386273    0.0\n",
            "350725    0.0\n",
            "69486     0.0\n",
            "417318    1.0\n",
            "...       ...\n",
            "368001    1.0\n",
            "456113    0.0\n",
            "80011     0.0\n",
            "38202     1.0\n",
            "190758    0.0\n",
            "\n",
            "[188784 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model builder function\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    \n",
        "    # Tune the number of neurons in the first hidden layer\n",
        "    hp_units = hp.Int('units', min_value=64, max_value=512, step=64)\n",
        "    \n",
        "    model.add(layers.Dense(units=hp_units, activation='relu', input_shape=(6,), bias_initializer='random_normal'))\n",
        "    \n",
        "    # Tune the learning rate for the optimizer\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "    \n",
        "    model.add(layers.Dense(units=10, activation='relu', bias_initializer='random_normal'))\n",
        "    model.add(layers.Dense(units=1, activation='sigmoid', bias_initializer='random_normal'))\n",
        "    \n",
        "    # Compile the model with binary cross-entropy loss and Adam optimizer, and add precision, recall, and F1 score to the metrics\n",
        "    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(hp_learning_rate), metrics=['accuracy', Precision(), Recall()])\n",
        "    \n",
        "    early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Initialize the random search tuner with the model builder function and the hyperparameter search space\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='Precision',\n",
        "    max_trials=5,\n",
        "    executions_per_trial=3,\n",
        "    directory='tuner_results',\n",
        "    project_name='my_model')\n",
        "\n",
        "# Search for the best hyperparameters\n",
        "tuner.search(train_df_x, train_df_y, epochs=200, batch_size=750, validation_data=(test_df_x, test_df_y))\n",
        "\n",
        "# Print the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print('Number of units in the first hidden layer: {}'.format(best_hps.get('units')))\n",
        "print('Learning rate: {}'.format(best_hps.get('learning_rate')))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BaBgMNp_ZSn-",
        "outputId": "11071092-1ab2-43c6-808b-b081652b7ae6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Search: Running Trial #3\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "64                |?                 |units\n",
            "0.0001            |?                 |learning_rate\n",
            "\n",
            "Epoch 1/200\n",
            "468/468 [==============================] - 7s 8ms/step - loss: 0.6892 - accuracy: 0.5428 - precision: 0.4537 - recall: 0.1300 - val_loss: 0.6833 - val_accuracy: 0.5597 - val_precision: 0.5741 - val_recall: 0.0446\n",
            "Epoch 2/200\n",
            "468/468 [==============================] - 4s 10ms/step - loss: 0.6797 - accuracy: 0.5660 - precision: 0.5482 - recall: 0.1459 - val_loss: 0.6765 - val_accuracy: 0.5687 - val_precision: 0.5373 - val_recall: 0.2284\n",
            "Epoch 3/200\n",
            "468/468 [==============================] - 5s 11ms/step - loss: 0.6744 - accuracy: 0.5733 - precision: 0.5414 - recall: 0.2750 - val_loss: 0.6728 - val_accuracy: 0.5759 - val_precision: 0.5371 - val_recall: 0.3474\n",
            "Epoch 4/200\n",
            "468/468 [==============================] - 5s 10ms/step - loss: 0.6719 - accuracy: 0.5773 - precision: 0.5423 - recall: 0.3276 - val_loss: 0.6710 - val_accuracy: 0.5781 - val_precision: 0.5441 - val_recall: 0.3256\n",
            "Epoch 5/200\n",
            "468/468 [==============================] - 5s 10ms/step - loss: 0.6707 - accuracy: 0.5791 - precision: 0.5436 - recall: 0.3436 - val_loss: 0.6700 - val_accuracy: 0.5795 - val_precision: 0.5455 - val_recall: 0.3358\n",
            "Epoch 6/200\n",
            "468/468 [==============================] - 5s 10ms/step - loss: 0.6699 - accuracy: 0.5805 - precision: 0.5444 - recall: 0.3569 - val_loss: 0.6692 - val_accuracy: 0.5811 - val_precision: 0.5420 - val_recall: 0.3841\n",
            "Epoch 7/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6692 - accuracy: 0.5818 - precision: 0.5454 - recall: 0.3672 - val_loss: 0.6686 - val_accuracy: 0.5820 - val_precision: 0.5454 - val_recall: 0.3707\n",
            "Epoch 8/200\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.6687 - accuracy: 0.5828 - precision: 0.5467 - recall: 0.3711 - val_loss: 0.6681 - val_accuracy: 0.5836 - val_precision: 0.5457 - val_recall: 0.3895\n",
            "Epoch 9/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6683 - accuracy: 0.5840 - precision: 0.5483 - recall: 0.3760 - val_loss: 0.6677 - val_accuracy: 0.5837 - val_precision: 0.5486 - val_recall: 0.3701\n",
            "Epoch 10/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6679 - accuracy: 0.5848 - precision: 0.5490 - recall: 0.3807 - val_loss: 0.6673 - val_accuracy: 0.5856 - val_precision: 0.5512 - val_recall: 0.3756\n",
            "Epoch 11/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6676 - accuracy: 0.5855 - precision: 0.5502 - recall: 0.3808 - val_loss: 0.6670 - val_accuracy: 0.5850 - val_precision: 0.5467 - val_recall: 0.4006\n",
            "Epoch 12/200\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.6673 - accuracy: 0.5863 - precision: 0.5508 - recall: 0.3853 - val_loss: 0.6667 - val_accuracy: 0.5859 - val_precision: 0.5467 - val_recall: 0.4117\n",
            "Epoch 13/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6670 - accuracy: 0.5868 - precision: 0.5512 - recall: 0.3899 - val_loss: 0.6664 - val_accuracy: 0.5869 - val_precision: 0.5509 - val_recall: 0.3930\n",
            "Epoch 14/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6667 - accuracy: 0.5877 - precision: 0.5524 - recall: 0.3916 - val_loss: 0.6661 - val_accuracy: 0.5876 - val_precision: 0.5512 - val_recall: 0.3990\n",
            "Epoch 15/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6665 - accuracy: 0.5882 - precision: 0.5529 - recall: 0.3945 - val_loss: 0.6660 - val_accuracy: 0.5879 - val_precision: 0.5559 - val_recall: 0.3725\n",
            "Epoch 16/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6663 - accuracy: 0.5881 - precision: 0.5526 - recall: 0.3951 - val_loss: 0.6656 - val_accuracy: 0.5894 - val_precision: 0.5548 - val_recall: 0.3959\n",
            "Epoch 17/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6661 - accuracy: 0.5888 - precision: 0.5536 - recall: 0.3974 - val_loss: 0.6654 - val_accuracy: 0.5894 - val_precision: 0.5564 - val_recall: 0.3858\n",
            "Epoch 18/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6658 - accuracy: 0.5893 - precision: 0.5542 - recall: 0.3987 - val_loss: 0.6652 - val_accuracy: 0.5901 - val_precision: 0.5543 - val_recall: 0.4079\n",
            "Epoch 19/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6656 - accuracy: 0.5900 - precision: 0.5551 - recall: 0.4004 - val_loss: 0.6650 - val_accuracy: 0.5910 - val_precision: 0.5562 - val_recall: 0.4056\n",
            "Epoch 20/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6654 - accuracy: 0.5898 - precision: 0.5545 - recall: 0.4027 - val_loss: 0.6648 - val_accuracy: 0.5920 - val_precision: 0.5596 - val_recall: 0.3941\n",
            "Epoch 21/200\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.6652 - accuracy: 0.5905 - precision: 0.5558 - recall: 0.4019 - val_loss: 0.6646 - val_accuracy: 0.5916 - val_precision: 0.5564 - val_recall: 0.4102\n",
            "Epoch 22/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6651 - accuracy: 0.5906 - precision: 0.5553 - recall: 0.4059 - val_loss: 0.6644 - val_accuracy: 0.5934 - val_precision: 0.5613 - val_recall: 0.3999\n",
            "Epoch 23/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6649 - accuracy: 0.5913 - precision: 0.5569 - recall: 0.4040 - val_loss: 0.6642 - val_accuracy: 0.5923 - val_precision: 0.5570 - val_recall: 0.4138\n",
            "Epoch 24/200\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.6647 - accuracy: 0.5918 - precision: 0.5573 - recall: 0.4063 - val_loss: 0.6640 - val_accuracy: 0.5926 - val_precision: 0.5566 - val_recall: 0.4197\n",
            "Epoch 25/200\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.6646 - accuracy: 0.5918 - precision: 0.5570 - recall: 0.4080 - val_loss: 0.6639 - val_accuracy: 0.5934 - val_precision: 0.5579 - val_recall: 0.4200\n",
            "Epoch 26/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6644 - accuracy: 0.5925 - precision: 0.5581 - recall: 0.4086 - val_loss: 0.6638 - val_accuracy: 0.5943 - val_precision: 0.5665 - val_recall: 0.3797\n",
            "Epoch 27/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6643 - accuracy: 0.5929 - precision: 0.5591 - recall: 0.4071 - val_loss: 0.6636 - val_accuracy: 0.5945 - val_precision: 0.5627 - val_recall: 0.4021\n",
            "Epoch 28/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6641 - accuracy: 0.5933 - precision: 0.5595 - recall: 0.4084 - val_loss: 0.6634 - val_accuracy: 0.5951 - val_precision: 0.5643 - val_recall: 0.3993\n",
            "Epoch 29/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6640 - accuracy: 0.5931 - precision: 0.5595 - recall: 0.4071 - val_loss: 0.6633 - val_accuracy: 0.5946 - val_precision: 0.5589 - val_recall: 0.4259\n",
            "Epoch 30/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6638 - accuracy: 0.5939 - precision: 0.5606 - recall: 0.4083 - val_loss: 0.6631 - val_accuracy: 0.5953 - val_precision: 0.5632 - val_recall: 0.4080\n",
            "Epoch 31/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6637 - accuracy: 0.5941 - precision: 0.5612 - recall: 0.4069 - val_loss: 0.6630 - val_accuracy: 0.5946 - val_precision: 0.5574 - val_recall: 0.4369\n",
            "Epoch 32/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6635 - accuracy: 0.5942 - precision: 0.5611 - recall: 0.4090 - val_loss: 0.6628 - val_accuracy: 0.5958 - val_precision: 0.5635 - val_recall: 0.4110\n",
            "Epoch 33/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6634 - accuracy: 0.5945 - precision: 0.5619 - recall: 0.4074 - val_loss: 0.6626 - val_accuracy: 0.5958 - val_precision: 0.5632 - val_recall: 0.4122\n",
            "Epoch 34/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6633 - accuracy: 0.5949 - precision: 0.5621 - recall: 0.4096 - val_loss: 0.6626 - val_accuracy: 0.5962 - val_precision: 0.5691 - val_recall: 0.3854\n",
            "Epoch 35/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6631 - accuracy: 0.5948 - precision: 0.5626 - recall: 0.4060 - val_loss: 0.6624 - val_accuracy: 0.5963 - val_precision: 0.5657 - val_recall: 0.4029\n",
            "Epoch 36/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6630 - accuracy: 0.5951 - precision: 0.5633 - recall: 0.4054 - val_loss: 0.6623 - val_accuracy: 0.5966 - val_precision: 0.5635 - val_recall: 0.4188\n",
            "Epoch 37/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6629 - accuracy: 0.5958 - precision: 0.5642 - recall: 0.4068 - val_loss: 0.6621 - val_accuracy: 0.5965 - val_precision: 0.5659 - val_recall: 0.4043\n",
            "Epoch 38/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6628 - accuracy: 0.5961 - precision: 0.5647 - recall: 0.4074 - val_loss: 0.6620 - val_accuracy: 0.5966 - val_precision: 0.5619 - val_recall: 0.4281\n",
            "Epoch 39/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6626 - accuracy: 0.5960 - precision: 0.5648 - recall: 0.4059 - val_loss: 0.6619 - val_accuracy: 0.5970 - val_precision: 0.5635 - val_recall: 0.4236\n",
            "Epoch 40/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6625 - accuracy: 0.5964 - precision: 0.5654 - recall: 0.4065 - val_loss: 0.6617 - val_accuracy: 0.5976 - val_precision: 0.5654 - val_recall: 0.4173\n",
            "Epoch 41/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6623 - accuracy: 0.5962 - precision: 0.5647 - recall: 0.4082 - val_loss: 0.6616 - val_accuracy: 0.5979 - val_precision: 0.5702 - val_recall: 0.3953\n",
            "Epoch 42/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6622 - accuracy: 0.5965 - precision: 0.5659 - recall: 0.4042 - val_loss: 0.6614 - val_accuracy: 0.5980 - val_precision: 0.5651 - val_recall: 0.4230\n",
            "Epoch 43/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6621 - accuracy: 0.5970 - precision: 0.5664 - recall: 0.4062 - val_loss: 0.6613 - val_accuracy: 0.5981 - val_precision: 0.5667 - val_recall: 0.4157\n",
            "Epoch 44/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6620 - accuracy: 0.5969 - precision: 0.5663 - recall: 0.4063 - val_loss: 0.6612 - val_accuracy: 0.5988 - val_precision: 0.5723 - val_recall: 0.3928\n",
            "Epoch 45/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6618 - accuracy: 0.5974 - precision: 0.5673 - recall: 0.4054 - val_loss: 0.6610 - val_accuracy: 0.5986 - val_precision: 0.5682 - val_recall: 0.4124\n",
            "Epoch 46/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6617 - accuracy: 0.5980 - precision: 0.5680 - recall: 0.4073 - val_loss: 0.6609 - val_accuracy: 0.5993 - val_precision: 0.5660 - val_recall: 0.4305\n",
            "Epoch 47/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6615 - accuracy: 0.5985 - precision: 0.5690 - recall: 0.4068 - val_loss: 0.6607 - val_accuracy: 0.5995 - val_precision: 0.5682 - val_recall: 0.4206\n",
            "Epoch 48/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6614 - accuracy: 0.5986 - precision: 0.5689 - recall: 0.4078 - val_loss: 0.6606 - val_accuracy: 0.5999 - val_precision: 0.5750 - val_recall: 0.3903\n",
            "Epoch 49/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6612 - accuracy: 0.5987 - precision: 0.5693 - recall: 0.4069 - val_loss: 0.6605 - val_accuracy: 0.6000 - val_precision: 0.5656 - val_recall: 0.4400\n",
            "Epoch 50/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6610 - accuracy: 0.5989 - precision: 0.5693 - recall: 0.4088 - val_loss: 0.6602 - val_accuracy: 0.6007 - val_precision: 0.5693 - val_recall: 0.4254\n",
            "Epoch 51/200\n",
            "468/468 [==============================] - 4s 9ms/step - loss: 0.6609 - accuracy: 0.5996 - precision: 0.5706 - recall: 0.4087 - val_loss: 0.6600 - val_accuracy: 0.6010 - val_precision: 0.5741 - val_recall: 0.4039\n",
            "Epoch 52/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6607 - accuracy: 0.5995 - precision: 0.5706 - recall: 0.4079 - val_loss: 0.6599 - val_accuracy: 0.6012 - val_precision: 0.5739 - val_recall: 0.4070\n",
            "Epoch 53/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6605 - accuracy: 0.5999 - precision: 0.5705 - recall: 0.4114 - val_loss: 0.6597 - val_accuracy: 0.6015 - val_precision: 0.5682 - val_recall: 0.4392\n",
            "Epoch 54/200\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.6603 - accuracy: 0.6003 - precision: 0.5713 - recall: 0.4117 - val_loss: 0.6594 - val_accuracy: 0.6025 - val_precision: 0.5742 - val_recall: 0.4164\n",
            "Epoch 55/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6601 - accuracy: 0.6007 - precision: 0.5719 - recall: 0.4120 - val_loss: 0.6593 - val_accuracy: 0.6025 - val_precision: 0.5697 - val_recall: 0.4400\n",
            "Epoch 56/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6599 - accuracy: 0.6012 - precision: 0.5725 - recall: 0.4138 - val_loss: 0.6590 - val_accuracy: 0.6031 - val_precision: 0.5782 - val_recall: 0.4034\n",
            "Epoch 57/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6597 - accuracy: 0.6017 - precision: 0.5726 - recall: 0.4169 - val_loss: 0.6588 - val_accuracy: 0.6034 - val_precision: 0.5762 - val_recall: 0.4148\n",
            "Epoch 58/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6595 - accuracy: 0.6016 - precision: 0.5726 - recall: 0.4164 - val_loss: 0.6586 - val_accuracy: 0.6041 - val_precision: 0.5749 - val_recall: 0.4275\n",
            "Epoch 59/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6592 - accuracy: 0.6027 - precision: 0.5743 - recall: 0.4176 - val_loss: 0.6584 - val_accuracy: 0.6037 - val_precision: 0.5743 - val_recall: 0.4267\n",
            "Epoch 60/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6591 - accuracy: 0.6022 - precision: 0.5728 - recall: 0.4202 - val_loss: 0.6583 - val_accuracy: 0.6049 - val_precision: 0.5707 - val_recall: 0.4558\n",
            "Epoch 61/200\n",
            "468/468 [==============================] - 3s 5ms/step - loss: 0.6589 - accuracy: 0.6029 - precision: 0.5739 - recall: 0.4216 - val_loss: 0.6580 - val_accuracy: 0.6058 - val_precision: 0.5724 - val_recall: 0.4549\n",
            "Epoch 62/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6587 - accuracy: 0.6034 - precision: 0.5743 - recall: 0.4239 - val_loss: 0.6578 - val_accuracy: 0.6055 - val_precision: 0.5732 - val_recall: 0.4477\n",
            "Epoch 63/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6585 - accuracy: 0.6033 - precision: 0.5739 - recall: 0.4246 - val_loss: 0.6575 - val_accuracy: 0.6063 - val_precision: 0.5791 - val_recall: 0.4250\n",
            "Epoch 64/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6582 - accuracy: 0.6042 - precision: 0.5753 - recall: 0.4255 - val_loss: 0.6574 - val_accuracy: 0.6062 - val_precision: 0.5785 - val_recall: 0.4275\n",
            "Epoch 65/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6581 - accuracy: 0.6044 - precision: 0.5754 - recall: 0.4264 - val_loss: 0.6574 - val_accuracy: 0.6066 - val_precision: 0.5695 - val_recall: 0.4789\n",
            "Epoch 66/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6579 - accuracy: 0.6054 - precision: 0.5763 - recall: 0.4311 - val_loss: 0.6571 - val_accuracy: 0.6074 - val_precision: 0.5838 - val_recall: 0.4137\n",
            "Epoch 67/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6577 - accuracy: 0.6054 - precision: 0.5763 - recall: 0.4307 - val_loss: 0.6568 - val_accuracy: 0.6077 - val_precision: 0.5850 - val_recall: 0.4109\n",
            "Epoch 68/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6575 - accuracy: 0.6054 - precision: 0.5766 - recall: 0.4295 - val_loss: 0.6566 - val_accuracy: 0.6080 - val_precision: 0.5800 - val_recall: 0.4350\n",
            "Epoch 69/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6573 - accuracy: 0.6064 - precision: 0.5776 - recall: 0.4333 - val_loss: 0.6564 - val_accuracy: 0.6086 - val_precision: 0.5890 - val_recall: 0.4016\n",
            "Epoch 70/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6571 - accuracy: 0.6067 - precision: 0.5784 - recall: 0.4319 - val_loss: 0.6562 - val_accuracy: 0.6085 - val_precision: 0.5844 - val_recall: 0.4195\n",
            "Epoch 71/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6570 - accuracy: 0.6068 - precision: 0.5780 - recall: 0.4348 - val_loss: 0.6561 - val_accuracy: 0.6090 - val_precision: 0.5813 - val_recall: 0.4372\n",
            "Epoch 72/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6568 - accuracy: 0.6071 - precision: 0.5784 - recall: 0.4353 - val_loss: 0.6558 - val_accuracy: 0.6095 - val_precision: 0.5835 - val_recall: 0.4316\n",
            "Epoch 73/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6566 - accuracy: 0.6074 - precision: 0.5788 - recall: 0.4353 - val_loss: 0.6556 - val_accuracy: 0.6097 - val_precision: 0.5796 - val_recall: 0.4510\n",
            "Epoch 74/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6564 - accuracy: 0.6077 - precision: 0.5791 - recall: 0.4367 - val_loss: 0.6554 - val_accuracy: 0.6097 - val_precision: 0.5793 - val_recall: 0.4524\n",
            "Epoch 75/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6562 - accuracy: 0.6081 - precision: 0.5797 - recall: 0.4368 - val_loss: 0.6552 - val_accuracy: 0.6100 - val_precision: 0.5795 - val_recall: 0.4538\n",
            "Epoch 76/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6560 - accuracy: 0.6082 - precision: 0.5789 - recall: 0.4412 - val_loss: 0.6551 - val_accuracy: 0.6106 - val_precision: 0.5921 - val_recall: 0.4046\n",
            "Epoch 77/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6557 - accuracy: 0.6087 - precision: 0.5805 - recall: 0.4379 - val_loss: 0.6548 - val_accuracy: 0.6111 - val_precision: 0.5863 - val_recall: 0.4308\n",
            "Epoch 78/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6556 - accuracy: 0.6089 - precision: 0.5802 - recall: 0.4410 - val_loss: 0.6546 - val_accuracy: 0.6114 - val_precision: 0.5874 - val_recall: 0.4290\n",
            "Epoch 79/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6553 - accuracy: 0.6093 - precision: 0.5812 - recall: 0.4396 - val_loss: 0.6543 - val_accuracy: 0.6109 - val_precision: 0.5837 - val_recall: 0.4409\n",
            "Epoch 80/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6551 - accuracy: 0.6093 - precision: 0.5808 - recall: 0.4415 - val_loss: 0.6541 - val_accuracy: 0.6113 - val_precision: 0.5815 - val_recall: 0.4546\n",
            "Epoch 81/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6549 - accuracy: 0.6096 - precision: 0.5811 - recall: 0.4430 - val_loss: 0.6539 - val_accuracy: 0.6121 - val_precision: 0.5901 - val_recall: 0.4234\n",
            "Epoch 82/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6547 - accuracy: 0.6096 - precision: 0.5813 - recall: 0.4419 - val_loss: 0.6536 - val_accuracy: 0.6122 - val_precision: 0.5872 - val_recall: 0.4357\n",
            "Epoch 83/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6544 - accuracy: 0.6102 - precision: 0.5819 - recall: 0.4442 - val_loss: 0.6533 - val_accuracy: 0.6122 - val_precision: 0.5837 - val_recall: 0.4516\n",
            "Epoch 84/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6541 - accuracy: 0.6104 - precision: 0.5824 - recall: 0.4430 - val_loss: 0.6531 - val_accuracy: 0.6130 - val_precision: 0.5876 - val_recall: 0.4398\n",
            "Epoch 85/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6538 - accuracy: 0.6109 - precision: 0.5825 - recall: 0.4467 - val_loss: 0.6528 - val_accuracy: 0.6125 - val_precision: 0.5825 - val_recall: 0.4598\n",
            "Epoch 86/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6536 - accuracy: 0.6114 - precision: 0.5837 - recall: 0.4451 - val_loss: 0.6525 - val_accuracy: 0.6132 - val_precision: 0.5843 - val_recall: 0.4563\n",
            "Epoch 87/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6533 - accuracy: 0.6117 - precision: 0.5836 - recall: 0.4479 - val_loss: 0.6522 - val_accuracy: 0.6138 - val_precision: 0.5875 - val_recall: 0.4461\n",
            "Epoch 88/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6530 - accuracy: 0.6121 - precision: 0.5843 - recall: 0.4478 - val_loss: 0.6519 - val_accuracy: 0.6141 - val_precision: 0.5894 - val_recall: 0.4404\n",
            "Epoch 89/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6527 - accuracy: 0.6125 - precision: 0.5850 - recall: 0.4477 - val_loss: 0.6517 - val_accuracy: 0.6150 - val_precision: 0.5914 - val_recall: 0.4389\n",
            "Epoch 90/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6524 - accuracy: 0.6124 - precision: 0.5849 - recall: 0.4478 - val_loss: 0.6513 - val_accuracy: 0.6144 - val_precision: 0.5854 - val_recall: 0.4607\n",
            "Epoch 91/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6521 - accuracy: 0.6131 - precision: 0.5857 - recall: 0.4491 - val_loss: 0.6510 - val_accuracy: 0.6147 - val_precision: 0.5857 - val_recall: 0.4617\n",
            "Epoch 92/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6518 - accuracy: 0.6136 - precision: 0.5863 - recall: 0.4500 - val_loss: 0.6508 - val_accuracy: 0.6160 - val_precision: 0.5915 - val_recall: 0.4455\n",
            "Epoch 93/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6515 - accuracy: 0.6138 - precision: 0.5869 - recall: 0.4492 - val_loss: 0.6504 - val_accuracy: 0.6156 - val_precision: 0.5907 - val_recall: 0.4465\n",
            "Epoch 94/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6511 - accuracy: 0.6141 - precision: 0.5872 - recall: 0.4504 - val_loss: 0.6502 - val_accuracy: 0.6156 - val_precision: 0.5844 - val_recall: 0.4748\n",
            "Epoch 95/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6508 - accuracy: 0.6144 - precision: 0.5878 - recall: 0.4499 - val_loss: 0.6498 - val_accuracy: 0.6163 - val_precision: 0.5939 - val_recall: 0.4381\n",
            "Epoch 96/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6505 - accuracy: 0.6149 - precision: 0.5884 - recall: 0.4506 - val_loss: 0.6495 - val_accuracy: 0.6163 - val_precision: 0.5897 - val_recall: 0.4558\n",
            "Epoch 97/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6502 - accuracy: 0.6150 - precision: 0.5885 - recall: 0.4507 - val_loss: 0.6492 - val_accuracy: 0.6180 - val_precision: 0.5943 - val_recall: 0.4487\n",
            "Epoch 98/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6499 - accuracy: 0.6153 - precision: 0.5893 - recall: 0.4500 - val_loss: 0.6489 - val_accuracy: 0.6181 - val_precision: 0.5913 - val_recall: 0.4619\n",
            "Epoch 99/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6497 - accuracy: 0.6157 - precision: 0.5899 - recall: 0.4505 - val_loss: 0.6487 - val_accuracy: 0.6179 - val_precision: 0.5894 - val_recall: 0.4684\n",
            "Epoch 100/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6495 - accuracy: 0.6162 - precision: 0.5903 - recall: 0.4523 - val_loss: 0.6484 - val_accuracy: 0.6183 - val_precision: 0.5952 - val_recall: 0.4472\n",
            "Epoch 101/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6492 - accuracy: 0.6165 - precision: 0.5913 - recall: 0.4504 - val_loss: 0.6482 - val_accuracy: 0.6184 - val_precision: 0.5914 - val_recall: 0.4638\n",
            "Epoch 102/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6490 - accuracy: 0.6168 - precision: 0.5915 - recall: 0.4519 - val_loss: 0.6482 - val_accuracy: 0.6186 - val_precision: 0.6019 - val_recall: 0.4247\n",
            "Epoch 103/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6488 - accuracy: 0.6168 - precision: 0.5918 - recall: 0.4501 - val_loss: 0.6477 - val_accuracy: 0.6191 - val_precision: 0.5980 - val_recall: 0.4424\n",
            "Epoch 104/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6485 - accuracy: 0.6173 - precision: 0.5930 - recall: 0.4491 - val_loss: 0.6474 - val_accuracy: 0.6193 - val_precision: 0.5955 - val_recall: 0.4533\n",
            "Epoch 105/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6483 - accuracy: 0.6172 - precision: 0.5928 - recall: 0.4494 - val_loss: 0.6473 - val_accuracy: 0.6194 - val_precision: 0.5997 - val_recall: 0.4376\n",
            "Epoch 106/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6480 - accuracy: 0.6177 - precision: 0.5936 - recall: 0.4494 - val_loss: 0.6471 - val_accuracy: 0.6198 - val_precision: 0.6032 - val_recall: 0.4280\n",
            "Epoch 107/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6478 - accuracy: 0.6182 - precision: 0.5947 - recall: 0.4490 - val_loss: 0.6468 - val_accuracy: 0.6202 - val_precision: 0.5990 - val_recall: 0.4460\n",
            "Epoch 108/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6475 - accuracy: 0.6186 - precision: 0.5956 - recall: 0.4475 - val_loss: 0.6466 - val_accuracy: 0.6203 - val_precision: 0.6041 - val_recall: 0.4286\n",
            "Epoch 109/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6473 - accuracy: 0.6189 - precision: 0.5958 - recall: 0.4492 - val_loss: 0.6463 - val_accuracy: 0.6206 - val_precision: 0.5974 - val_recall: 0.4546\n",
            "Epoch 110/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6471 - accuracy: 0.6191 - precision: 0.5965 - recall: 0.4478 - val_loss: 0.6461 - val_accuracy: 0.6206 - val_precision: 0.5996 - val_recall: 0.4460\n",
            "Epoch 111/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6469 - accuracy: 0.6193 - precision: 0.5964 - recall: 0.4493 - val_loss: 0.6459 - val_accuracy: 0.6217 - val_precision: 0.6055 - val_recall: 0.4327\n",
            "Epoch 112/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6467 - accuracy: 0.6198 - precision: 0.5975 - recall: 0.4485 - val_loss: 0.6459 - val_accuracy: 0.6211 - val_precision: 0.5916 - val_recall: 0.4830\n",
            "Epoch 113/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6464 - accuracy: 0.6204 - precision: 0.5986 - recall: 0.4485 - val_loss: 0.6455 - val_accuracy: 0.6215 - val_precision: 0.5960 - val_recall: 0.4668\n",
            "Epoch 114/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6462 - accuracy: 0.6203 - precision: 0.5984 - recall: 0.4489 - val_loss: 0.6453 - val_accuracy: 0.6220 - val_precision: 0.6074 - val_recall: 0.4282\n",
            "Epoch 115/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6460 - accuracy: 0.6207 - precision: 0.5989 - recall: 0.4494 - val_loss: 0.6453 - val_accuracy: 0.6240 - val_precision: 0.6154 - val_recall: 0.4156\n",
            "Epoch 116/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6458 - accuracy: 0.6211 - precision: 0.5999 - recall: 0.4487 - val_loss: 0.6449 - val_accuracy: 0.6217 - val_precision: 0.5983 - val_recall: 0.4589\n",
            "Epoch 117/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6456 - accuracy: 0.6217 - precision: 0.6007 - recall: 0.4493 - val_loss: 0.6448 - val_accuracy: 0.6238 - val_precision: 0.6027 - val_recall: 0.4561\n",
            "Epoch 118/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6454 - accuracy: 0.6221 - precision: 0.6014 - recall: 0.4496 - val_loss: 0.6447 - val_accuracy: 0.6226 - val_precision: 0.5935 - val_recall: 0.4848\n",
            "Epoch 119/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6453 - accuracy: 0.6220 - precision: 0.6011 - recall: 0.4503 - val_loss: 0.6443 - val_accuracy: 0.6235 - val_precision: 0.6073 - val_recall: 0.4382\n",
            "Epoch 120/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6450 - accuracy: 0.6222 - precision: 0.6019 - recall: 0.4486 - val_loss: 0.6443 - val_accuracy: 0.6251 - val_precision: 0.6148 - val_recall: 0.4240\n",
            "Epoch 121/200\n",
            "468/468 [==============================] - 4s 9ms/step - loss: 0.6448 - accuracy: 0.6226 - precision: 0.6024 - recall: 0.4493 - val_loss: 0.6440 - val_accuracy: 0.6246 - val_precision: 0.6054 - val_recall: 0.4518\n",
            "Epoch 122/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6447 - accuracy: 0.6227 - precision: 0.6023 - recall: 0.4501 - val_loss: 0.6437 - val_accuracy: 0.6238 - val_precision: 0.6021 - val_recall: 0.4584\n",
            "Epoch 123/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6445 - accuracy: 0.6231 - precision: 0.6037 - recall: 0.4482 - val_loss: 0.6438 - val_accuracy: 0.6235 - val_precision: 0.5940 - val_recall: 0.4889\n",
            "Epoch 124/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6443 - accuracy: 0.6233 - precision: 0.6027 - recall: 0.4525 - val_loss: 0.6434 - val_accuracy: 0.6249 - val_precision: 0.6055 - val_recall: 0.4533\n",
            "Epoch 125/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6442 - accuracy: 0.6234 - precision: 0.6035 - recall: 0.4508 - val_loss: 0.6433 - val_accuracy: 0.6246 - val_precision: 0.6045 - val_recall: 0.4547\n",
            "Epoch 126/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6440 - accuracy: 0.6235 - precision: 0.6038 - recall: 0.4503 - val_loss: 0.6431 - val_accuracy: 0.6249 - val_precision: 0.6008 - val_recall: 0.4705\n",
            "Epoch 127/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6439 - accuracy: 0.6236 - precision: 0.6034 - recall: 0.4520 - val_loss: 0.6430 - val_accuracy: 0.6253 - val_precision: 0.6041 - val_recall: 0.4612\n",
            "Epoch 128/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6437 - accuracy: 0.6236 - precision: 0.6039 - recall: 0.4506 - val_loss: 0.6429 - val_accuracy: 0.6261 - val_precision: 0.6129 - val_recall: 0.4359\n",
            "Epoch 129/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6436 - accuracy: 0.6238 - precision: 0.6039 - recall: 0.4516 - val_loss: 0.6429 - val_accuracy: 0.6251 - val_precision: 0.5974 - val_recall: 0.4854\n",
            "Epoch 130/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6434 - accuracy: 0.6243 - precision: 0.6046 - recall: 0.4521 - val_loss: 0.6426 - val_accuracy: 0.6257 - val_precision: 0.6025 - val_recall: 0.4691\n",
            "Epoch 131/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6432 - accuracy: 0.6242 - precision: 0.6047 - recall: 0.4516 - val_loss: 0.6425 - val_accuracy: 0.6264 - val_precision: 0.6158 - val_recall: 0.4287\n",
            "Epoch 132/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6432 - accuracy: 0.6240 - precision: 0.6041 - recall: 0.4525 - val_loss: 0.6424 - val_accuracy: 0.6269 - val_precision: 0.6125 - val_recall: 0.4423\n",
            "Epoch 133/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6431 - accuracy: 0.6246 - precision: 0.6049 - recall: 0.4529 - val_loss: 0.6424 - val_accuracy: 0.6244 - val_precision: 0.6003 - val_recall: 0.4694\n",
            "Epoch 134/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6429 - accuracy: 0.6243 - precision: 0.6047 - recall: 0.4525 - val_loss: 0.6421 - val_accuracy: 0.6265 - val_precision: 0.6129 - val_recall: 0.4386\n",
            "Epoch 135/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6428 - accuracy: 0.6242 - precision: 0.6044 - recall: 0.4526 - val_loss: 0.6420 - val_accuracy: 0.6266 - val_precision: 0.6135 - val_recall: 0.4369\n",
            "Epoch 136/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6427 - accuracy: 0.6246 - precision: 0.6052 - recall: 0.4522 - val_loss: 0.6418 - val_accuracy: 0.6262 - val_precision: 0.6103 - val_recall: 0.4448\n",
            "Epoch 137/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6426 - accuracy: 0.6247 - precision: 0.6052 - recall: 0.4530 - val_loss: 0.6417 - val_accuracy: 0.6258 - val_precision: 0.6044 - val_recall: 0.4629\n",
            "Epoch 138/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6424 - accuracy: 0.6250 - precision: 0.6054 - recall: 0.4543 - val_loss: 0.6419 - val_accuracy: 0.6279 - val_precision: 0.6144 - val_recall: 0.4420\n",
            "Epoch 139/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6423 - accuracy: 0.6246 - precision: 0.6050 - recall: 0.4530 - val_loss: 0.6417 - val_accuracy: 0.6259 - val_precision: 0.6005 - val_recall: 0.4785\n",
            "Epoch 140/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6422 - accuracy: 0.6253 - precision: 0.6057 - recall: 0.4548 - val_loss: 0.6415 - val_accuracy: 0.6275 - val_precision: 0.6130 - val_recall: 0.4440\n",
            "Epoch 141/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6421 - accuracy: 0.6250 - precision: 0.6057 - recall: 0.4531 - val_loss: 0.6416 - val_accuracy: 0.6247 - val_precision: 0.5965 - val_recall: 0.4868\n",
            "Epoch 142/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6420 - accuracy: 0.6251 - precision: 0.6054 - recall: 0.4549 - val_loss: 0.6416 - val_accuracy: 0.6265 - val_precision: 0.5999 - val_recall: 0.4850\n",
            "Epoch 143/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6420 - accuracy: 0.6253 - precision: 0.6056 - recall: 0.4557 - val_loss: 0.6412 - val_accuracy: 0.6257 - val_precision: 0.6019 - val_recall: 0.4719\n",
            "Epoch 144/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6419 - accuracy: 0.6256 - precision: 0.6063 - recall: 0.4550 - val_loss: 0.6411 - val_accuracy: 0.6270 - val_precision: 0.6128 - val_recall: 0.4417\n",
            "Epoch 145/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6418 - accuracy: 0.6253 - precision: 0.6057 - recall: 0.4551 - val_loss: 0.6415 - val_accuracy: 0.6281 - val_precision: 0.6225 - val_recall: 0.4195\n",
            "Epoch 146/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6418 - accuracy: 0.6256 - precision: 0.6062 - recall: 0.4548 - val_loss: 0.6410 - val_accuracy: 0.6270 - val_precision: 0.6042 - val_recall: 0.4713\n",
            "Epoch 147/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6416 - accuracy: 0.6257 - precision: 0.6062 - recall: 0.4561 - val_loss: 0.6408 - val_accuracy: 0.6275 - val_precision: 0.6133 - val_recall: 0.4435\n",
            "Epoch 148/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6415 - accuracy: 0.6255 - precision: 0.6064 - recall: 0.4542 - val_loss: 0.6409 - val_accuracy: 0.6263 - val_precision: 0.5990 - val_recall: 0.4874\n",
            "Epoch 149/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6415 - accuracy: 0.6254 - precision: 0.6059 - recall: 0.4554 - val_loss: 0.6409 - val_accuracy: 0.6254 - val_precision: 0.5988 - val_recall: 0.4819\n",
            "Epoch 150/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6414 - accuracy: 0.6262 - precision: 0.6070 - recall: 0.4561 - val_loss: 0.6406 - val_accuracy: 0.6275 - val_precision: 0.6052 - val_recall: 0.4712\n",
            "Epoch 151/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6413 - accuracy: 0.6261 - precision: 0.6066 - recall: 0.4569 - val_loss: 0.6406 - val_accuracy: 0.6265 - val_precision: 0.6066 - val_recall: 0.4599\n",
            "Epoch 152/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6413 - accuracy: 0.6259 - precision: 0.6066 - recall: 0.4555 - val_loss: 0.6406 - val_accuracy: 0.6281 - val_precision: 0.6145 - val_recall: 0.4428\n",
            "Epoch 153/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6412 - accuracy: 0.6261 - precision: 0.6071 - recall: 0.4556 - val_loss: 0.6405 - val_accuracy: 0.6284 - val_precision: 0.6164 - val_recall: 0.4394\n",
            "Epoch 154/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6411 - accuracy: 0.6261 - precision: 0.6072 - recall: 0.4552 - val_loss: 0.6404 - val_accuracy: 0.6280 - val_precision: 0.6074 - val_recall: 0.4661\n",
            "Epoch 155/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6410 - accuracy: 0.6262 - precision: 0.6070 - recall: 0.4559 - val_loss: 0.6404 - val_accuracy: 0.6269 - val_precision: 0.6045 - val_recall: 0.4697\n",
            "Epoch 156/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6410 - accuracy: 0.6259 - precision: 0.6067 - recall: 0.4556 - val_loss: 0.6403 - val_accuracy: 0.6280 - val_precision: 0.6130 - val_recall: 0.4472\n",
            "Epoch 157/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6409 - accuracy: 0.6261 - precision: 0.6065 - recall: 0.4573 - val_loss: 0.6402 - val_accuracy: 0.6283 - val_precision: 0.6133 - val_recall: 0.4480\n",
            "Epoch 158/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6408 - accuracy: 0.6262 - precision: 0.6074 - recall: 0.4550 - val_loss: 0.6402 - val_accuracy: 0.6263 - val_precision: 0.6035 - val_recall: 0.4692\n",
            "Epoch 159/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6408 - accuracy: 0.6261 - precision: 0.6072 - recall: 0.4549 - val_loss: 0.6403 - val_accuracy: 0.6294 - val_precision: 0.6097 - val_recall: 0.4672\n",
            "Epoch 160/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6407 - accuracy: 0.6263 - precision: 0.6072 - recall: 0.4561 - val_loss: 0.6400 - val_accuracy: 0.6288 - val_precision: 0.6116 - val_recall: 0.4569\n",
            "Epoch 161/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6407 - accuracy: 0.6263 - precision: 0.6073 - recall: 0.4558 - val_loss: 0.6399 - val_accuracy: 0.6287 - val_precision: 0.6133 - val_recall: 0.4504\n",
            "Epoch 162/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6406 - accuracy: 0.6266 - precision: 0.6081 - recall: 0.4553 - val_loss: 0.6401 - val_accuracy: 0.6272 - val_precision: 0.6022 - val_recall: 0.4802\n",
            "Epoch 163/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6405 - accuracy: 0.6264 - precision: 0.6074 - recall: 0.4565 - val_loss: 0.6399 - val_accuracy: 0.6282 - val_precision: 0.6102 - val_recall: 0.4576\n",
            "Epoch 164/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6405 - accuracy: 0.6264 - precision: 0.6075 - recall: 0.4556 - val_loss: 0.6401 - val_accuracy: 0.6265 - val_precision: 0.5976 - val_recall: 0.4941\n",
            "Epoch 165/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6405 - accuracy: 0.6267 - precision: 0.6078 - recall: 0.4566 - val_loss: 0.6398 - val_accuracy: 0.6288 - val_precision: 0.6111 - val_recall: 0.4586\n",
            "Epoch 166/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6404 - accuracy: 0.6263 - precision: 0.6074 - recall: 0.4554 - val_loss: 0.6397 - val_accuracy: 0.6291 - val_precision: 0.6110 - val_recall: 0.4608\n",
            "Epoch 167/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6403 - accuracy: 0.6267 - precision: 0.6082 - recall: 0.4553 - val_loss: 0.6397 - val_accuracy: 0.6281 - val_precision: 0.6102 - val_recall: 0.4572\n",
            "Epoch 168/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6403 - accuracy: 0.6268 - precision: 0.6084 - recall: 0.4552 - val_loss: 0.6398 - val_accuracy: 0.6279 - val_precision: 0.6019 - val_recall: 0.4864\n",
            "Epoch 169/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6402 - accuracy: 0.6268 - precision: 0.6080 - recall: 0.4561 - val_loss: 0.6396 - val_accuracy: 0.6290 - val_precision: 0.6190 - val_recall: 0.4351\n",
            "Epoch 170/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6402 - accuracy: 0.6267 - precision: 0.6086 - recall: 0.4540 - val_loss: 0.6396 - val_accuracy: 0.6293 - val_precision: 0.6145 - val_recall: 0.4506\n",
            "Epoch 171/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6401 - accuracy: 0.6269 - precision: 0.6083 - recall: 0.4561 - val_loss: 0.6395 - val_accuracy: 0.6291 - val_precision: 0.6159 - val_recall: 0.4446\n",
            "Epoch 172/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6400 - accuracy: 0.6271 - precision: 0.6090 - recall: 0.4546 - val_loss: 0.6397 - val_accuracy: 0.6284 - val_precision: 0.6030 - val_recall: 0.4851\n",
            "Epoch 173/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6400 - accuracy: 0.6271 - precision: 0.6088 - recall: 0.4554 - val_loss: 0.6395 - val_accuracy: 0.6300 - val_precision: 0.6140 - val_recall: 0.4562\n",
            "Epoch 174/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6400 - accuracy: 0.6271 - precision: 0.6088 - recall: 0.4552 - val_loss: 0.6394 - val_accuracy: 0.6282 - val_precision: 0.6065 - val_recall: 0.4707\n",
            "Epoch 175/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6399 - accuracy: 0.6270 - precision: 0.6088 - recall: 0.4549 - val_loss: 0.6394 - val_accuracy: 0.6272 - val_precision: 0.6002 - val_recall: 0.4881\n",
            "Epoch 176/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6399 - accuracy: 0.6270 - precision: 0.6089 - recall: 0.4547 - val_loss: 0.6392 - val_accuracy: 0.6285 - val_precision: 0.6078 - val_recall: 0.4682\n",
            "Epoch 177/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6398 - accuracy: 0.6273 - precision: 0.6093 - recall: 0.4552 - val_loss: 0.6398 - val_accuracy: 0.6297 - val_precision: 0.6300 - val_recall: 0.4087\n",
            "Epoch 178/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6397 - accuracy: 0.6271 - precision: 0.6093 - recall: 0.4537 - val_loss: 0.6391 - val_accuracy: 0.6295 - val_precision: 0.6152 - val_recall: 0.4492\n",
            "Epoch 179/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6396 - accuracy: 0.6275 - precision: 0.6100 - recall: 0.4540 - val_loss: 0.6392 - val_accuracy: 0.6297 - val_precision: 0.6220 - val_recall: 0.4302\n",
            "Epoch 180/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6396 - accuracy: 0.6270 - precision: 0.6089 - recall: 0.4545 - val_loss: 0.6390 - val_accuracy: 0.6288 - val_precision: 0.6132 - val_recall: 0.4513\n",
            "Epoch 181/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6396 - accuracy: 0.6273 - precision: 0.6097 - recall: 0.4541 - val_loss: 0.6390 - val_accuracy: 0.6295 - val_precision: 0.6168 - val_recall: 0.4447\n",
            "Epoch 182/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6395 - accuracy: 0.6274 - precision: 0.6099 - recall: 0.4542 - val_loss: 0.6389 - val_accuracy: 0.6304 - val_precision: 0.6203 - val_recall: 0.4392\n",
            "Epoch 183/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6394 - accuracy: 0.6277 - precision: 0.6105 - recall: 0.4538 - val_loss: 0.6393 - val_accuracy: 0.6269 - val_precision: 0.5963 - val_recall: 0.5027\n",
            "Epoch 184/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6394 - accuracy: 0.6273 - precision: 0.6096 - recall: 0.4543 - val_loss: 0.6389 - val_accuracy: 0.6308 - val_precision: 0.6248 - val_recall: 0.4284\n",
            "Epoch 185/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6393 - accuracy: 0.6273 - precision: 0.6094 - recall: 0.4548 - val_loss: 0.6388 - val_accuracy: 0.6295 - val_precision: 0.6090 - val_recall: 0.4701\n",
            "Epoch 186/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6393 - accuracy: 0.6277 - precision: 0.6104 - recall: 0.4540 - val_loss: 0.6386 - val_accuracy: 0.6297 - val_precision: 0.6181 - val_recall: 0.4419\n",
            "Epoch 187/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6392 - accuracy: 0.6276 - precision: 0.6105 - recall: 0.4529 - val_loss: 0.6387 - val_accuracy: 0.6295 - val_precision: 0.6082 - val_recall: 0.4728\n",
            "Epoch 188/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6392 - accuracy: 0.6279 - precision: 0.6108 - recall: 0.4539 - val_loss: 0.6387 - val_accuracy: 0.6290 - val_precision: 0.6047 - val_recall: 0.4827\n",
            "Epoch 189/200\n",
            "468/468 [==============================] - 4s 9ms/step - loss: 0.6391 - accuracy: 0.6281 - precision: 0.6111 - recall: 0.4542 - val_loss: 0.6386 - val_accuracy: 0.6293 - val_precision: 0.6063 - val_recall: 0.4783\n",
            "Epoch 190/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6391 - accuracy: 0.6282 - precision: 0.6115 - recall: 0.4533 - val_loss: 0.6385 - val_accuracy: 0.6285 - val_precision: 0.6068 - val_recall: 0.4717\n",
            "Epoch 191/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6390 - accuracy: 0.6281 - precision: 0.6110 - recall: 0.4542 - val_loss: 0.6385 - val_accuracy: 0.6287 - val_precision: 0.6093 - val_recall: 0.4639\n",
            "Epoch 192/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6390 - accuracy: 0.6280 - precision: 0.6112 - recall: 0.4530 - val_loss: 0.6384 - val_accuracy: 0.6307 - val_precision: 0.6206 - val_recall: 0.4403\n",
            "Epoch 193/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6389 - accuracy: 0.6284 - precision: 0.6119 - recall: 0.4531 - val_loss: 0.6384 - val_accuracy: 0.6309 - val_precision: 0.6138 - val_recall: 0.4625\n",
            "Epoch 194/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6389 - accuracy: 0.6284 - precision: 0.6121 - recall: 0.4529 - val_loss: 0.6383 - val_accuracy: 0.6285 - val_precision: 0.6048 - val_recall: 0.4794\n",
            "Epoch 195/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6388 - accuracy: 0.6284 - precision: 0.6122 - recall: 0.4523 - val_loss: 0.6383 - val_accuracy: 0.6291 - val_precision: 0.6063 - val_recall: 0.4776\n",
            "Epoch 196/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6388 - accuracy: 0.6283 - precision: 0.6119 - recall: 0.4528 - val_loss: 0.6382 - val_accuracy: 0.6315 - val_precision: 0.6262 - val_recall: 0.4285\n",
            "Epoch 197/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6388 - accuracy: 0.6286 - precision: 0.6121 - recall: 0.4538 - val_loss: 0.6383 - val_accuracy: 0.6309 - val_precision: 0.6148 - val_recall: 0.4589\n",
            "Epoch 198/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6386 - accuracy: 0.6290 - precision: 0.6129 - recall: 0.4532 - val_loss: 0.6380 - val_accuracy: 0.6297 - val_precision: 0.6074 - val_recall: 0.4772\n",
            "Epoch 199/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6385 - accuracy: 0.6289 - precision: 0.6130 - recall: 0.4528 - val_loss: 0.6380 - val_accuracy: 0.6287 - val_precision: 0.6073 - val_recall: 0.4712\n",
            "Epoch 200/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6385 - accuracy: 0.6286 - precision: 0.6121 - recall: 0.4535 - val_loss: 0.6378 - val_accuracy: 0.6305 - val_precision: 0.6151 - val_recall: 0.4553\n",
            "Epoch 1/200\n",
            "468/468 [==============================] - 4s 6ms/step - loss: 0.6898 - accuracy: 0.5344 - precision: 0.4552 - recall: 0.2301 - val_loss: 0.6838 - val_accuracy: 0.5590 - val_precision: 0.5504 - val_recall: 0.0546\n",
            "Epoch 2/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6817 - accuracy: 0.5628 - precision: 0.5413 - recall: 0.1212 - val_loss: 0.6796 - val_accuracy: 0.5674 - val_precision: 0.5418 - val_recall: 0.1871\n",
            "Epoch 3/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6775 - accuracy: 0.5703 - precision: 0.5422 - recall: 0.2268 - val_loss: 0.6755 - val_accuracy: 0.5714 - val_precision: 0.5388 - val_recall: 0.2620\n",
            "Epoch 4/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6743 - accuracy: 0.5744 - precision: 0.5433 - recall: 0.2794 - val_loss: 0.6730 - val_accuracy: 0.5750 - val_precision: 0.5427 - val_recall: 0.2911\n",
            "Epoch 5/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6723 - accuracy: 0.5771 - precision: 0.5447 - recall: 0.3083 - val_loss: 0.6715 - val_accuracy: 0.5774 - val_precision: 0.5451 - val_recall: 0.3100\n",
            "Epoch 6/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6712 - accuracy: 0.5788 - precision: 0.5455 - recall: 0.3268 - val_loss: 0.6705 - val_accuracy: 0.5792 - val_precision: 0.5426 - val_recall: 0.3526\n",
            "Epoch 7/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6704 - accuracy: 0.5799 - precision: 0.5455 - recall: 0.3409 - val_loss: 0.6698 - val_accuracy: 0.5802 - val_precision: 0.5425 - val_recall: 0.3669\n",
            "Epoch 8/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6699 - accuracy: 0.5806 - precision: 0.5453 - recall: 0.3516 - val_loss: 0.6695 - val_accuracy: 0.5804 - val_precision: 0.5493 - val_recall: 0.3235\n",
            "Epoch 9/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6695 - accuracy: 0.5814 - precision: 0.5460 - recall: 0.3574 - val_loss: 0.6690 - val_accuracy: 0.5813 - val_precision: 0.5479 - val_recall: 0.3436\n",
            "Epoch 10/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6691 - accuracy: 0.5821 - precision: 0.5468 - recall: 0.3608 - val_loss: 0.6686 - val_accuracy: 0.5824 - val_precision: 0.5446 - val_recall: 0.3828\n",
            "Epoch 11/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6688 - accuracy: 0.5822 - precision: 0.5461 - recall: 0.3675 - val_loss: 0.6683 - val_accuracy: 0.5829 - val_precision: 0.5480 - val_recall: 0.3634\n",
            "Epoch 12/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6685 - accuracy: 0.5830 - precision: 0.5473 - recall: 0.3691 - val_loss: 0.6680 - val_accuracy: 0.5836 - val_precision: 0.5466 - val_recall: 0.3818\n",
            "Epoch 13/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6683 - accuracy: 0.5836 - precision: 0.5475 - recall: 0.3753 - val_loss: 0.6677 - val_accuracy: 0.5837 - val_precision: 0.5496 - val_recall: 0.3627\n",
            "Epoch 14/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6680 - accuracy: 0.5840 - precision: 0.5481 - recall: 0.3765 - val_loss: 0.6675 - val_accuracy: 0.5846 - val_precision: 0.5518 - val_recall: 0.3599\n",
            "Epoch 15/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6678 - accuracy: 0.5847 - precision: 0.5491 - recall: 0.3785 - val_loss: 0.6672 - val_accuracy: 0.5843 - val_precision: 0.5487 - val_recall: 0.3765\n",
            "Epoch 16/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6676 - accuracy: 0.5848 - precision: 0.5490 - recall: 0.3806 - val_loss: 0.6670 - val_accuracy: 0.5852 - val_precision: 0.5511 - val_recall: 0.3716\n",
            "Epoch 17/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6674 - accuracy: 0.5856 - precision: 0.5499 - recall: 0.3843 - val_loss: 0.6669 - val_accuracy: 0.5859 - val_precision: 0.5544 - val_recall: 0.3582\n",
            "Epoch 18/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6671 - accuracy: 0.5860 - precision: 0.5503 - recall: 0.3858 - val_loss: 0.6666 - val_accuracy: 0.5869 - val_precision: 0.5524 - val_recall: 0.3824\n",
            "Epoch 19/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6669 - accuracy: 0.5864 - precision: 0.5508 - recall: 0.3868 - val_loss: 0.6664 - val_accuracy: 0.5866 - val_precision: 0.5518 - val_recall: 0.3834\n",
            "Epoch 20/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6667 - accuracy: 0.5869 - precision: 0.5512 - recall: 0.3905 - val_loss: 0.6661 - val_accuracy: 0.5870 - val_precision: 0.5499 - val_recall: 0.4006\n",
            "Epoch 21/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6665 - accuracy: 0.5874 - precision: 0.5520 - recall: 0.3912 - val_loss: 0.6660 - val_accuracy: 0.5877 - val_precision: 0.5548 - val_recall: 0.3766\n",
            "Epoch 22/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6663 - accuracy: 0.5877 - precision: 0.5522 - recall: 0.3937 - val_loss: 0.6657 - val_accuracy: 0.5883 - val_precision: 0.5534 - val_recall: 0.3926\n",
            "Epoch 23/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6661 - accuracy: 0.5884 - precision: 0.5532 - recall: 0.3954 - val_loss: 0.6656 - val_accuracy: 0.5890 - val_precision: 0.5586 - val_recall: 0.3690\n",
            "Epoch 24/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6659 - accuracy: 0.5889 - precision: 0.5538 - recall: 0.3964 - val_loss: 0.6653 - val_accuracy: 0.5895 - val_precision: 0.5570 - val_recall: 0.3840\n",
            "Epoch 25/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6657 - accuracy: 0.5894 - precision: 0.5545 - recall: 0.3979 - val_loss: 0.6651 - val_accuracy: 0.5897 - val_precision: 0.5546 - val_recall: 0.4015\n",
            "Epoch 26/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6655 - accuracy: 0.5899 - precision: 0.5550 - recall: 0.4000 - val_loss: 0.6650 - val_accuracy: 0.5900 - val_precision: 0.5507 - val_recall: 0.4319\n",
            "Epoch 27/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6653 - accuracy: 0.5908 - precision: 0.5565 - recall: 0.4006 - val_loss: 0.6648 - val_accuracy: 0.5900 - val_precision: 0.5509 - val_recall: 0.4312\n",
            "Epoch 28/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6652 - accuracy: 0.5906 - precision: 0.5558 - recall: 0.4031 - val_loss: 0.6645 - val_accuracy: 0.5913 - val_precision: 0.5589 - val_recall: 0.3914\n",
            "Epoch 29/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6650 - accuracy: 0.5912 - precision: 0.5568 - recall: 0.4028 - val_loss: 0.6644 - val_accuracy: 0.5917 - val_precision: 0.5597 - val_recall: 0.3907\n",
            "Epoch 30/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6648 - accuracy: 0.5918 - precision: 0.5576 - recall: 0.4047 - val_loss: 0.6641 - val_accuracy: 0.5915 - val_precision: 0.5546 - val_recall: 0.4208\n",
            "Epoch 31/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6646 - accuracy: 0.5921 - precision: 0.5579 - recall: 0.4059 - val_loss: 0.6640 - val_accuracy: 0.5927 - val_precision: 0.5576 - val_recall: 0.4145\n",
            "Epoch 32/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6644 - accuracy: 0.5923 - precision: 0.5583 - recall: 0.4054 - val_loss: 0.6638 - val_accuracy: 0.5927 - val_precision: 0.5587 - val_recall: 0.4078\n",
            "Epoch 33/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6643 - accuracy: 0.5928 - precision: 0.5587 - recall: 0.4083 - val_loss: 0.6637 - val_accuracy: 0.5941 - val_precision: 0.5676 - val_recall: 0.3728\n",
            "Epoch 34/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6641 - accuracy: 0.5930 - precision: 0.5594 - recall: 0.4065 - val_loss: 0.6634 - val_accuracy: 0.5940 - val_precision: 0.5627 - val_recall: 0.3979\n",
            "Epoch 35/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6639 - accuracy: 0.5935 - precision: 0.5603 - recall: 0.4063 - val_loss: 0.6634 - val_accuracy: 0.5937 - val_precision: 0.5549 - val_recall: 0.4437\n",
            "Epoch 36/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6638 - accuracy: 0.5937 - precision: 0.5601 - recall: 0.4089 - val_loss: 0.6631 - val_accuracy: 0.5944 - val_precision: 0.5587 - val_recall: 0.4254\n",
            "Epoch 37/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6636 - accuracy: 0.5944 - precision: 0.5611 - recall: 0.4112 - val_loss: 0.6630 - val_accuracy: 0.5954 - val_precision: 0.5674 - val_recall: 0.3861\n",
            "Epoch 38/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6635 - accuracy: 0.5948 - precision: 0.5620 - recall: 0.4095 - val_loss: 0.6628 - val_accuracy: 0.5950 - val_precision: 0.5628 - val_recall: 0.4071\n",
            "Epoch 39/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6633 - accuracy: 0.5949 - precision: 0.5619 - recall: 0.4114 - val_loss: 0.6627 - val_accuracy: 0.5956 - val_precision: 0.5632 - val_recall: 0.4103\n",
            "Epoch 40/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6632 - accuracy: 0.5952 - precision: 0.5621 - recall: 0.4131 - val_loss: 0.6625 - val_accuracy: 0.5958 - val_precision: 0.5620 - val_recall: 0.4201\n",
            "Epoch 41/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6630 - accuracy: 0.5961 - precision: 0.5638 - recall: 0.4118 - val_loss: 0.6624 - val_accuracy: 0.5956 - val_precision: 0.5593 - val_recall: 0.4351\n",
            "Epoch 42/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6629 - accuracy: 0.5959 - precision: 0.5630 - recall: 0.4147 - val_loss: 0.6622 - val_accuracy: 0.5966 - val_precision: 0.5659 - val_recall: 0.4059\n",
            "Epoch 43/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6628 - accuracy: 0.5961 - precision: 0.5636 - recall: 0.4128 - val_loss: 0.6621 - val_accuracy: 0.5970 - val_precision: 0.5685 - val_recall: 0.3953\n",
            "Epoch 44/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6626 - accuracy: 0.5965 - precision: 0.5640 - recall: 0.4148 - val_loss: 0.6620 - val_accuracy: 0.5974 - val_precision: 0.5689 - val_recall: 0.3971\n",
            "Epoch 45/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6625 - accuracy: 0.5972 - precision: 0.5651 - recall: 0.4151 - val_loss: 0.6619 - val_accuracy: 0.5973 - val_precision: 0.5681 - val_recall: 0.3999\n",
            "Epoch 46/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6624 - accuracy: 0.5970 - precision: 0.5648 - recall: 0.4153 - val_loss: 0.6618 - val_accuracy: 0.5976 - val_precision: 0.5605 - val_recall: 0.4475\n",
            "Epoch 47/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6623 - accuracy: 0.5976 - precision: 0.5656 - recall: 0.4160 - val_loss: 0.6617 - val_accuracy: 0.5980 - val_precision: 0.5706 - val_recall: 0.3947\n",
            "Epoch 48/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6621 - accuracy: 0.5977 - precision: 0.5660 - recall: 0.4151 - val_loss: 0.6615 - val_accuracy: 0.5986 - val_precision: 0.5633 - val_recall: 0.4404\n",
            "Epoch 49/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6620 - accuracy: 0.5983 - precision: 0.5667 - recall: 0.4172 - val_loss: 0.6614 - val_accuracy: 0.5984 - val_precision: 0.5683 - val_recall: 0.4097\n",
            "Epoch 50/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6619 - accuracy: 0.5985 - precision: 0.5666 - recall: 0.4194 - val_loss: 0.6613 - val_accuracy: 0.5992 - val_precision: 0.5689 - val_recall: 0.4138\n",
            "Epoch 51/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6618 - accuracy: 0.5984 - precision: 0.5671 - recall: 0.4156 - val_loss: 0.6612 - val_accuracy: 0.5993 - val_precision: 0.5647 - val_recall: 0.4387\n",
            "Epoch 52/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6617 - accuracy: 0.5990 - precision: 0.5676 - recall: 0.4189 - val_loss: 0.6610 - val_accuracy: 0.5998 - val_precision: 0.5708 - val_recall: 0.4094\n",
            "Epoch 53/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6616 - accuracy: 0.5995 - precision: 0.5682 - recall: 0.4201 - val_loss: 0.6610 - val_accuracy: 0.6007 - val_precision: 0.5731 - val_recall: 0.4058\n",
            "Epoch 54/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6615 - accuracy: 0.5995 - precision: 0.5684 - recall: 0.4193 - val_loss: 0.6610 - val_accuracy: 0.6004 - val_precision: 0.5764 - val_recall: 0.3888\n",
            "Epoch 55/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6614 - accuracy: 0.5994 - precision: 0.5680 - recall: 0.4204 - val_loss: 0.6607 - val_accuracy: 0.6008 - val_precision: 0.5703 - val_recall: 0.4208\n",
            "Epoch 56/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6613 - accuracy: 0.6000 - precision: 0.5687 - recall: 0.4225 - val_loss: 0.6607 - val_accuracy: 0.6014 - val_precision: 0.5762 - val_recall: 0.3973\n",
            "Epoch 57/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6612 - accuracy: 0.6003 - precision: 0.5695 - recall: 0.4208 - val_loss: 0.6606 - val_accuracy: 0.6013 - val_precision: 0.5743 - val_recall: 0.4059\n",
            "Epoch 58/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6611 - accuracy: 0.6005 - precision: 0.5698 - recall: 0.4209 - val_loss: 0.6605 - val_accuracy: 0.6015 - val_precision: 0.5681 - val_recall: 0.4402\n",
            "Epoch 59/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6610 - accuracy: 0.6008 - precision: 0.5696 - recall: 0.4248 - val_loss: 0.6604 - val_accuracy: 0.6019 - val_precision: 0.5681 - val_recall: 0.4428\n",
            "Epoch 60/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6609 - accuracy: 0.6008 - precision: 0.5698 - recall: 0.4237 - val_loss: 0.6603 - val_accuracy: 0.6017 - val_precision: 0.5742 - val_recall: 0.4099\n",
            "Epoch 61/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6608 - accuracy: 0.6012 - precision: 0.5705 - recall: 0.4240 - val_loss: 0.6602 - val_accuracy: 0.6023 - val_precision: 0.5712 - val_recall: 0.4304\n",
            "Epoch 62/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6607 - accuracy: 0.6013 - precision: 0.5703 - recall: 0.4257 - val_loss: 0.6601 - val_accuracy: 0.6026 - val_precision: 0.5744 - val_recall: 0.4163\n",
            "Epoch 63/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6606 - accuracy: 0.6016 - precision: 0.5706 - recall: 0.4269 - val_loss: 0.6602 - val_accuracy: 0.6019 - val_precision: 0.5800 - val_recall: 0.3859\n",
            "Epoch 64/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6606 - accuracy: 0.6018 - precision: 0.5711 - recall: 0.4263 - val_loss: 0.6599 - val_accuracy: 0.6031 - val_precision: 0.5760 - val_recall: 0.4129\n",
            "Epoch 65/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6605 - accuracy: 0.6022 - precision: 0.5718 - recall: 0.4255 - val_loss: 0.6599 - val_accuracy: 0.6029 - val_precision: 0.5685 - val_recall: 0.4505\n",
            "Epoch 66/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6604 - accuracy: 0.6025 - precision: 0.5719 - recall: 0.4279 - val_loss: 0.6598 - val_accuracy: 0.6030 - val_precision: 0.5765 - val_recall: 0.4095\n",
            "Epoch 67/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6603 - accuracy: 0.6029 - precision: 0.5726 - recall: 0.4278 - val_loss: 0.6597 - val_accuracy: 0.6030 - val_precision: 0.5731 - val_recall: 0.4264\n",
            "Epoch 68/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6602 - accuracy: 0.6028 - precision: 0.5722 - recall: 0.4294 - val_loss: 0.6597 - val_accuracy: 0.6037 - val_precision: 0.5773 - val_recall: 0.4122\n",
            "Epoch 69/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6602 - accuracy: 0.6031 - precision: 0.5728 - recall: 0.4288 - val_loss: 0.6595 - val_accuracy: 0.6041 - val_precision: 0.5711 - val_recall: 0.4468\n",
            "Epoch 70/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6601 - accuracy: 0.6035 - precision: 0.5731 - recall: 0.4309 - val_loss: 0.6595 - val_accuracy: 0.6038 - val_precision: 0.5699 - val_recall: 0.4511\n",
            "Epoch 71/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6600 - accuracy: 0.6040 - precision: 0.5736 - recall: 0.4329 - val_loss: 0.6594 - val_accuracy: 0.6040 - val_precision: 0.5767 - val_recall: 0.4169\n",
            "Epoch 72/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6599 - accuracy: 0.6041 - precision: 0.5738 - recall: 0.4319 - val_loss: 0.6593 - val_accuracy: 0.6052 - val_precision: 0.5744 - val_recall: 0.4391\n",
            "Epoch 73/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6599 - accuracy: 0.6040 - precision: 0.5739 - recall: 0.4309 - val_loss: 0.6593 - val_accuracy: 0.6048 - val_precision: 0.5723 - val_recall: 0.4464\n",
            "Epoch 74/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6598 - accuracy: 0.6043 - precision: 0.5741 - recall: 0.4330 - val_loss: 0.6592 - val_accuracy: 0.6049 - val_precision: 0.5749 - val_recall: 0.4336\n",
            "Epoch 75/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6598 - accuracy: 0.6044 - precision: 0.5742 - recall: 0.4331 - val_loss: 0.6591 - val_accuracy: 0.6055 - val_precision: 0.5763 - val_recall: 0.4324\n",
            "Epoch 76/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6597 - accuracy: 0.6047 - precision: 0.5743 - recall: 0.4355 - val_loss: 0.6596 - val_accuracy: 0.6055 - val_precision: 0.5904 - val_recall: 0.3734\n",
            "Epoch 77/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6597 - accuracy: 0.6049 - precision: 0.5750 - recall: 0.4333 - val_loss: 0.6592 - val_accuracy: 0.6059 - val_precision: 0.5846 - val_recall: 0.3986\n",
            "Epoch 78/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6596 - accuracy: 0.6051 - precision: 0.5750 - recall: 0.4351 - val_loss: 0.6590 - val_accuracy: 0.6057 - val_precision: 0.5786 - val_recall: 0.4225\n",
            "Epoch 79/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6595 - accuracy: 0.6054 - precision: 0.5756 - recall: 0.4348 - val_loss: 0.6589 - val_accuracy: 0.6060 - val_precision: 0.5732 - val_recall: 0.4523\n",
            "Epoch 80/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6595 - accuracy: 0.6055 - precision: 0.5751 - recall: 0.4372 - val_loss: 0.6589 - val_accuracy: 0.6066 - val_precision: 0.5811 - val_recall: 0.4189\n",
            "Epoch 81/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6594 - accuracy: 0.6054 - precision: 0.5758 - recall: 0.4337 - val_loss: 0.6588 - val_accuracy: 0.6062 - val_precision: 0.5726 - val_recall: 0.4577\n",
            "Epoch 82/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6594 - accuracy: 0.6056 - precision: 0.5752 - recall: 0.4378 - val_loss: 0.6588 - val_accuracy: 0.6063 - val_precision: 0.5825 - val_recall: 0.4103\n",
            "Epoch 83/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6593 - accuracy: 0.6057 - precision: 0.5758 - recall: 0.4355 - val_loss: 0.6587 - val_accuracy: 0.6063 - val_precision: 0.5766 - val_recall: 0.4370\n",
            "Epoch 84/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6593 - accuracy: 0.6061 - precision: 0.5761 - recall: 0.4375 - val_loss: 0.6588 - val_accuracy: 0.6064 - val_precision: 0.5701 - val_recall: 0.4731\n",
            "Epoch 85/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6592 - accuracy: 0.6060 - precision: 0.5760 - recall: 0.4374 - val_loss: 0.6586 - val_accuracy: 0.6065 - val_precision: 0.5768 - val_recall: 0.4382\n",
            "Epoch 86/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6592 - accuracy: 0.6059 - precision: 0.5758 - recall: 0.4381 - val_loss: 0.6585 - val_accuracy: 0.6073 - val_precision: 0.5793 - val_recall: 0.4331\n",
            "Epoch 87/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6591 - accuracy: 0.6065 - precision: 0.5764 - recall: 0.4397 - val_loss: 0.6588 - val_accuracy: 0.6069 - val_precision: 0.5871 - val_recall: 0.3963\n",
            "Epoch 88/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6591 - accuracy: 0.6062 - precision: 0.5762 - recall: 0.4382 - val_loss: 0.6584 - val_accuracy: 0.6071 - val_precision: 0.5746 - val_recall: 0.4539\n",
            "Epoch 89/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6590 - accuracy: 0.6065 - precision: 0.5763 - recall: 0.4401 - val_loss: 0.6584 - val_accuracy: 0.6076 - val_precision: 0.5762 - val_recall: 0.4500\n",
            "Epoch 90/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6590 - accuracy: 0.6067 - precision: 0.5767 - recall: 0.4400 - val_loss: 0.6585 - val_accuracy: 0.6072 - val_precision: 0.5838 - val_recall: 0.4117\n",
            "Epoch 91/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6589 - accuracy: 0.6067 - precision: 0.5768 - recall: 0.4396 - val_loss: 0.6583 - val_accuracy: 0.6077 - val_precision: 0.5767 - val_recall: 0.4483\n",
            "Epoch 92/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6589 - accuracy: 0.6068 - precision: 0.5769 - recall: 0.4398 - val_loss: 0.6585 - val_accuracy: 0.6066 - val_precision: 0.5678 - val_recall: 0.4887\n",
            "Epoch 93/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6588 - accuracy: 0.6067 - precision: 0.5765 - recall: 0.4414 - val_loss: 0.6582 - val_accuracy: 0.6077 - val_precision: 0.5779 - val_recall: 0.4424\n",
            "Epoch 94/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6588 - accuracy: 0.6069 - precision: 0.5767 - recall: 0.4418 - val_loss: 0.6583 - val_accuracy: 0.6080 - val_precision: 0.5861 - val_recall: 0.4082\n",
            "Epoch 95/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6587 - accuracy: 0.6069 - precision: 0.5770 - recall: 0.4404 - val_loss: 0.6582 - val_accuracy: 0.6084 - val_precision: 0.5829 - val_recall: 0.4251\n",
            "Epoch 96/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6587 - accuracy: 0.6071 - precision: 0.5772 - recall: 0.4407 - val_loss: 0.6581 - val_accuracy: 0.6089 - val_precision: 0.5818 - val_recall: 0.4337\n",
            "Epoch 97/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6586 - accuracy: 0.6075 - precision: 0.5776 - recall: 0.4421 - val_loss: 0.6581 - val_accuracy: 0.6085 - val_precision: 0.5831 - val_recall: 0.4244\n",
            "Epoch 98/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6586 - accuracy: 0.6074 - precision: 0.5776 - recall: 0.4414 - val_loss: 0.6580 - val_accuracy: 0.6090 - val_precision: 0.5799 - val_recall: 0.4437\n",
            "Epoch 99/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6586 - accuracy: 0.6073 - precision: 0.5774 - recall: 0.4421 - val_loss: 0.6580 - val_accuracy: 0.6090 - val_precision: 0.5841 - val_recall: 0.4241\n",
            "Epoch 100/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6585 - accuracy: 0.6075 - precision: 0.5778 - recall: 0.4419 - val_loss: 0.6580 - val_accuracy: 0.6090 - val_precision: 0.5849 - val_recall: 0.4209\n",
            "Epoch 101/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6585 - accuracy: 0.6079 - precision: 0.5782 - recall: 0.4427 - val_loss: 0.6578 - val_accuracy: 0.6089 - val_precision: 0.5784 - val_recall: 0.4502\n",
            "Epoch 102/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6585 - accuracy: 0.6075 - precision: 0.5775 - recall: 0.4427 - val_loss: 0.6578 - val_accuracy: 0.6094 - val_precision: 0.5798 - val_recall: 0.4475\n",
            "Epoch 103/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6584 - accuracy: 0.6075 - precision: 0.5777 - recall: 0.4421 - val_loss: 0.6578 - val_accuracy: 0.6088 - val_precision: 0.5782 - val_recall: 0.4508\n",
            "Epoch 104/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6584 - accuracy: 0.6080 - precision: 0.5782 - recall: 0.4436 - val_loss: 0.6577 - val_accuracy: 0.6088 - val_precision: 0.5764 - val_recall: 0.4596\n",
            "Epoch 105/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6583 - accuracy: 0.6077 - precision: 0.5776 - recall: 0.4443 - val_loss: 0.6577 - val_accuracy: 0.6097 - val_precision: 0.5822 - val_recall: 0.4386\n",
            "Epoch 106/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6583 - accuracy: 0.6079 - precision: 0.5781 - recall: 0.4432 - val_loss: 0.6578 - val_accuracy: 0.6086 - val_precision: 0.5731 - val_recall: 0.4757\n",
            "Epoch 107/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6583 - accuracy: 0.6081 - precision: 0.5782 - recall: 0.4442 - val_loss: 0.6576 - val_accuracy: 0.6098 - val_precision: 0.5791 - val_recall: 0.4542\n",
            "Epoch 108/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6582 - accuracy: 0.6081 - precision: 0.5780 - recall: 0.4455 - val_loss: 0.6576 - val_accuracy: 0.6102 - val_precision: 0.5840 - val_recall: 0.4342\n",
            "Epoch 109/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6582 - accuracy: 0.6083 - precision: 0.5785 - recall: 0.4447 - val_loss: 0.6576 - val_accuracy: 0.6095 - val_precision: 0.5838 - val_recall: 0.4295\n",
            "Epoch 110/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6582 - accuracy: 0.6084 - precision: 0.5788 - recall: 0.4437 - val_loss: 0.6576 - val_accuracy: 0.6093 - val_precision: 0.5761 - val_recall: 0.4653\n",
            "Epoch 111/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6581 - accuracy: 0.6084 - precision: 0.5784 - recall: 0.4455 - val_loss: 0.6575 - val_accuracy: 0.6099 - val_precision: 0.5812 - val_recall: 0.4443\n",
            "Epoch 112/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6581 - accuracy: 0.6084 - precision: 0.5786 - recall: 0.4451 - val_loss: 0.6574 - val_accuracy: 0.6102 - val_precision: 0.5803 - val_recall: 0.4510\n",
            "Epoch 113/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6580 - accuracy: 0.6087 - precision: 0.5789 - recall: 0.4461 - val_loss: 0.6576 - val_accuracy: 0.6098 - val_precision: 0.5844 - val_recall: 0.4293\n",
            "Epoch 114/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6580 - accuracy: 0.6088 - precision: 0.5789 - recall: 0.4464 - val_loss: 0.6574 - val_accuracy: 0.6095 - val_precision: 0.5767 - val_recall: 0.4641\n",
            "Epoch 115/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6580 - accuracy: 0.6089 - precision: 0.5790 - recall: 0.4470 - val_loss: 0.6574 - val_accuracy: 0.6100 - val_precision: 0.5758 - val_recall: 0.4727\n",
            "Epoch 116/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6580 - accuracy: 0.6088 - precision: 0.5788 - recall: 0.4468 - val_loss: 0.6573 - val_accuracy: 0.6106 - val_precision: 0.5847 - val_recall: 0.4341\n",
            "Epoch 117/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6579 - accuracy: 0.6089 - precision: 0.5792 - recall: 0.4459 - val_loss: 0.6573 - val_accuracy: 0.6101 - val_precision: 0.5806 - val_recall: 0.4496\n",
            "Epoch 118/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6579 - accuracy: 0.6089 - precision: 0.5790 - recall: 0.4469 - val_loss: 0.6573 - val_accuracy: 0.6096 - val_precision: 0.5749 - val_recall: 0.4745\n",
            "Epoch 119/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6578 - accuracy: 0.6090 - precision: 0.5791 - recall: 0.4477 - val_loss: 0.6573 - val_accuracy: 0.6108 - val_precision: 0.5816 - val_recall: 0.4496\n",
            "Epoch 120/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6578 - accuracy: 0.6093 - precision: 0.5796 - recall: 0.4475 - val_loss: 0.6572 - val_accuracy: 0.6102 - val_precision: 0.5853 - val_recall: 0.4286\n",
            "Epoch 121/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6578 - accuracy: 0.6092 - precision: 0.5794 - recall: 0.4478 - val_loss: 0.6573 - val_accuracy: 0.6106 - val_precision: 0.5877 - val_recall: 0.4217\n",
            "Epoch 122/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6578 - accuracy: 0.6094 - precision: 0.5798 - recall: 0.4470 - val_loss: 0.6572 - val_accuracy: 0.6100 - val_precision: 0.5764 - val_recall: 0.4701\n",
            "Epoch 123/200\n",
            "468/468 [==============================] - 4s 9ms/step - loss: 0.6577 - accuracy: 0.6093 - precision: 0.5792 - recall: 0.4494 - val_loss: 0.6571 - val_accuracy: 0.6109 - val_precision: 0.5833 - val_recall: 0.4427\n",
            "Epoch 124/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6577 - accuracy: 0.6095 - precision: 0.5799 - recall: 0.4481 - val_loss: 0.6570 - val_accuracy: 0.6108 - val_precision: 0.5818 - val_recall: 0.4490\n",
            "Epoch 125/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6576 - accuracy: 0.6096 - precision: 0.5799 - recall: 0.4479 - val_loss: 0.6573 - val_accuracy: 0.6098 - val_precision: 0.5721 - val_recall: 0.4924\n",
            "Epoch 126/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6576 - accuracy: 0.6092 - precision: 0.5793 - recall: 0.4481 - val_loss: 0.6570 - val_accuracy: 0.6106 - val_precision: 0.5818 - val_recall: 0.4475\n",
            "Epoch 127/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6575 - accuracy: 0.6096 - precision: 0.5798 - recall: 0.4489 - val_loss: 0.6570 - val_accuracy: 0.6110 - val_precision: 0.5867 - val_recall: 0.4285\n",
            "Epoch 128/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6575 - accuracy: 0.6097 - precision: 0.5800 - recall: 0.4488 - val_loss: 0.6569 - val_accuracy: 0.6105 - val_precision: 0.5804 - val_recall: 0.4538\n",
            "Epoch 129/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6575 - accuracy: 0.6100 - precision: 0.5802 - recall: 0.4496 - val_loss: 0.6569 - val_accuracy: 0.6105 - val_precision: 0.5808 - val_recall: 0.4515\n",
            "Epoch 130/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6574 - accuracy: 0.6102 - precision: 0.5806 - recall: 0.4498 - val_loss: 0.6569 - val_accuracy: 0.6110 - val_precision: 0.5858 - val_recall: 0.4329\n",
            "Epoch 131/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6574 - accuracy: 0.6103 - precision: 0.5809 - recall: 0.4496 - val_loss: 0.6568 - val_accuracy: 0.6107 - val_precision: 0.5817 - val_recall: 0.4485\n",
            "Epoch 132/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6574 - accuracy: 0.6103 - precision: 0.5809 - recall: 0.4493 - val_loss: 0.6569 - val_accuracy: 0.6109 - val_precision: 0.5761 - val_recall: 0.4784\n",
            "Epoch 133/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6573 - accuracy: 0.6104 - precision: 0.5808 - recall: 0.4504 - val_loss: 0.6568 - val_accuracy: 0.6106 - val_precision: 0.5763 - val_recall: 0.4748\n",
            "Epoch 134/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6573 - accuracy: 0.6102 - precision: 0.5806 - recall: 0.4495 - val_loss: 0.6567 - val_accuracy: 0.6108 - val_precision: 0.5799 - val_recall: 0.4587\n",
            "Epoch 135/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6572 - accuracy: 0.6106 - precision: 0.5812 - recall: 0.4500 - val_loss: 0.6567 - val_accuracy: 0.6109 - val_precision: 0.5791 - val_recall: 0.4629\n",
            "Epoch 136/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6572 - accuracy: 0.6104 - precision: 0.5807 - recall: 0.4512 - val_loss: 0.6570 - val_accuracy: 0.6113 - val_precision: 0.5905 - val_recall: 0.4158\n",
            "Epoch 137/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6572 - accuracy: 0.6103 - precision: 0.5808 - recall: 0.4499 - val_loss: 0.6566 - val_accuracy: 0.6114 - val_precision: 0.5832 - val_recall: 0.4476\n",
            "Epoch 138/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6572 - accuracy: 0.6104 - precision: 0.5808 - recall: 0.4507 - val_loss: 0.6566 - val_accuracy: 0.6109 - val_precision: 0.5792 - val_recall: 0.4627\n",
            "Epoch 139/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6572 - accuracy: 0.6103 - precision: 0.5807 - recall: 0.4499 - val_loss: 0.6566 - val_accuracy: 0.6118 - val_precision: 0.5852 - val_recall: 0.4419\n",
            "Epoch 140/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6571 - accuracy: 0.6108 - precision: 0.5815 - recall: 0.4503 - val_loss: 0.6567 - val_accuracy: 0.6119 - val_precision: 0.5914 - val_recall: 0.4168\n",
            "Epoch 141/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6571 - accuracy: 0.6106 - precision: 0.5810 - recall: 0.4508 - val_loss: 0.6565 - val_accuracy: 0.6118 - val_precision: 0.5842 - val_recall: 0.4458\n",
            "Epoch 142/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6571 - accuracy: 0.6106 - precision: 0.5814 - recall: 0.4487 - val_loss: 0.6565 - val_accuracy: 0.6110 - val_precision: 0.5790 - val_recall: 0.4648\n",
            "Epoch 143/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6570 - accuracy: 0.6105 - precision: 0.5807 - recall: 0.4516 - val_loss: 0.6565 - val_accuracy: 0.6116 - val_precision: 0.5820 - val_recall: 0.4545\n",
            "Epoch 144/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6570 - accuracy: 0.6103 - precision: 0.5809 - recall: 0.4495 - val_loss: 0.6565 - val_accuracy: 0.6108 - val_precision: 0.5770 - val_recall: 0.4733\n",
            "Epoch 145/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6569 - accuracy: 0.6104 - precision: 0.5808 - recall: 0.4509 - val_loss: 0.6564 - val_accuracy: 0.6117 - val_precision: 0.5832 - val_recall: 0.4497\n",
            "Epoch 146/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6569 - accuracy: 0.6110 - precision: 0.5817 - recall: 0.4507 - val_loss: 0.6565 - val_accuracy: 0.6110 - val_precision: 0.5763 - val_recall: 0.4785\n",
            "Epoch 147/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6569 - accuracy: 0.6105 - precision: 0.5813 - recall: 0.4493 - val_loss: 0.6564 - val_accuracy: 0.6108 - val_precision: 0.5773 - val_recall: 0.4716\n",
            "Epoch 148/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6569 - accuracy: 0.6106 - precision: 0.5810 - recall: 0.4513 - val_loss: 0.6563 - val_accuracy: 0.6117 - val_precision: 0.5805 - val_recall: 0.4624\n",
            "Epoch 149/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6569 - accuracy: 0.6111 - precision: 0.5819 - recall: 0.4507 - val_loss: 0.6563 - val_accuracy: 0.6121 - val_precision: 0.5877 - val_recall: 0.4332\n",
            "Epoch 150/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6568 - accuracy: 0.6111 - precision: 0.5818 - recall: 0.4510 - val_loss: 0.6563 - val_accuracy: 0.6118 - val_precision: 0.5800 - val_recall: 0.4659\n",
            "Epoch 151/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6568 - accuracy: 0.6109 - precision: 0.5813 - recall: 0.4520 - val_loss: 0.6564 - val_accuracy: 0.6122 - val_precision: 0.5924 - val_recall: 0.4149\n",
            "Epoch 152/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6568 - accuracy: 0.6113 - precision: 0.5827 - recall: 0.4485 - val_loss: 0.6562 - val_accuracy: 0.6117 - val_precision: 0.5819 - val_recall: 0.4561\n",
            "Epoch 153/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6567 - accuracy: 0.6107 - precision: 0.5811 - recall: 0.4519 - val_loss: 0.6562 - val_accuracy: 0.6121 - val_precision: 0.5875 - val_recall: 0.4342\n",
            "Epoch 154/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6567 - accuracy: 0.6108 - precision: 0.5815 - recall: 0.4509 - val_loss: 0.6561 - val_accuracy: 0.6121 - val_precision: 0.5848 - val_recall: 0.4453\n",
            "Epoch 155/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6567 - accuracy: 0.6112 - precision: 0.5822 - recall: 0.4505 - val_loss: 0.6561 - val_accuracy: 0.6123 - val_precision: 0.5834 - val_recall: 0.4536\n",
            "Epoch 156/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6566 - accuracy: 0.6112 - precision: 0.5820 - recall: 0.4511 - val_loss: 0.6561 - val_accuracy: 0.6125 - val_precision: 0.5859 - val_recall: 0.4438\n",
            "Epoch 157/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6566 - accuracy: 0.6112 - precision: 0.5822 - recall: 0.4503 - val_loss: 0.6561 - val_accuracy: 0.6121 - val_precision: 0.5840 - val_recall: 0.4495\n",
            "Epoch 158/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6566 - accuracy: 0.6112 - precision: 0.5824 - recall: 0.4493 - val_loss: 0.6561 - val_accuracy: 0.6117 - val_precision: 0.5788 - val_recall: 0.4708\n",
            "Epoch 159/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6566 - accuracy: 0.6110 - precision: 0.5816 - recall: 0.4517 - val_loss: 0.6561 - val_accuracy: 0.6123 - val_precision: 0.5887 - val_recall: 0.4299\n",
            "Epoch 160/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6565 - accuracy: 0.6109 - precision: 0.5820 - recall: 0.4490 - val_loss: 0.6560 - val_accuracy: 0.6121 - val_precision: 0.5816 - val_recall: 0.4600\n",
            "Epoch 161/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6565 - accuracy: 0.6110 - precision: 0.5819 - recall: 0.4502 - val_loss: 0.6560 - val_accuracy: 0.6117 - val_precision: 0.5792 - val_recall: 0.4693\n",
            "Epoch 162/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6564 - accuracy: 0.6114 - precision: 0.5825 - recall: 0.4504 - val_loss: 0.6560 - val_accuracy: 0.6120 - val_precision: 0.5802 - val_recall: 0.4668\n",
            "Epoch 163/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6564 - accuracy: 0.6112 - precision: 0.5821 - recall: 0.4510 - val_loss: 0.6559 - val_accuracy: 0.6123 - val_precision: 0.5856 - val_recall: 0.4434\n",
            "Epoch 164/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6564 - accuracy: 0.6114 - precision: 0.5825 - recall: 0.4501 - val_loss: 0.6559 - val_accuracy: 0.6119 - val_precision: 0.5801 - val_recall: 0.4661\n",
            "Epoch 165/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6564 - accuracy: 0.6112 - precision: 0.5827 - recall: 0.4480 - val_loss: 0.6558 - val_accuracy: 0.6122 - val_precision: 0.5831 - val_recall: 0.4543\n",
            "Epoch 166/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6563 - accuracy: 0.6110 - precision: 0.5817 - recall: 0.4507 - val_loss: 0.6560 - val_accuracy: 0.6126 - val_precision: 0.5938 - val_recall: 0.4121\n",
            "Epoch 167/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6563 - accuracy: 0.6111 - precision: 0.5825 - recall: 0.4484 - val_loss: 0.6558 - val_accuracy: 0.6124 - val_precision: 0.5861 - val_recall: 0.4422\n",
            "Epoch 168/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6563 - accuracy: 0.6111 - precision: 0.5821 - recall: 0.4497 - val_loss: 0.6559 - val_accuracy: 0.6117 - val_precision: 0.5773 - val_recall: 0.4791\n",
            "Epoch 169/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6563 - accuracy: 0.6113 - precision: 0.5824 - recall: 0.4500 - val_loss: 0.6557 - val_accuracy: 0.6124 - val_precision: 0.5839 - val_recall: 0.4523\n",
            "Epoch 170/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6562 - accuracy: 0.6115 - precision: 0.5829 - recall: 0.4494 - val_loss: 0.6557 - val_accuracy: 0.6117 - val_precision: 0.5786 - val_recall: 0.4720\n",
            "Epoch 171/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6562 - accuracy: 0.6111 - precision: 0.5822 - recall: 0.4496 - val_loss: 0.6556 - val_accuracy: 0.6123 - val_precision: 0.5823 - val_recall: 0.4590\n",
            "Epoch 172/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6562 - accuracy: 0.6117 - precision: 0.5830 - recall: 0.4504 - val_loss: 0.6556 - val_accuracy: 0.6124 - val_precision: 0.5827 - val_recall: 0.4580\n",
            "Epoch 173/200\n",
            "468/468 [==============================] - 4s 9ms/step - loss: 0.6562 - accuracy: 0.6112 - precision: 0.5823 - recall: 0.4495 - val_loss: 0.6557 - val_accuracy: 0.6122 - val_precision: 0.5789 - val_recall: 0.4750\n",
            "Epoch 174/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6561 - accuracy: 0.6116 - precision: 0.5831 - recall: 0.4492 - val_loss: 0.6555 - val_accuracy: 0.6128 - val_precision: 0.5872 - val_recall: 0.4404\n",
            "Epoch 175/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6561 - accuracy: 0.6110 - precision: 0.5825 - recall: 0.4473 - val_loss: 0.6556 - val_accuracy: 0.6122 - val_precision: 0.5793 - val_recall: 0.4728\n",
            "Epoch 176/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6561 - accuracy: 0.6115 - precision: 0.5828 - recall: 0.4502 - val_loss: 0.6555 - val_accuracy: 0.6124 - val_precision: 0.5866 - val_recall: 0.4401\n",
            "Epoch 177/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6560 - accuracy: 0.6111 - precision: 0.5825 - recall: 0.4486 - val_loss: 0.6556 - val_accuracy: 0.6121 - val_precision: 0.5783 - val_recall: 0.4778\n",
            "Epoch 178/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6560 - accuracy: 0.6113 - precision: 0.5825 - recall: 0.4495 - val_loss: 0.6554 - val_accuracy: 0.6127 - val_precision: 0.5874 - val_recall: 0.4383\n",
            "Epoch 179/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6560 - accuracy: 0.6112 - precision: 0.5828 - recall: 0.4477 - val_loss: 0.6555 - val_accuracy: 0.6124 - val_precision: 0.5790 - val_recall: 0.4763\n",
            "Epoch 180/200\n",
            "468/468 [==============================] - 4s 9ms/step - loss: 0.6559 - accuracy: 0.6113 - precision: 0.5829 - recall: 0.4481 - val_loss: 0.6554 - val_accuracy: 0.6123 - val_precision: 0.5810 - val_recall: 0.4652\n",
            "Epoch 181/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6559 - accuracy: 0.6112 - precision: 0.5823 - recall: 0.4501 - val_loss: 0.6553 - val_accuracy: 0.6127 - val_precision: 0.5853 - val_recall: 0.4478\n",
            "Epoch 182/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6559 - accuracy: 0.6116 - precision: 0.5831 - recall: 0.4492 - val_loss: 0.6553 - val_accuracy: 0.6130 - val_precision: 0.5884 - val_recall: 0.4368\n",
            "Epoch 183/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6559 - accuracy: 0.6115 - precision: 0.5832 - recall: 0.4483 - val_loss: 0.6553 - val_accuracy: 0.6126 - val_precision: 0.5843 - val_recall: 0.4514\n",
            "Epoch 184/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6558 - accuracy: 0.6114 - precision: 0.5827 - recall: 0.4493 - val_loss: 0.6553 - val_accuracy: 0.6129 - val_precision: 0.5895 - val_recall: 0.4313\n",
            "Epoch 185/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6558 - accuracy: 0.6114 - precision: 0.5829 - recall: 0.4485 - val_loss: 0.6552 - val_accuracy: 0.6131 - val_precision: 0.5858 - val_recall: 0.4489\n",
            "Epoch 186/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6558 - accuracy: 0.6115 - precision: 0.5834 - recall: 0.4472 - val_loss: 0.6553 - val_accuracy: 0.6123 - val_precision: 0.5780 - val_recall: 0.4807\n",
            "Epoch 187/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6557 - accuracy: 0.6117 - precision: 0.5831 - recall: 0.4499 - val_loss: 0.6551 - val_accuracy: 0.6125 - val_precision: 0.5827 - val_recall: 0.4589\n",
            "Epoch 188/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6557 - accuracy: 0.6114 - precision: 0.5829 - recall: 0.4484 - val_loss: 0.6551 - val_accuracy: 0.6132 - val_precision: 0.5898 - val_recall: 0.4324\n",
            "Epoch 189/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6557 - accuracy: 0.6118 - precision: 0.5836 - recall: 0.4483 - val_loss: 0.6552 - val_accuracy: 0.6126 - val_precision: 0.5882 - val_recall: 0.4344\n",
            "Epoch 190/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6556 - accuracy: 0.6114 - precision: 0.5828 - recall: 0.4488 - val_loss: 0.6551 - val_accuracy: 0.6133 - val_precision: 0.5907 - val_recall: 0.4295\n",
            "Epoch 191/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6556 - accuracy: 0.6113 - precision: 0.5829 - recall: 0.4478 - val_loss: 0.6550 - val_accuracy: 0.6126 - val_precision: 0.5807 - val_recall: 0.4687\n",
            "Epoch 192/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6556 - accuracy: 0.6117 - precision: 0.5836 - recall: 0.4478 - val_loss: 0.6550 - val_accuracy: 0.6128 - val_precision: 0.5849 - val_recall: 0.4507\n",
            "Epoch 193/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6555 - accuracy: 0.6115 - precision: 0.5830 - recall: 0.4491 - val_loss: 0.6550 - val_accuracy: 0.6122 - val_precision: 0.5799 - val_recall: 0.4700\n",
            "Epoch 194/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6555 - accuracy: 0.6114 - precision: 0.5831 - recall: 0.4475 - val_loss: 0.6549 - val_accuracy: 0.6128 - val_precision: 0.5848 - val_recall: 0.4509\n",
            "Epoch 195/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6554 - accuracy: 0.6118 - precision: 0.5838 - recall: 0.4478 - val_loss: 0.6550 - val_accuracy: 0.6119 - val_precision: 0.5766 - val_recall: 0.4848\n",
            "Epoch 196/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6554 - accuracy: 0.6117 - precision: 0.5835 - recall: 0.4481 - val_loss: 0.6549 - val_accuracy: 0.6124 - val_precision: 0.5825 - val_recall: 0.4586\n",
            "Epoch 197/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6554 - accuracy: 0.6116 - precision: 0.5834 - recall: 0.4480 - val_loss: 0.6548 - val_accuracy: 0.6129 - val_precision: 0.5815 - val_recall: 0.4673\n",
            "Epoch 198/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6553 - accuracy: 0.6115 - precision: 0.5830 - recall: 0.4492 - val_loss: 0.6548 - val_accuracy: 0.6128 - val_precision: 0.5828 - val_recall: 0.4600\n",
            "Epoch 199/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6553 - accuracy: 0.6115 - precision: 0.5833 - recall: 0.4479 - val_loss: 0.6547 - val_accuracy: 0.6126 - val_precision: 0.5831 - val_recall: 0.4576\n",
            "Epoch 200/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6553 - accuracy: 0.6119 - precision: 0.5839 - recall: 0.4481 - val_loss: 0.6547 - val_accuracy: 0.6131 - val_precision: 0.5834 - val_recall: 0.4598\n",
            "Epoch 1/200\n",
            "468/468 [==============================] - 6s 8ms/step - loss: 0.6895 - accuracy: 0.5285 - precision: 0.4480 - recall: 0.2514 - val_loss: 0.6836 - val_accuracy: 0.5546 - val_precision: 0.5004 - val_recall: 0.0347\n",
            "Epoch 2/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6806 - accuracy: 0.5623 - precision: 0.5302 - recall: 0.1530 - val_loss: 0.6779 - val_accuracy: 0.5663 - val_precision: 0.5304 - val_recall: 0.2304\n",
            "Epoch 3/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6756 - accuracy: 0.5717 - precision: 0.5371 - recall: 0.2782 - val_loss: 0.6736 - val_accuracy: 0.5717 - val_precision: 0.5345 - val_recall: 0.2976\n",
            "Epoch 4/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6724 - accuracy: 0.5754 - precision: 0.5375 - recall: 0.3351 - val_loss: 0.6713 - val_accuracy: 0.5758 - val_precision: 0.5349 - val_recall: 0.3664\n",
            "Epoch 5/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6708 - accuracy: 0.5778 - precision: 0.5382 - recall: 0.3673 - val_loss: 0.6701 - val_accuracy: 0.5773 - val_precision: 0.5364 - val_recall: 0.3766\n",
            "Epoch 6/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6699 - accuracy: 0.5794 - precision: 0.5386 - recall: 0.3886 - val_loss: 0.6693 - val_accuracy: 0.5796 - val_precision: 0.5368 - val_recall: 0.4098\n",
            "Epoch 7/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6692 - accuracy: 0.5799 - precision: 0.5376 - recall: 0.4071 - val_loss: 0.6687 - val_accuracy: 0.5802 - val_precision: 0.5376 - val_recall: 0.4113\n",
            "Epoch 8/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6687 - accuracy: 0.5804 - precision: 0.5373 - recall: 0.4175 - val_loss: 0.6682 - val_accuracy: 0.5802 - val_precision: 0.5351 - val_recall: 0.4392\n",
            "Epoch 9/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6683 - accuracy: 0.5813 - precision: 0.5376 - recall: 0.4296 - val_loss: 0.6678 - val_accuracy: 0.5806 - val_precision: 0.5355 - val_recall: 0.4408\n",
            "Epoch 10/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6679 - accuracy: 0.5814 - precision: 0.5374 - recall: 0.4316 - val_loss: 0.6675 - val_accuracy: 0.5814 - val_precision: 0.5358 - val_recall: 0.4507\n",
            "Epoch 11/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6676 - accuracy: 0.5823 - precision: 0.5386 - recall: 0.4346 - val_loss: 0.6671 - val_accuracy: 0.5824 - val_precision: 0.5394 - val_recall: 0.4274\n",
            "Epoch 12/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6673 - accuracy: 0.5828 - precision: 0.5400 - recall: 0.4280 - val_loss: 0.6669 - val_accuracy: 0.5828 - val_precision: 0.5392 - val_recall: 0.4364\n",
            "Epoch 13/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6671 - accuracy: 0.5833 - precision: 0.5408 - recall: 0.4280 - val_loss: 0.6666 - val_accuracy: 0.5832 - val_precision: 0.5407 - val_recall: 0.4270\n",
            "Epoch 14/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6669 - accuracy: 0.5839 - precision: 0.5421 - recall: 0.4242 - val_loss: 0.6664 - val_accuracy: 0.5834 - val_precision: 0.5413 - val_recall: 0.4241\n",
            "Epoch 15/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6667 - accuracy: 0.5840 - precision: 0.5422 - recall: 0.4241 - val_loss: 0.6662 - val_accuracy: 0.5840 - val_precision: 0.5421 - val_recall: 0.4254\n",
            "Epoch 16/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6665 - accuracy: 0.5844 - precision: 0.5429 - recall: 0.4235 - val_loss: 0.6661 - val_accuracy: 0.5856 - val_precision: 0.5465 - val_recall: 0.4093\n",
            "Epoch 17/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6664 - accuracy: 0.5852 - precision: 0.5447 - recall: 0.4195 - val_loss: 0.6659 - val_accuracy: 0.5839 - val_precision: 0.5404 - val_recall: 0.4404\n",
            "Epoch 18/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6662 - accuracy: 0.5853 - precision: 0.5442 - recall: 0.4241 - val_loss: 0.6658 - val_accuracy: 0.5851 - val_precision: 0.5430 - val_recall: 0.4329\n",
            "Epoch 19/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6661 - accuracy: 0.5858 - precision: 0.5455 - recall: 0.4199 - val_loss: 0.6656 - val_accuracy: 0.5866 - val_precision: 0.5479 - val_recall: 0.4119\n",
            "Epoch 20/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6659 - accuracy: 0.5867 - precision: 0.5473 - recall: 0.4175 - val_loss: 0.6654 - val_accuracy: 0.5856 - val_precision: 0.5443 - val_recall: 0.4282\n",
            "Epoch 21/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6658 - accuracy: 0.5867 - precision: 0.5472 - recall: 0.4177 - val_loss: 0.6652 - val_accuracy: 0.5871 - val_precision: 0.5487 - val_recall: 0.4124\n",
            "Epoch 22/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6655 - accuracy: 0.5875 - precision: 0.5494 - recall: 0.4115 - val_loss: 0.6650 - val_accuracy: 0.5882 - val_precision: 0.5527 - val_recall: 0.3956\n",
            "Epoch 23/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6653 - accuracy: 0.5887 - precision: 0.5515 - recall: 0.4094 - val_loss: 0.6647 - val_accuracy: 0.5888 - val_precision: 0.5508 - val_recall: 0.4166\n",
            "Epoch 24/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6651 - accuracy: 0.5894 - precision: 0.5522 - recall: 0.4141 - val_loss: 0.6645 - val_accuracy: 0.5895 - val_precision: 0.5499 - val_recall: 0.4317\n",
            "Epoch 25/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6648 - accuracy: 0.5904 - precision: 0.5542 - recall: 0.4108 - val_loss: 0.6642 - val_accuracy: 0.5906 - val_precision: 0.5531 - val_recall: 0.4219\n",
            "Epoch 26/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6646 - accuracy: 0.5908 - precision: 0.5546 - recall: 0.4135 - val_loss: 0.6640 - val_accuracy: 0.5921 - val_precision: 0.5555 - val_recall: 0.4221\n",
            "Epoch 27/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6643 - accuracy: 0.5919 - precision: 0.5559 - recall: 0.4162 - val_loss: 0.6636 - val_accuracy: 0.5931 - val_precision: 0.5562 - val_recall: 0.4288\n",
            "Epoch 28/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6639 - accuracy: 0.5930 - precision: 0.5572 - recall: 0.4201 - val_loss: 0.6632 - val_accuracy: 0.5942 - val_precision: 0.5583 - val_recall: 0.4259\n",
            "Epoch 29/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6636 - accuracy: 0.5940 - precision: 0.5596 - recall: 0.4157 - val_loss: 0.6629 - val_accuracy: 0.5947 - val_precision: 0.5575 - val_recall: 0.4370\n",
            "Epoch 30/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6633 - accuracy: 0.5947 - precision: 0.5610 - recall: 0.4144 - val_loss: 0.6626 - val_accuracy: 0.5964 - val_precision: 0.5635 - val_recall: 0.4165\n",
            "Epoch 31/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6630 - accuracy: 0.5954 - precision: 0.5623 - recall: 0.4135 - val_loss: 0.6623 - val_accuracy: 0.5966 - val_precision: 0.5622 - val_recall: 0.4268\n",
            "Epoch 32/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6628 - accuracy: 0.5957 - precision: 0.5625 - recall: 0.4157 - val_loss: 0.6622 - val_accuracy: 0.5981 - val_precision: 0.5724 - val_recall: 0.3866\n",
            "Epoch 33/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6626 - accuracy: 0.5965 - precision: 0.5648 - recall: 0.4100 - val_loss: 0.6619 - val_accuracy: 0.5978 - val_precision: 0.5660 - val_recall: 0.4164\n",
            "Epoch 34/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6624 - accuracy: 0.5969 - precision: 0.5647 - recall: 0.4150 - val_loss: 0.6618 - val_accuracy: 0.5985 - val_precision: 0.5702 - val_recall: 0.4002\n",
            "Epoch 35/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6623 - accuracy: 0.5974 - precision: 0.5661 - recall: 0.4120 - val_loss: 0.6615 - val_accuracy: 0.5984 - val_precision: 0.5648 - val_recall: 0.4291\n",
            "Epoch 36/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6621 - accuracy: 0.5979 - precision: 0.5668 - recall: 0.4134 - val_loss: 0.6613 - val_accuracy: 0.5991 - val_precision: 0.5668 - val_recall: 0.4242\n",
            "Epoch 37/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6619 - accuracy: 0.5981 - precision: 0.5665 - recall: 0.4164 - val_loss: 0.6612 - val_accuracy: 0.6001 - val_precision: 0.5729 - val_recall: 0.4013\n",
            "Epoch 38/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6618 - accuracy: 0.5988 - precision: 0.5678 - recall: 0.4155 - val_loss: 0.6610 - val_accuracy: 0.5997 - val_precision: 0.5706 - val_recall: 0.4097\n",
            "Epoch 39/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6616 - accuracy: 0.5990 - precision: 0.5681 - recall: 0.4155 - val_loss: 0.6609 - val_accuracy: 0.6008 - val_precision: 0.5777 - val_recall: 0.3858\n",
            "Epoch 40/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6615 - accuracy: 0.5995 - precision: 0.5692 - recall: 0.4143 - val_loss: 0.6606 - val_accuracy: 0.6003 - val_precision: 0.5686 - val_recall: 0.4261\n",
            "Epoch 41/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6613 - accuracy: 0.5996 - precision: 0.5690 - recall: 0.4166 - val_loss: 0.6606 - val_accuracy: 0.6011 - val_precision: 0.5681 - val_recall: 0.4354\n",
            "Epoch 42/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6611 - accuracy: 0.6002 - precision: 0.5700 - recall: 0.4173 - val_loss: 0.6603 - val_accuracy: 0.6016 - val_precision: 0.5720 - val_recall: 0.4194\n",
            "Epoch 43/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6609 - accuracy: 0.6004 - precision: 0.5700 - recall: 0.4186 - val_loss: 0.6601 - val_accuracy: 0.6018 - val_precision: 0.5732 - val_recall: 0.4154\n",
            "Epoch 44/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6608 - accuracy: 0.6009 - precision: 0.5704 - recall: 0.4216 - val_loss: 0.6600 - val_accuracy: 0.6028 - val_precision: 0.5772 - val_recall: 0.4046\n",
            "Epoch 45/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6606 - accuracy: 0.6011 - precision: 0.5710 - recall: 0.4204 - val_loss: 0.6598 - val_accuracy: 0.6027 - val_precision: 0.5746 - val_recall: 0.4168\n",
            "Epoch 46/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6604 - accuracy: 0.6017 - precision: 0.5716 - recall: 0.4224 - val_loss: 0.6597 - val_accuracy: 0.6031 - val_precision: 0.5774 - val_recall: 0.4068\n",
            "Epoch 47/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6603 - accuracy: 0.6021 - precision: 0.5720 - recall: 0.4239 - val_loss: 0.6595 - val_accuracy: 0.6039 - val_precision: 0.5776 - val_recall: 0.4122\n",
            "Epoch 48/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6601 - accuracy: 0.6024 - precision: 0.5722 - recall: 0.4254 - val_loss: 0.6594 - val_accuracy: 0.6041 - val_precision: 0.5749 - val_recall: 0.4275\n",
            "Epoch 49/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6600 - accuracy: 0.6026 - precision: 0.5728 - recall: 0.4238 - val_loss: 0.6592 - val_accuracy: 0.6039 - val_precision: 0.5742 - val_recall: 0.4285\n",
            "Epoch 50/200\n",
            "468/468 [==============================] - 4s 9ms/step - loss: 0.6598 - accuracy: 0.6029 - precision: 0.5729 - recall: 0.4267 - val_loss: 0.6591 - val_accuracy: 0.6046 - val_precision: 0.5712 - val_recall: 0.4507\n",
            "Epoch 51/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6597 - accuracy: 0.6032 - precision: 0.5727 - recall: 0.4300 - val_loss: 0.6589 - val_accuracy: 0.6059 - val_precision: 0.5819 - val_recall: 0.4094\n",
            "Epoch 52/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6595 - accuracy: 0.6038 - precision: 0.5741 - recall: 0.4283 - val_loss: 0.6587 - val_accuracy: 0.6054 - val_precision: 0.5781 - val_recall: 0.4224\n",
            "Epoch 53/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6594 - accuracy: 0.6041 - precision: 0.5744 - recall: 0.4295 - val_loss: 0.6586 - val_accuracy: 0.6055 - val_precision: 0.5744 - val_recall: 0.4415\n",
            "Epoch 54/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6593 - accuracy: 0.6046 - precision: 0.5750 - recall: 0.4302 - val_loss: 0.6585 - val_accuracy: 0.6056 - val_precision: 0.5772 - val_recall: 0.4282\n",
            "Epoch 55/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6591 - accuracy: 0.6047 - precision: 0.5746 - recall: 0.4336 - val_loss: 0.6588 - val_accuracy: 0.6073 - val_precision: 0.5892 - val_recall: 0.3913\n",
            "Epoch 56/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6590 - accuracy: 0.6052 - precision: 0.5756 - recall: 0.4324 - val_loss: 0.6582 - val_accuracy: 0.6064 - val_precision: 0.5770 - val_recall: 0.4362\n",
            "Epoch 57/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6589 - accuracy: 0.6055 - precision: 0.5761 - recall: 0.4329 - val_loss: 0.6581 - val_accuracy: 0.6069 - val_precision: 0.5771 - val_recall: 0.4394\n",
            "Epoch 58/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6587 - accuracy: 0.6055 - precision: 0.5758 - recall: 0.4346 - val_loss: 0.6581 - val_accuracy: 0.6070 - val_precision: 0.5836 - val_recall: 0.4114\n",
            "Epoch 59/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6586 - accuracy: 0.6057 - precision: 0.5763 - recall: 0.4334 - val_loss: 0.6578 - val_accuracy: 0.6071 - val_precision: 0.5772 - val_recall: 0.4416\n",
            "Epoch 60/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6585 - accuracy: 0.6064 - precision: 0.5767 - recall: 0.4372 - val_loss: 0.6577 - val_accuracy: 0.6076 - val_precision: 0.5809 - val_recall: 0.4282\n",
            "Epoch 61/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6584 - accuracy: 0.6063 - precision: 0.5768 - recall: 0.4360 - val_loss: 0.6578 - val_accuracy: 0.6065 - val_precision: 0.5711 - val_recall: 0.4688\n",
            "Epoch 62/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6583 - accuracy: 0.6064 - precision: 0.5769 - recall: 0.4362 - val_loss: 0.6575 - val_accuracy: 0.6075 - val_precision: 0.5782 - val_recall: 0.4394\n",
            "Epoch 63/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6582 - accuracy: 0.6067 - precision: 0.5775 - recall: 0.4363 - val_loss: 0.6575 - val_accuracy: 0.6073 - val_precision: 0.5735 - val_recall: 0.4620\n",
            "Epoch 64/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6581 - accuracy: 0.6067 - precision: 0.5765 - recall: 0.4412 - val_loss: 0.6573 - val_accuracy: 0.6079 - val_precision: 0.5792 - val_recall: 0.4383\n",
            "Epoch 65/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6580 - accuracy: 0.6071 - precision: 0.5776 - recall: 0.4394 - val_loss: 0.6574 - val_accuracy: 0.6098 - val_precision: 0.5900 - val_recall: 0.4065\n",
            "Epoch 66/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6579 - accuracy: 0.6073 - precision: 0.5782 - recall: 0.4371 - val_loss: 0.6571 - val_accuracy: 0.6091 - val_precision: 0.5794 - val_recall: 0.4465\n",
            "Epoch 67/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6578 - accuracy: 0.6073 - precision: 0.5779 - recall: 0.4396 - val_loss: 0.6570 - val_accuracy: 0.6086 - val_precision: 0.5791 - val_recall: 0.4446\n",
            "Epoch 68/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6577 - accuracy: 0.6075 - precision: 0.5780 - recall: 0.4401 - val_loss: 0.6569 - val_accuracy: 0.6087 - val_precision: 0.5774 - val_recall: 0.4532\n",
            "Epoch 69/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6577 - accuracy: 0.6075 - precision: 0.5777 - recall: 0.4420 - val_loss: 0.6569 - val_accuracy: 0.6093 - val_precision: 0.5822 - val_recall: 0.4352\n",
            "Epoch 70/200\n",
            "468/468 [==============================] - 4s 9ms/step - loss: 0.6576 - accuracy: 0.6077 - precision: 0.5784 - recall: 0.4403 - val_loss: 0.6567 - val_accuracy: 0.6090 - val_precision: 0.5795 - val_recall: 0.4455\n",
            "Epoch 71/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6575 - accuracy: 0.6081 - precision: 0.5786 - recall: 0.4423 - val_loss: 0.6567 - val_accuracy: 0.6092 - val_precision: 0.5809 - val_recall: 0.4405\n",
            "Epoch 72/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6574 - accuracy: 0.6078 - precision: 0.5780 - recall: 0.4425 - val_loss: 0.6566 - val_accuracy: 0.6092 - val_precision: 0.5813 - val_recall: 0.4387\n",
            "Epoch 73/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6573 - accuracy: 0.6078 - precision: 0.5784 - recall: 0.4407 - val_loss: 0.6565 - val_accuracy: 0.6099 - val_precision: 0.5824 - val_recall: 0.4389\n",
            "Epoch 74/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6573 - accuracy: 0.6079 - precision: 0.5783 - recall: 0.4419 - val_loss: 0.6565 - val_accuracy: 0.6092 - val_precision: 0.5785 - val_recall: 0.4524\n",
            "Epoch 75/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6572 - accuracy: 0.6078 - precision: 0.5782 - recall: 0.4419 - val_loss: 0.6564 - val_accuracy: 0.6089 - val_precision: 0.5792 - val_recall: 0.4468\n",
            "Epoch 76/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6571 - accuracy: 0.6080 - precision: 0.5784 - recall: 0.4420 - val_loss: 0.6564 - val_accuracy: 0.6099 - val_precision: 0.5858 - val_recall: 0.4243\n",
            "Epoch 77/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6570 - accuracy: 0.6082 - precision: 0.5787 - recall: 0.4423 - val_loss: 0.6562 - val_accuracy: 0.6095 - val_precision: 0.5814 - val_recall: 0.4403\n",
            "Epoch 78/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6570 - accuracy: 0.6081 - precision: 0.5783 - recall: 0.4441 - val_loss: 0.6565 - val_accuracy: 0.6100 - val_precision: 0.5909 - val_recall: 0.4051\n",
            "Epoch 79/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6569 - accuracy: 0.6080 - precision: 0.5788 - recall: 0.4409 - val_loss: 0.6561 - val_accuracy: 0.6100 - val_precision: 0.5820 - val_recall: 0.4420\n",
            "Epoch 80/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6568 - accuracy: 0.6081 - precision: 0.5787 - recall: 0.4424 - val_loss: 0.6562 - val_accuracy: 0.6107 - val_precision: 0.5819 - val_recall: 0.4474\n",
            "Epoch 81/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6568 - accuracy: 0.6082 - precision: 0.5784 - recall: 0.4440 - val_loss: 0.6562 - val_accuracy: 0.6104 - val_precision: 0.5885 - val_recall: 0.4171\n",
            "Epoch 82/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6567 - accuracy: 0.6085 - precision: 0.5795 - recall: 0.4418 - val_loss: 0.6559 - val_accuracy: 0.6099 - val_precision: 0.5823 - val_recall: 0.4394\n",
            "Epoch 83/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6567 - accuracy: 0.6082 - precision: 0.5785 - recall: 0.4437 - val_loss: 0.6559 - val_accuracy: 0.6104 - val_precision: 0.5818 - val_recall: 0.4464\n",
            "Epoch 84/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6566 - accuracy: 0.6083 - precision: 0.5784 - recall: 0.4447 - val_loss: 0.6558 - val_accuracy: 0.6109 - val_precision: 0.5852 - val_recall: 0.4342\n",
            "Epoch 85/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6565 - accuracy: 0.6081 - precision: 0.5783 - recall: 0.4436 - val_loss: 0.6557 - val_accuracy: 0.6100 - val_precision: 0.5795 - val_recall: 0.4539\n",
            "Epoch 86/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6564 - accuracy: 0.6083 - precision: 0.5786 - recall: 0.4438 - val_loss: 0.6556 - val_accuracy: 0.6104 - val_precision: 0.5822 - val_recall: 0.4442\n",
            "Epoch 87/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6564 - accuracy: 0.6084 - precision: 0.5790 - recall: 0.4425 - val_loss: 0.6556 - val_accuracy: 0.6103 - val_precision: 0.5797 - val_recall: 0.4554\n",
            "Epoch 88/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6563 - accuracy: 0.6085 - precision: 0.5787 - recall: 0.4449 - val_loss: 0.6556 - val_accuracy: 0.6109 - val_precision: 0.5873 - val_recall: 0.4257\n",
            "Epoch 89/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6563 - accuracy: 0.6087 - precision: 0.5792 - recall: 0.4445 - val_loss: 0.6555 - val_accuracy: 0.6103 - val_precision: 0.5771 - val_recall: 0.4682\n",
            "Epoch 90/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6562 - accuracy: 0.6085 - precision: 0.5788 - recall: 0.4446 - val_loss: 0.6554 - val_accuracy: 0.6104 - val_precision: 0.5817 - val_recall: 0.4468\n",
            "Epoch 91/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6561 - accuracy: 0.6084 - precision: 0.5783 - recall: 0.4467 - val_loss: 0.6554 - val_accuracy: 0.6116 - val_precision: 0.5894 - val_recall: 0.4221\n",
            "Epoch 92/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6561 - accuracy: 0.6087 - precision: 0.5792 - recall: 0.4446 - val_loss: 0.6553 - val_accuracy: 0.6115 - val_precision: 0.5842 - val_recall: 0.4435\n",
            "Epoch 93/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6560 - accuracy: 0.6089 - precision: 0.5792 - recall: 0.4458 - val_loss: 0.6552 - val_accuracy: 0.6111 - val_precision: 0.5850 - val_recall: 0.4373\n",
            "Epoch 94/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6560 - accuracy: 0.6091 - precision: 0.5796 - recall: 0.4461 - val_loss: 0.6552 - val_accuracy: 0.6114 - val_precision: 0.5839 - val_recall: 0.4442\n",
            "Epoch 95/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6559 - accuracy: 0.6088 - precision: 0.5793 - recall: 0.4445 - val_loss: 0.6550 - val_accuracy: 0.6108 - val_precision: 0.5789 - val_recall: 0.4632\n",
            "Epoch 96/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6558 - accuracy: 0.6088 - precision: 0.5787 - recall: 0.4475 - val_loss: 0.6550 - val_accuracy: 0.6113 - val_precision: 0.5818 - val_recall: 0.4528\n",
            "Epoch 97/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6557 - accuracy: 0.6093 - precision: 0.5797 - recall: 0.4469 - val_loss: 0.6550 - val_accuracy: 0.6115 - val_precision: 0.5885 - val_recall: 0.4248\n",
            "Epoch 98/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6557 - accuracy: 0.6088 - precision: 0.5793 - recall: 0.4452 - val_loss: 0.6548 - val_accuracy: 0.6119 - val_precision: 0.5834 - val_recall: 0.4505\n",
            "Epoch 99/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6556 - accuracy: 0.6089 - precision: 0.5789 - recall: 0.4472 - val_loss: 0.6547 - val_accuracy: 0.6113 - val_precision: 0.5826 - val_recall: 0.4491\n",
            "Epoch 100/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6555 - accuracy: 0.6094 - precision: 0.5796 - recall: 0.4485 - val_loss: 0.6546 - val_accuracy: 0.6117 - val_precision: 0.5828 - val_recall: 0.4520\n",
            "Epoch 101/200\n",
            "468/468 [==============================] - 4s 9ms/step - loss: 0.6554 - accuracy: 0.6091 - precision: 0.5793 - recall: 0.4472 - val_loss: 0.6546 - val_accuracy: 0.6117 - val_precision: 0.5855 - val_recall: 0.4395\n",
            "Epoch 102/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6554 - accuracy: 0.6093 - precision: 0.5800 - recall: 0.4455 - val_loss: 0.6545 - val_accuracy: 0.6117 - val_precision: 0.5819 - val_recall: 0.4560\n",
            "Epoch 103/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6553 - accuracy: 0.6091 - precision: 0.5790 - recall: 0.4481 - val_loss: 0.6545 - val_accuracy: 0.6117 - val_precision: 0.5855 - val_recall: 0.4398\n",
            "Epoch 104/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6552 - accuracy: 0.6093 - precision: 0.5799 - recall: 0.4457 - val_loss: 0.6544 - val_accuracy: 0.6121 - val_precision: 0.5815 - val_recall: 0.4615\n",
            "Epoch 105/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6551 - accuracy: 0.6097 - precision: 0.5799 - recall: 0.4494 - val_loss: 0.6543 - val_accuracy: 0.6125 - val_precision: 0.5830 - val_recall: 0.4568\n",
            "Epoch 106/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6551 - accuracy: 0.6097 - precision: 0.5802 - recall: 0.4475 - val_loss: 0.6542 - val_accuracy: 0.6124 - val_precision: 0.5847 - val_recall: 0.4480\n",
            "Epoch 107/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6550 - accuracy: 0.6097 - precision: 0.5803 - recall: 0.4475 - val_loss: 0.6541 - val_accuracy: 0.6123 - val_precision: 0.5800 - val_recall: 0.4702\n",
            "Epoch 108/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6549 - accuracy: 0.6100 - precision: 0.5805 - recall: 0.4484 - val_loss: 0.6540 - val_accuracy: 0.6123 - val_precision: 0.5851 - val_recall: 0.4460\n",
            "Epoch 109/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6548 - accuracy: 0.6101 - precision: 0.5806 - recall: 0.4489 - val_loss: 0.6539 - val_accuracy: 0.6126 - val_precision: 0.5857 - val_recall: 0.4456\n",
            "Epoch 110/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6547 - accuracy: 0.6099 - precision: 0.5806 - recall: 0.4479 - val_loss: 0.6539 - val_accuracy: 0.6130 - val_precision: 0.5816 - val_recall: 0.4676\n",
            "Epoch 111/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6546 - accuracy: 0.6098 - precision: 0.5805 - recall: 0.4476 - val_loss: 0.6538 - val_accuracy: 0.6127 - val_precision: 0.5866 - val_recall: 0.4420\n",
            "Epoch 112/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6545 - accuracy: 0.6099 - precision: 0.5805 - recall: 0.4480 - val_loss: 0.6537 - val_accuracy: 0.6129 - val_precision: 0.5811 - val_recall: 0.4695\n",
            "Epoch 113/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6544 - accuracy: 0.6103 - precision: 0.5810 - recall: 0.4486 - val_loss: 0.6535 - val_accuracy: 0.6127 - val_precision: 0.5813 - val_recall: 0.4666\n",
            "Epoch 114/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6543 - accuracy: 0.6102 - precision: 0.5805 - recall: 0.4507 - val_loss: 0.6534 - val_accuracy: 0.6137 - val_precision: 0.5889 - val_recall: 0.4397\n",
            "Epoch 115/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6542 - accuracy: 0.6105 - precision: 0.5815 - recall: 0.4479 - val_loss: 0.6534 - val_accuracy: 0.6131 - val_precision: 0.5829 - val_recall: 0.4623\n",
            "Epoch 116/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6541 - accuracy: 0.6106 - precision: 0.5814 - recall: 0.4499 - val_loss: 0.6532 - val_accuracy: 0.6139 - val_precision: 0.5875 - val_recall: 0.4474\n",
            "Epoch 117/200\n",
            "468/468 [==============================] - 4s 10ms/step - loss: 0.6540 - accuracy: 0.6108 - precision: 0.5819 - recall: 0.4487 - val_loss: 0.6531 - val_accuracy: 0.6137 - val_precision: 0.5855 - val_recall: 0.4544\n",
            "Epoch 118/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6539 - accuracy: 0.6109 - precision: 0.5821 - recall: 0.4480 - val_loss: 0.6531 - val_accuracy: 0.6135 - val_precision: 0.5803 - val_recall: 0.4781\n",
            "Epoch 119/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6537 - accuracy: 0.6113 - precision: 0.5824 - recall: 0.4504 - val_loss: 0.6530 - val_accuracy: 0.6149 - val_precision: 0.5872 - val_recall: 0.4558\n",
            "Epoch 120/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6536 - accuracy: 0.6114 - precision: 0.5827 - recall: 0.4497 - val_loss: 0.6527 - val_accuracy: 0.6144 - val_precision: 0.5870 - val_recall: 0.4533\n",
            "Epoch 121/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6535 - accuracy: 0.6118 - precision: 0.5831 - recall: 0.4509 - val_loss: 0.6527 - val_accuracy: 0.6148 - val_precision: 0.5952 - val_recall: 0.4226\n",
            "Epoch 122/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6533 - accuracy: 0.6114 - precision: 0.5829 - recall: 0.4486 - val_loss: 0.6524 - val_accuracy: 0.6143 - val_precision: 0.5872 - val_recall: 0.4515\n",
            "Epoch 123/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6531 - accuracy: 0.6122 - precision: 0.5836 - recall: 0.4515 - val_loss: 0.6522 - val_accuracy: 0.6143 - val_precision: 0.5856 - val_recall: 0.4592\n",
            "Epoch 124/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6530 - accuracy: 0.6122 - precision: 0.5842 - recall: 0.4488 - val_loss: 0.6521 - val_accuracy: 0.6144 - val_precision: 0.5823 - val_recall: 0.4754\n",
            "Epoch 125/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6528 - accuracy: 0.6123 - precision: 0.5840 - recall: 0.4509 - val_loss: 0.6519 - val_accuracy: 0.6154 - val_precision: 0.5914 - val_recall: 0.4422\n",
            "Epoch 126/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6525 - accuracy: 0.6125 - precision: 0.5845 - recall: 0.4500 - val_loss: 0.6517 - val_accuracy: 0.6161 - val_precision: 0.5922 - val_recall: 0.4438\n",
            "Epoch 127/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6523 - accuracy: 0.6128 - precision: 0.5844 - recall: 0.4527 - val_loss: 0.6516 - val_accuracy: 0.6168 - val_precision: 0.6005 - val_recall: 0.4175\n",
            "Epoch 128/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6521 - accuracy: 0.6132 - precision: 0.5854 - recall: 0.4509 - val_loss: 0.6512 - val_accuracy: 0.6156 - val_precision: 0.5943 - val_recall: 0.4316\n",
            "Epoch 129/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6518 - accuracy: 0.6128 - precision: 0.5849 - recall: 0.4507 - val_loss: 0.6510 - val_accuracy: 0.6168 - val_precision: 0.5898 - val_recall: 0.4591\n",
            "Epoch 130/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6516 - accuracy: 0.6134 - precision: 0.5858 - recall: 0.4513 - val_loss: 0.6506 - val_accuracy: 0.6161 - val_precision: 0.5886 - val_recall: 0.4589\n",
            "Epoch 131/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6514 - accuracy: 0.6139 - precision: 0.5865 - recall: 0.4515 - val_loss: 0.6504 - val_accuracy: 0.6177 - val_precision: 0.5961 - val_recall: 0.4396\n",
            "Epoch 132/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6511 - accuracy: 0.6144 - precision: 0.5877 - recall: 0.4501 - val_loss: 0.6503 - val_accuracy: 0.6177 - val_precision: 0.5983 - val_recall: 0.4316\n",
            "Epoch 133/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6508 - accuracy: 0.6141 - precision: 0.5871 - recall: 0.4506 - val_loss: 0.6498 - val_accuracy: 0.6174 - val_precision: 0.5909 - val_recall: 0.4585\n",
            "Epoch 134/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6505 - accuracy: 0.6150 - precision: 0.5885 - recall: 0.4509 - val_loss: 0.6497 - val_accuracy: 0.6173 - val_precision: 0.5929 - val_recall: 0.4496\n",
            "Epoch 135/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6503 - accuracy: 0.6151 - precision: 0.5886 - recall: 0.4511 - val_loss: 0.6493 - val_accuracy: 0.6185 - val_precision: 0.5954 - val_recall: 0.4482\n",
            "Epoch 136/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6501 - accuracy: 0.6154 - precision: 0.5896 - recall: 0.4499 - val_loss: 0.6491 - val_accuracy: 0.6191 - val_precision: 0.5953 - val_recall: 0.4528\n",
            "Epoch 137/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6498 - accuracy: 0.6152 - precision: 0.5891 - recall: 0.4501 - val_loss: 0.6489 - val_accuracy: 0.6189 - val_precision: 0.5931 - val_recall: 0.4600\n",
            "Epoch 138/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6495 - accuracy: 0.6157 - precision: 0.5901 - recall: 0.4497 - val_loss: 0.6486 - val_accuracy: 0.6189 - val_precision: 0.5952 - val_recall: 0.4517\n",
            "Epoch 139/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6493 - accuracy: 0.6160 - precision: 0.5904 - recall: 0.4507 - val_loss: 0.6484 - val_accuracy: 0.6196 - val_precision: 0.5953 - val_recall: 0.4564\n",
            "Epoch 140/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6490 - accuracy: 0.6163 - precision: 0.5908 - recall: 0.4507 - val_loss: 0.6481 - val_accuracy: 0.6197 - val_precision: 0.5966 - val_recall: 0.4516\n",
            "Epoch 141/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6488 - accuracy: 0.6168 - precision: 0.5919 - recall: 0.4500 - val_loss: 0.6478 - val_accuracy: 0.6198 - val_precision: 0.5984 - val_recall: 0.4457\n",
            "Epoch 142/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6485 - accuracy: 0.6171 - precision: 0.5929 - recall: 0.4481 - val_loss: 0.6477 - val_accuracy: 0.6203 - val_precision: 0.5992 - val_recall: 0.4456\n",
            "Epoch 143/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6483 - accuracy: 0.6171 - precision: 0.5922 - recall: 0.4507 - val_loss: 0.6475 - val_accuracy: 0.6199 - val_precision: 0.5969 - val_recall: 0.4521\n",
            "Epoch 144/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6481 - accuracy: 0.6174 - precision: 0.5932 - recall: 0.4493 - val_loss: 0.6472 - val_accuracy: 0.6203 - val_precision: 0.6014 - val_recall: 0.4375\n",
            "Epoch 145/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6479 - accuracy: 0.6176 - precision: 0.5937 - recall: 0.4481 - val_loss: 0.6471 - val_accuracy: 0.6206 - val_precision: 0.5972 - val_recall: 0.4554\n",
            "Epoch 146/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6477 - accuracy: 0.6179 - precision: 0.5943 - recall: 0.4483 - val_loss: 0.6470 - val_accuracy: 0.6214 - val_precision: 0.6023 - val_recall: 0.4416\n",
            "Epoch 147/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6476 - accuracy: 0.6183 - precision: 0.5949 - recall: 0.4483 - val_loss: 0.6468 - val_accuracy: 0.6213 - val_precision: 0.6059 - val_recall: 0.4289\n",
            "Epoch 148/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6474 - accuracy: 0.6182 - precision: 0.5953 - recall: 0.4464 - val_loss: 0.6465 - val_accuracy: 0.6213 - val_precision: 0.5990 - val_recall: 0.4535\n",
            "Epoch 149/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6472 - accuracy: 0.6184 - precision: 0.5956 - recall: 0.4465 - val_loss: 0.6464 - val_accuracy: 0.6211 - val_precision: 0.5952 - val_recall: 0.4671\n",
            "Epoch 150/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6471 - accuracy: 0.6185 - precision: 0.5957 - recall: 0.4469 - val_loss: 0.6462 - val_accuracy: 0.6214 - val_precision: 0.6004 - val_recall: 0.4491\n",
            "Epoch 151/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6469 - accuracy: 0.6187 - precision: 0.5959 - recall: 0.4472 - val_loss: 0.6463 - val_accuracy: 0.6224 - val_precision: 0.6123 - val_recall: 0.4153\n",
            "Epoch 152/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6467 - accuracy: 0.6193 - precision: 0.5975 - recall: 0.4455 - val_loss: 0.6459 - val_accuracy: 0.6216 - val_precision: 0.6008 - val_recall: 0.4487\n",
            "Epoch 153/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6465 - accuracy: 0.6192 - precision: 0.5973 - recall: 0.4451 - val_loss: 0.6457 - val_accuracy: 0.6222 - val_precision: 0.6008 - val_recall: 0.4527\n",
            "Epoch 154/200\n",
            "468/468 [==============================] - 4s 9ms/step - loss: 0.6464 - accuracy: 0.6195 - precision: 0.5980 - recall: 0.4449 - val_loss: 0.6457 - val_accuracy: 0.6222 - val_precision: 0.5987 - val_recall: 0.4609\n",
            "Epoch 155/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6462 - accuracy: 0.6197 - precision: 0.5983 - recall: 0.4452 - val_loss: 0.6457 - val_accuracy: 0.6212 - val_precision: 0.5924 - val_recall: 0.4800\n",
            "Epoch 156/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6461 - accuracy: 0.6196 - precision: 0.5981 - recall: 0.4449 - val_loss: 0.6453 - val_accuracy: 0.6231 - val_precision: 0.6061 - val_recall: 0.4394\n",
            "Epoch 157/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6459 - accuracy: 0.6201 - precision: 0.5995 - recall: 0.4434 - val_loss: 0.6451 - val_accuracy: 0.6227 - val_precision: 0.6014 - val_recall: 0.4537\n",
            "Epoch 158/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6458 - accuracy: 0.6203 - precision: 0.5993 - recall: 0.4449 - val_loss: 0.6449 - val_accuracy: 0.6227 - val_precision: 0.6050 - val_recall: 0.4408\n",
            "Epoch 159/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6456 - accuracy: 0.6206 - precision: 0.6001 - recall: 0.4440 - val_loss: 0.6448 - val_accuracy: 0.6238 - val_precision: 0.6059 - val_recall: 0.4449\n",
            "Epoch 160/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6454 - accuracy: 0.6205 - precision: 0.5998 - recall: 0.4444 - val_loss: 0.6448 - val_accuracy: 0.6223 - val_precision: 0.5995 - val_recall: 0.4584\n",
            "Epoch 161/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6453 - accuracy: 0.6209 - precision: 0.6013 - recall: 0.4422 - val_loss: 0.6445 - val_accuracy: 0.6233 - val_precision: 0.6051 - val_recall: 0.4446\n",
            "Epoch 162/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6451 - accuracy: 0.6208 - precision: 0.6012 - recall: 0.4416 - val_loss: 0.6444 - val_accuracy: 0.6241 - val_precision: 0.6090 - val_recall: 0.4361\n",
            "Epoch 163/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6450 - accuracy: 0.6212 - precision: 0.6019 - recall: 0.4417 - val_loss: 0.6445 - val_accuracy: 0.6247 - val_precision: 0.6115 - val_recall: 0.4319\n",
            "Epoch 164/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6448 - accuracy: 0.6218 - precision: 0.6027 - recall: 0.4430 - val_loss: 0.6441 - val_accuracy: 0.6241 - val_precision: 0.6105 - val_recall: 0.4312\n",
            "Epoch 165/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6447 - accuracy: 0.6214 - precision: 0.6027 - recall: 0.4407 - val_loss: 0.6440 - val_accuracy: 0.6249 - val_precision: 0.6095 - val_recall: 0.4396\n",
            "Epoch 166/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6445 - accuracy: 0.6217 - precision: 0.6030 - recall: 0.4409 - val_loss: 0.6439 - val_accuracy: 0.6260 - val_precision: 0.6149 - val_recall: 0.4292\n",
            "Epoch 167/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6444 - accuracy: 0.6219 - precision: 0.6037 - recall: 0.4397 - val_loss: 0.6436 - val_accuracy: 0.6244 - val_precision: 0.6077 - val_recall: 0.4427\n",
            "Epoch 168/200\n",
            "468/468 [==============================] - 6s 12ms/step - loss: 0.6442 - accuracy: 0.6223 - precision: 0.6044 - recall: 0.4404 - val_loss: 0.6435 - val_accuracy: 0.6246 - val_precision: 0.6082 - val_recall: 0.4421\n",
            "Epoch 169/200\n",
            "468/468 [==============================] - 8s 16ms/step - loss: 0.6441 - accuracy: 0.6226 - precision: 0.6049 - recall: 0.4403 - val_loss: 0.6435 - val_accuracy: 0.6264 - val_precision: 0.6153 - val_recall: 0.4305\n",
            "Epoch 170/200\n",
            "468/468 [==============================] - 5s 11ms/step - loss: 0.6439 - accuracy: 0.6228 - precision: 0.6052 - recall: 0.4404 - val_loss: 0.6433 - val_accuracy: 0.6255 - val_precision: 0.6111 - val_recall: 0.4378\n",
            "Epoch 171/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6438 - accuracy: 0.6230 - precision: 0.6058 - recall: 0.4397 - val_loss: 0.6431 - val_accuracy: 0.6242 - val_precision: 0.6061 - val_recall: 0.4467\n",
            "Epoch 172/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6437 - accuracy: 0.6234 - precision: 0.6063 - recall: 0.4406 - val_loss: 0.6430 - val_accuracy: 0.6255 - val_precision: 0.6127 - val_recall: 0.4332\n",
            "Epoch 173/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6435 - accuracy: 0.6233 - precision: 0.6066 - recall: 0.4389 - val_loss: 0.6432 - val_accuracy: 0.6262 - val_precision: 0.6111 - val_recall: 0.4423\n",
            "Epoch 174/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6434 - accuracy: 0.6238 - precision: 0.6072 - recall: 0.4400 - val_loss: 0.6427 - val_accuracy: 0.6263 - val_precision: 0.6114 - val_recall: 0.4418\n",
            "Epoch 175/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6433 - accuracy: 0.6241 - precision: 0.6075 - recall: 0.4409 - val_loss: 0.6427 - val_accuracy: 0.6247 - val_precision: 0.6045 - val_recall: 0.4554\n",
            "Epoch 176/200\n",
            "468/468 [==============================] - 4s 9ms/step - loss: 0.6432 - accuracy: 0.6240 - precision: 0.6077 - recall: 0.4399 - val_loss: 0.6428 - val_accuracy: 0.6274 - val_precision: 0.6166 - val_recall: 0.4327\n",
            "Epoch 177/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6431 - accuracy: 0.6242 - precision: 0.6079 - recall: 0.4405 - val_loss: 0.6425 - val_accuracy: 0.6265 - val_precision: 0.6167 - val_recall: 0.4266\n",
            "Epoch 178/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6430 - accuracy: 0.6244 - precision: 0.6084 - recall: 0.4401 - val_loss: 0.6423 - val_accuracy: 0.6266 - val_precision: 0.6117 - val_recall: 0.4431\n",
            "Epoch 179/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6428 - accuracy: 0.6251 - precision: 0.6097 - recall: 0.4400 - val_loss: 0.6422 - val_accuracy: 0.6261 - val_precision: 0.6095 - val_recall: 0.4473\n",
            "Epoch 180/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6427 - accuracy: 0.6251 - precision: 0.6098 - recall: 0.4401 - val_loss: 0.6421 - val_accuracy: 0.6263 - val_precision: 0.6086 - val_recall: 0.4513\n",
            "Epoch 181/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6426 - accuracy: 0.6254 - precision: 0.6101 - recall: 0.4403 - val_loss: 0.6419 - val_accuracy: 0.6268 - val_precision: 0.6138 - val_recall: 0.4374\n",
            "Epoch 182/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6425 - accuracy: 0.6253 - precision: 0.6104 - recall: 0.4392 - val_loss: 0.6420 - val_accuracy: 0.6260 - val_precision: 0.6044 - val_recall: 0.4646\n",
            "Epoch 183/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6424 - accuracy: 0.6255 - precision: 0.6100 - recall: 0.4416 - val_loss: 0.6418 - val_accuracy: 0.6284 - val_precision: 0.6180 - val_recall: 0.4344\n",
            "Epoch 184/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6422 - accuracy: 0.6258 - precision: 0.6116 - recall: 0.4386 - val_loss: 0.6417 - val_accuracy: 0.6268 - val_precision: 0.6078 - val_recall: 0.4575\n",
            "Epoch 185/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6422 - accuracy: 0.6260 - precision: 0.6110 - recall: 0.4411 - val_loss: 0.6417 - val_accuracy: 0.6283 - val_precision: 0.6159 - val_recall: 0.4400\n",
            "Epoch 186/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6421 - accuracy: 0.6259 - precision: 0.6115 - recall: 0.4391 - val_loss: 0.6416 - val_accuracy: 0.6285 - val_precision: 0.6158 - val_recall: 0.4416\n",
            "Epoch 187/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6419 - accuracy: 0.6267 - precision: 0.6129 - recall: 0.4393 - val_loss: 0.6414 - val_accuracy: 0.6272 - val_precision: 0.6105 - val_recall: 0.4506\n",
            "Epoch 188/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6419 - accuracy: 0.6263 - precision: 0.6119 - recall: 0.4403 - val_loss: 0.6414 - val_accuracy: 0.6289 - val_precision: 0.6196 - val_recall: 0.4324\n",
            "Epoch 189/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6418 - accuracy: 0.6269 - precision: 0.6126 - recall: 0.4414 - val_loss: 0.6413 - val_accuracy: 0.6270 - val_precision: 0.6110 - val_recall: 0.4473\n",
            "Epoch 190/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6417 - accuracy: 0.6267 - precision: 0.6131 - recall: 0.4392 - val_loss: 0.6412 - val_accuracy: 0.6292 - val_precision: 0.6172 - val_recall: 0.4415\n",
            "Epoch 191/200\n",
            "468/468 [==============================] - 5s 10ms/step - loss: 0.6415 - accuracy: 0.6275 - precision: 0.6140 - recall: 0.4413 - val_loss: 0.6410 - val_accuracy: 0.6279 - val_precision: 0.6145 - val_recall: 0.4418\n",
            "Epoch 192/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6414 - accuracy: 0.6276 - precision: 0.6140 - recall: 0.4415 - val_loss: 0.6409 - val_accuracy: 0.6289 - val_precision: 0.6150 - val_recall: 0.4465\n",
            "Epoch 193/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6413 - accuracy: 0.6276 - precision: 0.6137 - recall: 0.4427 - val_loss: 0.6408 - val_accuracy: 0.6297 - val_precision: 0.6209 - val_recall: 0.4334\n",
            "Epoch 194/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6411 - accuracy: 0.6281 - precision: 0.6145 - recall: 0.4431 - val_loss: 0.6406 - val_accuracy: 0.6291 - val_precision: 0.6145 - val_recall: 0.4492\n",
            "Epoch 195/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6410 - accuracy: 0.6284 - precision: 0.6147 - recall: 0.4441 - val_loss: 0.6404 - val_accuracy: 0.6292 - val_precision: 0.6184 - val_recall: 0.4374\n",
            "Epoch 196/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6407 - accuracy: 0.6279 - precision: 0.6142 - recall: 0.4430 - val_loss: 0.6403 - val_accuracy: 0.6303 - val_precision: 0.6203 - val_recall: 0.4385\n",
            "Epoch 197/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6405 - accuracy: 0.6284 - precision: 0.6146 - recall: 0.4443 - val_loss: 0.6399 - val_accuracy: 0.6296 - val_precision: 0.6191 - val_recall: 0.4378\n",
            "Epoch 198/200\n",
            "468/468 [==============================] - 3s 7ms/step - loss: 0.6403 - accuracy: 0.6284 - precision: 0.6150 - recall: 0.4429 - val_loss: 0.6398 - val_accuracy: 0.6302 - val_precision: 0.6198 - val_recall: 0.4395\n",
            "Epoch 199/200\n",
            "468/468 [==============================] - 4s 8ms/step - loss: 0.6401 - accuracy: 0.6282 - precision: 0.6144 - recall: 0.4442 - val_loss: 0.6398 - val_accuracy: 0.6304 - val_precision: 0.6288 - val_recall: 0.4157\n",
            "Epoch 200/200\n",
            "468/468 [==============================] - 3s 6ms/step - loss: 0.6399 - accuracy: 0.6289 - precision: 0.6159 - recall: 0.4435 - val_loss: 0.6394 - val_accuracy: 0.6296 - val_precision: 0.6159 - val_recall: 0.4474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/base_tuner.py\", line 266, in _try_run_and_update_trial\n",
            "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/base_tuner.py\", line 257, in _run_and_update_trial\n",
            "    tuner_utils.convert_to_metrics_dict(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/tuner_utils.py\", line 270, in convert_to_metrics_dict\n",
            "    [convert_to_metrics_dict(elem, objective) for elem in results]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/tuner_utils.py\", line 270, in <listcomp>\n",
            "    [convert_to_metrics_dict(elem, objective) for elem in results]\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/tuner_utils.py\", line 283, in convert_to_metrics_dict\n",
            "    best_value, _ = _get_best_value_and_best_epoch_from_history(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/tuner_utils.py\", line 254, in _get_best_value_and_best_epoch_from_history\n",
            "    objective_value = objective.get_value(metrics)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/objective.py\", line 57, in get_value\n",
            "    return logs[self.name]\n",
            "KeyError: 'Precision'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-e0353cac1dcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Search for the best hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m750\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Print the best hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36mon_trial_end\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTrial\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \"\"\"\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         \u001b[0;31m# Display needs the updated trial scored by the Oracle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_display\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/oracle.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mLOCKS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mTHREADS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mthread_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mret_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mneed_acquire\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mTHREADS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/oracle.py\u001b[0m in \u001b[0;36mend_trial\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_order\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_consecutive_failures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/oracle.py\u001b[0m in \u001b[0;36m_check_consecutive_failures\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    385\u001b[0m                 \u001b[0mconsecutive_failures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconsecutive_failures\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_consecutive_failed_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m                 raise RuntimeError(\n\u001b[0m\u001b[1;32m    388\u001b[0m                     \u001b[0;34m\"Number of consecutive failures excceeded the limit \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \u001b[0;34mf\"of {self.max_consecutive_failed_trials}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Number of consecutive failures excceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/base_tuner.py\", line 266, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/base_tuner.py\", line 257, in _run_and_update_trial\n    tuner_utils.convert_to_metrics_dict(\n  File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/tuner_utils.py\", line 270, in convert_to_metrics_dict\n    [convert_to_metrics_dict(elem, objective) for elem in results]\n  File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/tuner_utils.py\", line 270, in <listcomp>\n    [convert_to_metrics_dict(elem, objective) for elem in results]\n  File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/tuner_utils.py\", line 283, in convert_to_metrics_dict\n    best_value, _ = _get_best_value_and_best_epoch_from_history(\n  File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/tuner_utils.py\", line 254, in _get_best_value_and_best_epoch_from_history\n    objective_value = objective.get_value(metrics)\n  File \"/usr/local/lib/python3.8/dist-packages/keras_tuner/engine/objective.py\", line 57, in get_value\n    return logs[self.name]\nKeyError: 'Precision'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model = tf.keras.Sequential([\n",
        "    #tf.keras.layers.Dense(320, activation='relu', input_shape = (6,), bias_initializer = 'random_normal', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    #tf.keras.layers.Dense(10, activation='relu', bias_initializer='random_normal', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    #tf.keras.layers.Dense(1, activation='sigmoid', bias_initializer='random_normal')\n",
        "#])"
      ],
      "metadata": {
        "id": "eaIwPT5jo13g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model with binary cross-entropy loss and Adam optimizer, and add precision, recall score to the metrics\n",
        "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', Precision(), Recall()])\n",
        "#model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.01), metrics=['accuracy', Precision(), Recall()])\n",
        "#early_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10)\n",
        "\n",
        "\n",
        "# train the model using the training set\n",
        "#history = model.fit(train_df_x, train_df_y, epochs=100, batch_size=750, validation_data=(test_df_x, test_df_y))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "#test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_df_x, test_df_y, verbose=0)\n",
        "\n",
        "# Print the results\n",
        "#print('Test Loss:', test_loss)\n",
        "#print('Test Accuracy:', test_accuracy)\n",
        "#print('Test Precision:', test_precision)\n",
        "#print('Test Recall:', test_recall)"
      ],
      "metadata": {
        "id": "lEwy6Rkb6Hhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict classes for the test set\n",
        "#y_pred_prob = model.predict(test_df_x)\n",
        "#y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# generate confusion matrix\n",
        "#cm = confusion_matrix(test_df_y, y_pred, labels=[0,1])\n",
        "\n",
        "#sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
        "\n",
        "#plt.xlabel('Predicted label')\n",
        "#plt.ylabel('True label')\n",
        "\n",
        "# print confusion matrix\n",
        "#print('Confusion Matrix: ')\n",
        "#print(cm)\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "PWsK5QOaNAjv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}