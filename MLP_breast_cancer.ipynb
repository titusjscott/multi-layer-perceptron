{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1VUtjuH074KJ5Ubwup8wI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/titusjscott/multi-layer-perceptron/blob/main/MLP_breast_cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G59fc8wGnSKw"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelBinarizer, MinMaxScaler, Normalizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/titusjscott/multi-layer-perceptron/main/breastcancerdata.csv\")\n"
      ],
      "metadata": {
        "id": "Tlj6-calpT7r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DaRq3pMpvwo",
        "outputId": "5b9a3aec-d9ef-4af2-f23e-b451b1043a32"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 33)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "dca06hvrqBYe",
        "outputId": "c2fda05c-a832-4481-bcc7-bff27e2cbad1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
              "0  ...          17.33           184.60      2019.0            0.1622   \n",
              "1  ...          23.41           158.80      1956.0            0.1238   \n",
              "2  ...          25.53           152.50      1709.0            0.1444   \n",
              "3  ...          26.50            98.87       567.7            0.2098   \n",
              "4  ...          16.67           152.20      1575.0            0.1374   \n",
              "\n",
              "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
              "0             0.6656           0.7119                0.2654          0.4601   \n",
              "1             0.1866           0.2416                0.1860          0.2750   \n",
              "2             0.4245           0.4504                0.2430          0.3613   \n",
              "3             0.8663           0.6869                0.2575          0.6638   \n",
              "4             0.2050           0.4000                0.1625          0.2364   \n",
              "\n",
              "   fractal_dimension_worst  Unnamed: 32  \n",
              "0                  0.11890          NaN  \n",
              "1                  0.08902          NaN  \n",
              "2                  0.08758          NaN  \n",
              "3                  0.17300          NaN  \n",
              "4                  0.07678          NaN  \n",
              "\n",
              "[5 rows x 33 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a544ca4-628d-4cb9-8879-f3cfcffbf0f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 33 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a544ca4-628d-4cb9-8879-f3cfcffbf0f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8a544ca4-628d-4cb9-8879-f3cfcffbf0f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8a544ca4-628d-4cb9-8879-f3cfcffbf0f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.iloc[:,:-1]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "C2D79fJaq2aK",
        "outputId": "c739960e-06a1-423d-cd02-1bce9f3836ef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
              "0    842302         M        17.99         10.38          122.80     1001.0   \n",
              "1    842517         M        20.57         17.77          132.90     1326.0   \n",
              "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
              "3  84348301         M        11.42         20.38           77.58      386.1   \n",
              "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
              "\n",
              "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
              "0          0.11840           0.27760          0.3001              0.14710   \n",
              "1          0.08474           0.07864          0.0869              0.07017   \n",
              "2          0.10960           0.15990          0.1974              0.12790   \n",
              "3          0.14250           0.28390          0.2414              0.10520   \n",
              "4          0.10030           0.13280          0.1980              0.10430   \n",
              "\n",
              "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
              "0  ...         25.38          17.33           184.60      2019.0   \n",
              "1  ...         24.99          23.41           158.80      1956.0   \n",
              "2  ...         23.57          25.53           152.50      1709.0   \n",
              "3  ...         14.91          26.50            98.87       567.7   \n",
              "4  ...         22.54          16.67           152.20      1575.0   \n",
              "\n",
              "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
              "0            0.1622             0.6656           0.7119                0.2654   \n",
              "1            0.1238             0.1866           0.2416                0.1860   \n",
              "2            0.1444             0.4245           0.4504                0.2430   \n",
              "3            0.2098             0.8663           0.6869                0.2575   \n",
              "4            0.1374             0.2050           0.4000                0.1625   \n",
              "\n",
              "   symmetry_worst  fractal_dimension_worst  \n",
              "0          0.4601                  0.11890  \n",
              "1          0.2750                  0.08902  \n",
              "2          0.3613                  0.08758  \n",
              "3          0.6638                  0.17300  \n",
              "4          0.2364                  0.07678  \n",
              "\n",
              "[5 rows x 32 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eafe1816-a925-44bd-af26-ae1dc785c09f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>...</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>...</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>...</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>...</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 32 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eafe1816-a925-44bd-af26-ae1dc785c09f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eafe1816-a925-44bd-af26-ae1dc785c09f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eafe1816-a925-44bd-af26-ae1dc785c09f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(df['diagnosis'], label = \"Count\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "lwXLFJm2HbG0",
        "outputId": "2d6fc494-b244-4d21-b96a-de36f0c50c9a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='diagnosis', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df, test_size=0.35, random_state = 38)\n",
        "print(\"Training Data :\", train.shape)\n",
        "print(\"Testing Data :\", test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8HzKrBjJZXf",
        "outputId": "421e0b4c-f19e-4714-f52c-727452d16330"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data : (369, 32)\n",
            "Testing Data : (200, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_id = train['id']\n",
        "test_id = test['id']\n",
        "\n",
        "train_df = train.iloc[:,1:]\n",
        "test_df = test.iloc[:,1:]\n",
        "\n",
        "print(\"Training Data :\", train_df.shape)\n",
        "print(\"Testing Data :\", test_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBG0p6uEJ6u2",
        "outputId": "c89848d9-ae56-4cb9-8827-a5dd34b46a81"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data : (369, 31)\n",
            "Testing Data : (200, 31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_x = train_df.iloc[:,1:]\n",
        "train_df_x = MinMaxScaler().fit_transform(train_df_x)\n",
        "\n",
        "test_df_x = test_df.iloc[:,1:]\n",
        "test_df_x = MinMaxScaler().fit_transform(test_df_x)\n",
        "\n",
        "print(train_df_x.shape)\n",
        "print(test_df_x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVPBOp93wIOZ",
        "outputId": "aa0cb776-0bc9-4b92-89ca-85b593c704ea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(369, 30)\n",
            "(200, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_y = train_df.iloc[:,:1]\n",
        "train_df_y[train_df_y=='M'] = 0\n",
        "train_df_y[train_df_y=='B'] = 1\n",
        "train_df_y = train_df_y.astype('float32')\n",
        "\n",
        "\n",
        "test_df_y = test_df.iloc[:,:1]\n",
        "test_df_y[test_df_y=='M'] = 0\n",
        "test_df_y[test_df_y=='B'] = 1\n",
        "test_df_y = test_df_y.astype('float32')\n",
        "\n",
        "print(train_df_y.shape)\n",
        "print(test_df_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qlho0sCw5qf",
        "outputId": "84d8703f-16a5-451f-d25c-4a19ed7a3137"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(369, 1)\n",
            "(200, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(15, activation='relu', input_shape=(30,), bias_initializer='random_normal', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(3, activation='relu', bias_initializer='random_normal', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid', bias_initializer='random_normal')\n",
        "])"
      ],
      "metadata": {
        "id": "lQmCKuA1zT2J"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.metrics import Precision, Recall\n",
        "\n",
        "# compile the model with binary cross-entropy loss and Adam optimizer, and add precision, recall, and F1 score to the metrics\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', Precision(), Recall()])\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 10)\n",
        "\n",
        "\n",
        "# train the model using the training set\n",
        "history = model.fit(train_df_x, train_df_y, epochs=100, batch_size=32, validation_data=(test_df_x, test_df_y))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_df_x, test_df_y, verbose=0)\n",
        "\n",
        "# Print the results\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_accuracy)\n",
        "print('Test Precision:', test_precision)\n",
        "print('Test Recall:', test_recall)\n"
      ],
      "metadata": {
        "id": "cMllJ3PL90S7",
        "outputId": "d6da6a92-8264-4e11-f8af-1d13716c04b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 4s 74ms/step - loss: 0.7157 - accuracy: 0.5068 - precision: 0.6984 - recall: 0.3793 - val_loss: 0.7059 - val_accuracy: 0.6300 - val_precision: 0.6364 - val_recall: 0.9520\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.7045 - accuracy: 0.6531 - precision: 0.6940 - recall: 0.8017 - val_loss: 0.6930 - val_accuracy: 0.6300 - val_precision: 0.6294 - val_recall: 0.9920\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.6871 - accuracy: 0.7263 - precision: 0.7191 - recall: 0.9267 - val_loss: 0.6799 - val_accuracy: 0.6300 - val_precision: 0.6294 - val_recall: 0.9920\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.6745 - accuracy: 0.7317 - precision: 0.7098 - recall: 0.9698 - val_loss: 0.6699 - val_accuracy: 0.6350 - val_precision: 0.6313 - val_recall: 1.0000\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.6582 - accuracy: 0.6856 - precision: 0.6667 - recall: 1.0000 - val_loss: 0.6556 - val_accuracy: 0.6450 - val_precision: 0.6378 - val_recall: 1.0000\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6491 - accuracy: 0.6423 - precision: 0.6374 - recall: 1.0000 - val_loss: 0.6398 - val_accuracy: 0.6250 - val_precision: 0.6250 - val_recall: 1.0000\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.6364 - accuracy: 0.6287 - precision: 0.6287 - recall: 1.0000 - val_loss: 0.6299 - val_accuracy: 0.6250 - val_precision: 0.6250 - val_recall: 1.0000\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.6215 - accuracy: 0.6287 - precision: 0.6287 - recall: 1.0000 - val_loss: 0.6157 - val_accuracy: 0.6250 - val_precision: 0.6250 - val_recall: 1.0000\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.6108 - accuracy: 0.6287 - precision: 0.6287 - recall: 1.0000 - val_loss: 0.6005 - val_accuracy: 0.6250 - val_precision: 0.6250 - val_recall: 1.0000\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5970 - accuracy: 0.6287 - precision: 0.6287 - recall: 1.0000 - val_loss: 0.5877 - val_accuracy: 0.6250 - val_precision: 0.6250 - val_recall: 1.0000\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5852 - accuracy: 0.6287 - precision: 0.6287 - recall: 1.0000 - val_loss: 0.5747 - val_accuracy: 0.6250 - val_precision: 0.6250 - val_recall: 1.0000\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.5730 - accuracy: 0.6287 - precision: 0.6287 - recall: 1.0000 - val_loss: 0.5618 - val_accuracy: 0.6250 - val_precision: 0.6250 - val_recall: 1.0000\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5599 - accuracy: 0.6287 - precision: 0.6287 - recall: 1.0000 - val_loss: 0.5491 - val_accuracy: 0.6250 - val_precision: 0.6250 - val_recall: 1.0000\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.5441 - accuracy: 0.6287 - precision: 0.6287 - recall: 1.0000 - val_loss: 0.5413 - val_accuracy: 0.6250 - val_precision: 0.6250 - val_recall: 1.0000\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.5315 - accuracy: 0.6287 - precision: 0.6287 - recall: 1.0000 - val_loss: 0.5258 - val_accuracy: 0.6250 - val_precision: 0.6250 - val_recall: 1.0000\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.5222 - accuracy: 0.6287 - precision: 0.6287 - recall: 1.0000 - val_loss: 0.5139 - val_accuracy: 0.6250 - val_precision: 0.6250 - val_recall: 1.0000\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.5151 - accuracy: 0.6287 - precision: 0.6287 - recall: 1.0000 - val_loss: 0.5032 - val_accuracy: 0.6250 - val_precision: 0.6250 - val_recall: 1.0000\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.5001 - accuracy: 0.6287 - precision: 0.6287 - recall: 1.0000 - val_loss: 0.4933 - val_accuracy: 0.6250 - val_precision: 0.6250 - val_recall: 1.0000\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.4973 - accuracy: 0.7724 - precision: 0.7342 - recall: 1.0000 - val_loss: 0.4845 - val_accuracy: 0.8500 - val_precision: 0.8105 - val_recall: 0.9920\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 0.4895 - accuracy: 0.8293 - precision: 0.7884 - recall: 0.9957 - val_loss: 0.4773 - val_accuracy: 0.8750 - val_precision: 0.8378 - val_recall: 0.9920\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4717 - accuracy: 0.8509 - precision: 0.8084 - recall: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.8650 - val_precision: 0.8267 - val_recall: 0.9920\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.4676 - accuracy: 0.8509 - precision: 0.8105 - recall: 0.9957 - val_loss: 0.4627 - val_accuracy: 0.8950 - val_precision: 0.8611 - val_recall: 0.9920\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.4593 - accuracy: 0.8564 - precision: 0.8140 - recall: 1.0000 - val_loss: 0.4556 - val_accuracy: 0.8950 - val_precision: 0.8611 - val_recall: 0.9920\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.4540 - accuracy: 0.8645 - precision: 0.8227 - recall: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.9000 - val_precision: 0.8671 - val_recall: 0.9920\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.4494 - accuracy: 0.8753 - precision: 0.8345 - recall: 1.0000 - val_loss: 0.4440 - val_accuracy: 0.9000 - val_precision: 0.8671 - val_recall: 0.9920\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.4354 - accuracy: 0.8943 - precision: 0.8614 - recall: 0.9914 - val_loss: 0.4390 - val_accuracy: 0.9000 - val_precision: 0.8723 - val_recall: 0.9840\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.4407 - accuracy: 0.8726 - precision: 0.8413 - recall: 0.9828 - val_loss: 0.4320 - val_accuracy: 0.9000 - val_precision: 0.8671 - val_recall: 0.9920\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.4305 - accuracy: 0.8862 - precision: 0.8519 - recall: 0.9914 - val_loss: 0.4283 - val_accuracy: 0.9050 - val_precision: 0.8786 - val_recall: 0.9840\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.4188 - accuracy: 0.8889 - precision: 0.8577 - recall: 0.9871 - val_loss: 0.4218 - val_accuracy: 0.9000 - val_precision: 0.8723 - val_recall: 0.9840\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.4108 - accuracy: 0.9051 - precision: 0.8774 - recall: 0.9871 - val_loss: 0.4172 - val_accuracy: 0.9000 - val_precision: 0.8723 - val_recall: 0.9840\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.4082 - accuracy: 0.8889 - precision: 0.8577 - recall: 0.9871 - val_loss: 0.4134 - val_accuracy: 0.9100 - val_precision: 0.8849 - val_recall: 0.9840\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.4024 - accuracy: 0.9024 - precision: 0.8712 - recall: 0.9914 - val_loss: 0.4083 - val_accuracy: 0.9150 - val_precision: 0.8913 - val_recall: 0.9840\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.3957 - accuracy: 0.9024 - precision: 0.8769 - recall: 0.9828 - val_loss: 0.4039 - val_accuracy: 0.9150 - val_precision: 0.8913 - val_recall: 0.9840\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 0.3938 - accuracy: 0.8997 - precision: 0.8736 - recall: 0.9828 - val_loss: 0.4012 - val_accuracy: 0.9250 - val_precision: 0.9044 - val_recall: 0.9840\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.3860 - accuracy: 0.9187 - precision: 0.8945 - recall: 0.9871 - val_loss: 0.3979 - val_accuracy: 0.9300 - val_precision: 0.9111 - val_recall: 0.9840\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.3800 - accuracy: 0.9187 - precision: 0.8945 - recall: 0.9871 - val_loss: 0.3912 - val_accuracy: 0.9250 - val_precision: 0.9044 - val_recall: 0.9840\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.3794 - accuracy: 0.9160 - precision: 0.8851 - recall: 0.9957 - val_loss: 0.3875 - val_accuracy: 0.9250 - val_precision: 0.9044 - val_recall: 0.9840\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.3743 - accuracy: 0.9133 - precision: 0.8906 - recall: 0.9828 - val_loss: 0.3835 - val_accuracy: 0.9300 - val_precision: 0.9051 - val_recall: 0.9920\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.3722 - accuracy: 0.9133 - precision: 0.8846 - recall: 0.9914 - val_loss: 0.3829 - val_accuracy: 0.9350 - val_precision: 0.9179 - val_recall: 0.9840\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.3608 - accuracy: 0.9322 - precision: 0.9124 - recall: 0.9871 - val_loss: 0.3783 - val_accuracy: 0.9300 - val_precision: 0.9111 - val_recall: 0.9840\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3652 - accuracy: 0.9241 - precision: 0.8953 - recall: 0.9957 - val_loss: 0.3757 - val_accuracy: 0.9400 - val_precision: 0.9248 - val_recall: 0.9840\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.3576 - accuracy: 0.9214 - precision: 0.9012 - recall: 0.9828 - val_loss: 0.3717 - val_accuracy: 0.9400 - val_precision: 0.9248 - val_recall: 0.9840\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.3547 - accuracy: 0.9322 - precision: 0.9091 - recall: 0.9914 - val_loss: 0.3694 - val_accuracy: 0.9400 - val_precision: 0.9248 - val_recall: 0.9840\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.3554 - accuracy: 0.9322 - precision: 0.9091 - recall: 0.9914 - val_loss: 0.3684 - val_accuracy: 0.9350 - val_precision: 0.9242 - val_recall: 0.9760\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.3429 - accuracy: 0.9268 - precision: 0.9051 - recall: 0.9871 - val_loss: 0.3623 - val_accuracy: 0.9450 - val_precision: 0.9254 - val_recall: 0.9920\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.3356 - accuracy: 0.9322 - precision: 0.9091 - recall: 0.9914 - val_loss: 0.3590 - val_accuracy: 0.9450 - val_precision: 0.9254 - val_recall: 0.9920\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.3353 - accuracy: 0.9350 - precision: 0.9094 - recall: 0.9957 - val_loss: 0.3570 - val_accuracy: 0.9450 - val_precision: 0.9254 - val_recall: 0.9920\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.3274 - accuracy: 0.9377 - precision: 0.9098 - recall: 1.0000 - val_loss: 0.3538 - val_accuracy: 0.9450 - val_precision: 0.9254 - val_recall: 0.9920\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.3283 - accuracy: 0.9404 - precision: 0.9268 - recall: 0.9828 - val_loss: 0.3514 - val_accuracy: 0.9400 - val_precision: 0.9248 - val_recall: 0.9840\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3244 - accuracy: 0.9350 - precision: 0.9160 - recall: 0.9871 - val_loss: 0.3470 - val_accuracy: 0.9450 - val_precision: 0.9254 - val_recall: 0.9920\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.3245 - accuracy: 0.9322 - precision: 0.9124 - recall: 0.9871 - val_loss: 0.3450 - val_accuracy: 0.9400 - val_precision: 0.9248 - val_recall: 0.9840\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.3220 - accuracy: 0.9350 - precision: 0.9160 - recall: 0.9871 - val_loss: 0.3430 - val_accuracy: 0.9400 - val_precision: 0.9248 - val_recall: 0.9840\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.3173 - accuracy: 0.9458 - precision: 0.9240 - recall: 0.9957 - val_loss: 0.3415 - val_accuracy: 0.9350 - val_precision: 0.9242 - val_recall: 0.9760\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.3148 - accuracy: 0.9458 - precision: 0.9274 - recall: 0.9914 - val_loss: 0.3382 - val_accuracy: 0.9400 - val_precision: 0.9248 - val_recall: 0.9840\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.3033 - accuracy: 0.9458 - precision: 0.9274 - recall: 0.9914 - val_loss: 0.3366 - val_accuracy: 0.9400 - val_precision: 0.9313 - val_recall: 0.9760\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.3046 - accuracy: 0.9458 - precision: 0.9274 - recall: 0.9914 - val_loss: 0.3342 - val_accuracy: 0.9450 - val_precision: 0.9385 - val_recall: 0.9760\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 0.3032 - accuracy: 0.9593 - precision: 0.9429 - recall: 0.9957 - val_loss: 0.3330 - val_accuracy: 0.9500 - val_precision: 0.9457 - val_recall: 0.9760\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.3080 - accuracy: 0.9458 - precision: 0.9206 - recall: 1.0000 - val_loss: 0.3287 - val_accuracy: 0.9450 - val_precision: 0.9318 - val_recall: 0.9840\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2955 - accuracy: 0.9458 - precision: 0.9240 - recall: 0.9957 - val_loss: 0.3289 - val_accuracy: 0.9500 - val_precision: 0.9457 - val_recall: 0.9760\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.2955 - accuracy: 0.9593 - precision: 0.9429 - recall: 0.9957 - val_loss: 0.3266 - val_accuracy: 0.9500 - val_precision: 0.9457 - val_recall: 0.9760\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 0.2905 - accuracy: 0.9566 - precision: 0.9390 - recall: 0.9957 - val_loss: 0.3267 - val_accuracy: 0.9500 - val_precision: 0.9457 - val_recall: 0.9760\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 0.2876 - accuracy: 0.9512 - precision: 0.9385 - recall: 0.9871 - val_loss: 0.3217 - val_accuracy: 0.9500 - val_precision: 0.9457 - val_recall: 0.9760\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.2901 - accuracy: 0.9458 - precision: 0.9206 - recall: 1.0000 - val_loss: 0.3206 - val_accuracy: 0.9500 - val_precision: 0.9457 - val_recall: 0.9760\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.2800 - accuracy: 0.9539 - precision: 0.9352 - recall: 0.9957 - val_loss: 0.3186 - val_accuracy: 0.9500 - val_precision: 0.9457 - val_recall: 0.9760\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 0.2830 - accuracy: 0.9539 - precision: 0.9317 - recall: 1.0000 - val_loss: 0.3176 - val_accuracy: 0.9550 - val_precision: 0.9531 - val_recall: 0.9760\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.2810 - accuracy: 0.9566 - precision: 0.9390 - recall: 0.9957 - val_loss: 0.3157 - val_accuracy: 0.9550 - val_precision: 0.9531 - val_recall: 0.9760\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.2828 - accuracy: 0.9621 - precision: 0.9504 - recall: 0.9914 - val_loss: 0.3169 - val_accuracy: 0.9550 - val_precision: 0.9531 - val_recall: 0.9760\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.2730 - accuracy: 0.9539 - precision: 0.9352 - recall: 0.9957 - val_loss: 0.3127 - val_accuracy: 0.9550 - val_precision: 0.9531 - val_recall: 0.9760\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2722 - accuracy: 0.9593 - precision: 0.9393 - recall: 1.0000 - val_loss: 0.3111 - val_accuracy: 0.9550 - val_precision: 0.9531 - val_recall: 0.9760\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2698 - accuracy: 0.9566 - precision: 0.9426 - recall: 0.9914 - val_loss: 0.3134 - val_accuracy: 0.9500 - val_precision: 0.9528 - val_recall: 0.9680\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2717 - accuracy: 0.9485 - precision: 0.9347 - recall: 0.9871 - val_loss: 0.3066 - val_accuracy: 0.9550 - val_precision: 0.9531 - val_recall: 0.9760\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2626 - accuracy: 0.9539 - precision: 0.9352 - recall: 0.9957 - val_loss: 0.3063 - val_accuracy: 0.9550 - val_precision: 0.9531 - val_recall: 0.9760\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2649 - accuracy: 0.9675 - precision: 0.9583 - recall: 0.9914 - val_loss: 0.3068 - val_accuracy: 0.9550 - val_precision: 0.9531 - val_recall: 0.9760\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2601 - accuracy: 0.9593 - precision: 0.9578 - recall: 0.9784 - val_loss: 0.3044 - val_accuracy: 0.9550 - val_precision: 0.9531 - val_recall: 0.9760\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2571 - accuracy: 0.9566 - precision: 0.9390 - recall: 0.9957 - val_loss: 0.3020 - val_accuracy: 0.9550 - val_precision: 0.9531 - val_recall: 0.9760\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2570 - accuracy: 0.9593 - precision: 0.9429 - recall: 0.9957 - val_loss: 0.3003 - val_accuracy: 0.9550 - val_precision: 0.9531 - val_recall: 0.9760\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2541 - accuracy: 0.9566 - precision: 0.9538 - recall: 0.9784 - val_loss: 0.3034 - val_accuracy: 0.9500 - val_precision: 0.9528 - val_recall: 0.9680\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2525 - accuracy: 0.9729 - precision: 0.9625 - recall: 0.9957 - val_loss: 0.2997 - val_accuracy: 0.9500 - val_precision: 0.9528 - val_recall: 0.9680\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2457 - accuracy: 0.9675 - precision: 0.9545 - recall: 0.9957 - val_loss: 0.2962 - val_accuracy: 0.9550 - val_precision: 0.9531 - val_recall: 0.9760\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2477 - accuracy: 0.9675 - precision: 0.9545 - recall: 0.9957 - val_loss: 0.3024 - val_accuracy: 0.9500 - val_precision: 0.9600 - val_recall: 0.9600\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2403 - accuracy: 0.9783 - precision: 0.9706 - recall: 0.9957 - val_loss: 0.2945 - val_accuracy: 0.9550 - val_precision: 0.9531 - val_recall: 0.9760\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2457 - accuracy: 0.9621 - precision: 0.9467 - recall: 0.9957 - val_loss: 0.2910 - val_accuracy: 0.9550 - val_precision: 0.9531 - val_recall: 0.9760\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2440 - accuracy: 0.9648 - precision: 0.9506 - recall: 0.9957 - val_loss: 0.3029 - val_accuracy: 0.9500 - val_precision: 0.9600 - val_recall: 0.9600\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2406 - accuracy: 0.9783 - precision: 0.9706 - recall: 0.9957 - val_loss: 0.2961 - val_accuracy: 0.9550 - val_precision: 0.9603 - val_recall: 0.9680\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2474 - accuracy: 0.9675 - precision: 0.9545 - recall: 0.9957 - val_loss: 0.2904 - val_accuracy: 0.9550 - val_precision: 0.9531 - val_recall: 0.9760\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2409 - accuracy: 0.9621 - precision: 0.9431 - recall: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.9550 - val_precision: 0.9603 - val_recall: 0.9680\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2335 - accuracy: 0.9756 - precision: 0.9665 - recall: 0.9957 - val_loss: 0.2943 - val_accuracy: 0.9550 - val_precision: 0.9603 - val_recall: 0.9680\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2374 - accuracy: 0.9702 - precision: 0.9547 - recall: 1.0000 - val_loss: 0.2838 - val_accuracy: 0.9550 - val_precision: 0.9531 - val_recall: 0.9760\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2371 - accuracy: 0.9675 - precision: 0.9508 - recall: 1.0000 - val_loss: 0.2857 - val_accuracy: 0.9500 - val_precision: 0.9528 - val_recall: 0.9680\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2336 - accuracy: 0.9675 - precision: 0.9583 - recall: 0.9914 - val_loss: 0.2885 - val_accuracy: 0.9550 - val_precision: 0.9603 - val_recall: 0.9680\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2317 - accuracy: 0.9675 - precision: 0.9622 - recall: 0.9871 - val_loss: 0.2908 - val_accuracy: 0.9550 - val_precision: 0.9603 - val_recall: 0.9680\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2269 - accuracy: 0.9702 - precision: 0.9547 - recall: 1.0000 - val_loss: 0.2827 - val_accuracy: 0.9550 - val_precision: 0.9531 - val_recall: 0.9760\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.2309 - accuracy: 0.9593 - precision: 0.9465 - recall: 0.9914 - val_loss: 0.2921 - val_accuracy: 0.9500 - val_precision: 0.9600 - val_recall: 0.9600\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.2223 - accuracy: 0.9756 - precision: 0.9745 - recall: 0.9871 - val_loss: 0.2848 - val_accuracy: 0.9550 - val_precision: 0.9603 - val_recall: 0.9680\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.2265 - accuracy: 0.9702 - precision: 0.9547 - recall: 1.0000 - val_loss: 0.2795 - val_accuracy: 0.9550 - val_precision: 0.9603 - val_recall: 0.9680\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2217 - accuracy: 0.9729 - precision: 0.9587 - recall: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.9550 - val_precision: 0.9603 - val_recall: 0.9680\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.2240 - accuracy: 0.9675 - precision: 0.9545 - recall: 0.9957 - val_loss: 0.2876 - val_accuracy: 0.9500 - val_precision: 0.9600 - val_recall: 0.9600\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.2211 - accuracy: 0.9783 - precision: 0.9746 - recall: 0.9914 - val_loss: 0.2815 - val_accuracy: 0.9550 - val_precision: 0.9603 - val_recall: 0.9680\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2175 - accuracy: 0.9810 - precision: 0.9707 - recall: 1.0000 - val_loss: 0.2831 - val_accuracy: 0.9550 - val_precision: 0.9603 - val_recall: 0.9680\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.2158 - accuracy: 0.9783 - precision: 0.9706 - recall: 0.9957 - val_loss: 0.2777 - val_accuracy: 0.9550 - val_precision: 0.9603 - val_recall: 0.9680\n",
            "Test Loss: 0.2776811420917511\n",
            "Test Accuracy: 0.9549999833106995\n",
            "Test Precision: 0.9603174328804016\n",
            "Test Recall: 0.9679999947547913\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# predict classes for the test set\n",
        "y_pred_prob = model.predict(test_df_x)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# generate confusion matrix\n",
        "cm = confusion_matrix(test_df_y, y_pred, labels=[0,1])\n",
        "\n",
        "sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\", xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
        "\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "\n",
        "# print confusion matrix\n",
        "print('Confusion Matrix: ')\n",
        "print(cm)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "i1f1X2jHAsGc",
        "outputId": "8a4bce3b-fae8-4224-8048-dfcc91da2acb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 3ms/step\n",
            "Confusion Matrix: \n",
            "[[ 70   5]\n",
            " [  4 121]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}